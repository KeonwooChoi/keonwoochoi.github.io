<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: AI - blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="blog"><meta name="msapplication-TileImage" content="./img/favicon3.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="blog"><meta property="og:url" content="https://keonwoochoi.github.io/"><meta property="og:site_name" content="blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://keonwoochoi.github.io/img/og_image.png"><meta property="article:author" content="Keonwoo Choi"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://keonwoochoi.github.io"},"headline":"blog","image":["https://keonwoochoi.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Keonwoo Choi"},"description":""}</script><link rel="icon" href="/./img/favicon3.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">blog</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-10-tablet is-10-desktop is-10-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">AI</a></li></ul></nav></div></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/23/BoostCamp/Day21/"><img class="fill" src="/img/boostcamp.png" alt="Day21"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-23T04:36:05.000Z" title="2021-2-23 1:36:05 ├F10: PM┤">2021-02-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:31:35.031Z" title="2021-3-22 6:31:35 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">16 minutes read (About 2396 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/23/BoostCamp/Day21/">Day21</a></h1><div class="content"><h2 id="그래프"><a href="#그래프" class="headerlink" title="그래프"></a>그래프</h2><ul>
<li>그래프는 <code>정점(Vertex)</code> 집합과, <code>간선(Edge)</code> 집합으로 이루어진 수학적 구조이다.</li>
<li>네트워크로도 불리며, 정점은 노드(Node)로, 간선은 엣지(Edge) 혹은 링크(Link)로도 불린다.</li>
<li>우리 주변의 많은 복잡계(Complex System)는 구성 요소 간의 복잡한 상호작용을 하는 특성이 있다</li>
<li>그래프는 이복잡계의 상호작용을 효과적으로 표현하고, 복잡계를 분석하기 위한 언어이다.</li>
</ul>
<h2 id="정점-분류-Node-Classification-문제"><a href="#정점-분류-Node-Classification-문제" class="headerlink" title="정점 분류(Node Classification) 문제"></a>정점 분류(Node Classification) 문제</h2><ul>
<li>트위터에서의 공유(Retweet) 관계를 분석하여, 각 사용자의 정치적 성향을 파악</li>
<li>백질의 상호작용을 분석</li>
</ul>
<h2 id="연결-예측-Link-Prediction-문제"><a href="#연결-예측-Link-Prediction-문제" class="headerlink" title="연결 예측(Link Prediction) 문제"></a>연결 예측(Link Prediction) 문제</h2><ul>
<li>거시적 - 페이스북 소셜네트워크는 진화 방향 예측</li>
<li>미시적 : 추천시스템</li>
</ul>
<h3 id="군집-분석-Community-Detection-문제"><a href="#군집-분석-Community-Detection-문제" class="headerlink" title="군집 분석(Community Detection) 문제"></a>군집 분석(Community Detection) 문제</h3><ul>
<li>연결 관계로부터 사회적 무리(Social Circle)을 찾아내기</li>
</ul>
<h3 id="랭킹-Ranking-및-정보-검색-Information-Retrieval-문제"><a href="#랭킹-Ranking-및-정보-검색-Information-Retrieval-문제" class="headerlink" title="랭킹(Ranking) 및 정보 검색(Information Retrieval) 문제"></a>랭킹(Ranking) 및 정보 검색(Information Retrieval) 문제</h3><ul>
<li>웹(Web)이라는 거대한 그래프로부터 중요한 웹페이지 찾아내기</li>
</ul>
<h2 id="정보-전파-Information-Cascading-및-바이럴-마케팅-Viral-Marketing-문제"><a href="#정보-전파-Information-Cascading-및-바이럴-마케팅-Viral-Marketing-문제" class="headerlink" title="정보 전파(Information Cascading) 및 바이럴 마케팅(Viral Marketing) 문제"></a>정보 전파(Information Cascading) 및 바이럴 마케팅(Viral Marketing) 문제</h2><ul>
<li>정보 전달을 최대화</li>
</ul>
<h1 id="그래프의-유형-및-분류"><a href="#그래프의-유형-및-분류" class="headerlink" title="그래프의 유형 및 분류"></a>그래프의 유형 및 분류</h1><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108802744-58eb4280-75dc-11eb-8ed6-8d9c4b729e91.png" alt="image-20210223115720602"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108802747-58eb4280-75dc-11eb-9ed5-384a4ea41557.png" alt="image-20210223115746262"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108802748-5983d900-75dc-11eb-9f8e-97c4da9cf980.png" alt="image-20210223115803381"></li>
</ul>
<h2 id="표현-방식"><a href="#표현-방식" class="headerlink" title="표현 방식"></a>표현 방식</h2><ul>
<li><p>일반적으로 정점들의 집합을 _V_, 간선들의 집합을 _E_, 그래프를 _G_=(_V_,_E_)로 적는다.</p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/108802741-57ba1580-75dc-11eb-822c-41c90fb74ee1.png" alt="image-20210223114334189"></p>
</li>
<li>방향성이 있는 그래프에서는 나가는 이웃들의 집합을 $N_{out}{(v)}$ 들어오는 이웃들의 집합을 $N_{in}{(v)}$으로 표시</li>
<li>간선 리스트(Edge List) - 그래프를 간선들의 리스트로 저장한다<ul>
<li>간선이 연결하는 두 정점들의 순서쌍(Pair)로 저장된다.</li>
<li>방향성이 있는 간선의 경우 (출발점, 도착점) 순서로 저장</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108802751-5983d900-75dc-11eb-9387-aadf995641f0.png" alt="image-20210223120744121"></li>
</ul>
</li>
<li>인접 리스트(Adjacent List) - 각 정점들의 이웃들을 리스트로 저장한다.<ul>
<li>방향성이 없는 경우<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108802753-5a1c6f80-75dc-11eb-90d4-dfa8d81c9255.png" alt="image-20210223120844329"></li>
</ul>
</li>
<li>방향성이 있는 경우<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108802758-5a1c6f80-75dc-11eb-89e0-924cafb398b9.png" alt="image-20210223120901521"></li>
</ul>
</li>
</ul>
</li>
<li>인접 행렬(Adjacent Matrix)<ul>
<li>방향성이 없는 경우<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108802759-5ab50600-75dc-11eb-8f45-5256034097f7.png" alt="image-20210223120955560"></li>
</ul>
</li>
<li>방향성이 있는 경우<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108802761-5ab50600-75dc-11eb-9991-0374273e9bc2.png" alt="image-20210223121021010"></li>
</ul>
</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108802764-5b4d9c80-75dc-11eb-8414-901d19ee87df.png" alt="image-20210223121240289"><ul>
<li>행렬의 원소가 대부분 0이 아닌 경우에 일반행렬이 더 빠르다</li>
</ul>
</li>
</ul>
<hr>
<h2 id="실제-그래프와-랜덤-그래프"><a href="#실제-그래프와-랜덤-그래프" class="headerlink" title="실제 그래프와 랜덤 그래프"></a>실제 그래프와 랜덤 그래프</h2><ul>
<li>실제 그래프(RealGraph)란 다양한 복잡계로 부터 얻어진 그래프<ul>
<li>MSN</li>
</ul>
</li>
<li>랜덤 그래프(RandomGraph)는 확률적 과정을 통해 생성한 그래프<ul>
<li>에르되스(Erdős)와 레니(Rényi)가 제안한 랜덤 그래프 모델<ul>
<li>임의의 두 정점 사이에 간선이 존재하는지 여부는 동일한 확률 분포에 의해 결정됩니다</li>
<li>에르되스-레니 랜덤그래프 $G(n,p)$는<ul>
<li>n개의 정점을 가지고</li>
<li>임의의 두 개의 정점 사이에 간선이 존재할 확률은 p</li>
<li>정점 간의 연결은 서로 독립적</li>
</ul>
</li>
<li>Q. G(3,0.3) 에 의해 생성될 수 있는 그래프와 각각의 확률은?</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108802743-5852ac00-75dc-11eb-9dd1-708e6d764e52.png" alt="image-20210223114623627"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="작은-세상-효과"><a href="#작은-세상-효과" class="headerlink" title="작은 세상 효과"></a>작은 세상 효과</h2><ul>
<li>경로와 거리<ul>
<li>정점 <em>u</em>와 _v_ 사이의 <strong><code>경로(Path)</code></strong>는 아래 조건을 만족하는 정점들의 순열(Sequence)이다<ol>
<li><em>u</em>에서 시작하여 <em>v</em>에서 끝난다.</li>
<li>순열에서 연속된 정점은 간선으로 연결되어 있어야 한다.</li>
</ol>
</li>
<li><code>경로의 길이</code>는 해당 경로 상에 놓이는 간선의 수로 정의된다.<ul>
<li>경로의 길이= 순열에 존재하는 정점들의 수-1</li>
</ul>
</li>
<li>정점 u<em>와 </em>v<em> 사이의 <code>거리(Distance)</code>는 </em>u<em>와 </em>v* 사이 최단경로의 길이이다.</li>
<li><code>지름(Diameter)</code>은 정점 간 거리의 최댓값이다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108802767-5b4d9c80-75dc-11eb-92cb-40bc5a41c886.png" alt="image-20210223121919073"></li>
</ul>
</li>
</ul>
</li>
<li>작은 세상 효과<ul>
<li>임의의 두 사람을 골랐을 때, 몇 단계의 지인을 거쳐 연결되어 있을까?<ul>
<li>평균적으로 6단계만을 거쳤습니다</li>
</ul>
</li>
<li>MSN메신저 그래프에서는 어떨까요?<ul>
<li>정점 간의 평균 거리는 7 정도 밖에 되지 않습니다</li>
</ul>
</li>
<li>작은 세상 효과는 높은 확률로 랜덤 그래프에도 존재<ul>
<li>모든 사람이 100명의 지인이 있다고 가정해봅시다 다섯 단계를 거치면 최대 100억(= $100^5$)명의 사람과 연결될 수 있습니다</li>
</ul>
</li>
<li>하지만 모든 그래프에서 작은 세상 효과가 존재하는 것은 아닙니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108802770-5be63300-75dc-11eb-9753-126df567fb87.png" alt="image-20210223122304321"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="연결성의-두터운-꼬리-분포"><a href="#연결성의-두터운-꼬리-분포" class="headerlink" title="연결성의 두터운 꼬리 분포"></a>연결성의 두터운 꼬리 분포</h2><ul>
<li>연결성<ul>
<li>정점의 연결성(Degree)은 그 정점과 연결된 간선의 수를 의미합니다</li>
<li>정점 V의 연결성은 해당 정점의 이웃들의 수와 같습니다 보통 정점 V의 연결성은 $d(v)$, $d_v$혹은 $|N(v)|$ 로 적습니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108802772-5c7ec980-75dc-11eb-914f-3c12b0375791.png" alt="image-20210223122531540"></li>
</ul>
</li>
<li>두터운 꼬리 분포<ul>
<li>실제 그래프의 연결성 분포는 두터운 꼬리(HeavyTail)를 갖습니다</li>
<li>즉,연결성이 매우 높은 허브(Hub) 정점이 존재함을 의미합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108802773-5c7ec980-75dc-11eb-9746-9c53365fa814.png" alt="image-20210223122627251"></li>
</ul>
</li>
<li>랜덤 그래프의 연결성 분포는 높은 확률로 정규 분포와 유사합니다</li>
<li>연결성이 매우 높은 허브(Hub) 정점이 존재할 가능성은 0</li>
<li>정규 분포와 유사한 예시로는 키의 분포가 있습니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108802774-5d176000-75dc-11eb-9c3e-d666d58ffb1d.png" alt="image-20210223122722259"></li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108802775-5daff680-75dc-11eb-85a6-cf6c5593a1f6.png" alt="image-20210223122738022"></li>
</ul>
</li>
</ul>
<h2 id="거대-연결-요소"><a href="#거대-연결-요소" class="headerlink" title="거대 연결 요소"></a>거대 연결 요소</h2><ul>
<li>연결 요소<ul>
<li>연결 요소(ConnectedComponent)는 다음 조건들을 만족하는 정점들의 집합을 의미합니다<ol>
<li>연결 요소에 속하는 정점들은 경로로 연결될 수 있습니다</li>
<li>1의 조건을 만족하면서 정점을 추가할 수 없습니다</li>
</ol>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108802776-5daff680-75dc-11eb-8bfe-12b5dd14470c.png" alt="image-20210223122832410"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108802778-5e488d00-75dc-11eb-91cd-5b539648f710.png" alt="image-20210223122900416"></li>
</ul>
</li>
<li>거대 연결 요소<ul>
<li>실제 그래프에는 거대 연결 요소(GiantConnectedComponent)가 존재합니다 거대 연결 요소는 대다수의 정점을 포함합니다</li>
<li>MSN메신저 그래프에는 99.9%의 정점이 하나의 거대 연결 요소에 포함됩니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108802781-5ee12380-75dc-11eb-8652-8f3e83aa28d6.png" alt="image-20210223122936506"></li>
</ul>
</li>
<li>랜덤 그래프에도 높은 확률로 거대 연결 요소(GiantConnectedComponent)가 존재합니다</li>
<li>단,정점들의 평균 연결성이 1보다 충분히 커야 합니다</li>
<li>는 RandomGraphTheory<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108802782-5ee12380-75dc-11eb-9b91-92b24c63945a.png" alt="image-20210223123007297"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="군집-계수"><a href="#군집-계수" class="headerlink" title="군집 계수"></a>군집 계수</h2><ul>
<li>군집<ul>
<li>군집(Community)이란 다음 조건들을 만족하는 정점들의 집합입니다<ol>
<li>집합에 속하는 정점 사이에는 많은 간선이 존재합니다</li>
<li>집합에 속하는 정점과 그렇지 않은 정점 사이에는 적은 수의 간선이 존재합니다</li>
</ol>
</li>
<li>수학적으로 엄밀한 정의는 아니다.</li>
</ul>
</li>
<li>지역적 군집 계수<ul>
<li>지역적 군집 계수(LocalClusteringCoefficient)는 한 정점에서 군집의 형성 정도를 측정합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108802786-5f79ba00-75dc-11eb-879a-21f37c13d893.png" alt="image-20210223130649731"></li>
<li>지역적 군집 계수(LocalClusteringCoefficient)는 한 정점에서 군집의 형성 정도를 측정합니다</li>
<li>연결성이 0인 정점에서는 지역적 군집 계수가 정의되지 않습니다</li>
<li>지역적 군집 계수가 군집이랑 어떻게 연결되는 것이죠?<ul>
<li>정점 i의 지역적 군집 계수가 매우 높다고 합시다 즉,정점 i의 이웃들도 높은 확률로 서로 간선으로 연결되어 있습니다 정점 i와 그 이웃들은 높은 확률로 군집을 형성합니다</li>
</ul>
</li>
</ul>
</li>
<li>전역 군집 계수<ul>
<li>전역 군집 계수(GlobalClusteringCoefficient)는 전체 그래프에서 군집의 형성 정도를 측정합니다</li>
<li>그래프 G의 전역 군집 계수는 각 정점에서의 지역적 군집 계수의 평균입니다 단,지역적 군집 계수가 정의되지 않는 정점은 제외합니다</li>
</ul>
</li>
<li>높은 군집 계수<ul>
<li>실제 그래프에서는 군집 계수가 높다. 즉, <strong>많은 군집이 존재</strong>한다. 이유에는 여러가지가 있다.</li>
<li><code>동질성(Homophily)</code> : 서로 유사한 정점끼리 간선으로 연결될 가능성이 높다.<ul>
<li>같은 동네에 사는 같은 나이의 아이들이 친구가 되는 경우가 그 예시입니다</li>
</ul>
</li>
<li><code>전이성(Transitivity)</code> : 공통 이웃이 있는 경우, 공통 이웃이 매개 역할을 해줄 수 있다.<ul>
<li>친구를 서로에게 소개해주는 경우가 그 예시입니다</li>
</ul>
</li>
<li>반면 랜덤 그래프에서는 지역적 혹은 전역 군집 계수가 높지 않습니다<ul>
<li>구체적으로 랜덤 그래프 G(n,p)에서의 군집 계수는 p입니다</li>
<li>랜덤 그래프에서의 간선 연결이 독립적인 것을 고려하면 당연한 결과입니다</li>
</ul>
</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108802789-60125080-75dc-11eb-8867-a63aa8c0eae2.png" alt="image-20210223131725442"></li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/22/BoostCamp/Day20/"><img class="fill" src="/img/boostcamp.png" alt="Day20"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-22T06:35:02.000Z" title="2021-2-22 3:35:02 ├F10: PM┤">2021-02-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:31:27.173Z" title="2021-3-22 6:31:27 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">11 minutes read (About 1596 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/22/BoostCamp/Day20/">Day20</a></h1><div class="content"><h1 id="Recent-Trends"><a href="#Recent-Trends" class="headerlink" title="Recent Trends"></a>Recent Trends</h1><ul>
<li>self-attention block을 많이 쌓는다</li>
<li>self-supervised learning framework</li>
<li>추천시스템 신약개발 영상처리</li>
<li><p>자연어 생성 task에서 여전히 greedy decoding 벗어나지 못함</p>
<h1 id="GPT-1"><a href="#GPT-1" class="headerlink" title="GPT-1"></a>GPT-1</h1></li>
</ul>
<p><img src="https://user-images.githubusercontent.com/46857207/108671137-5e388680-7523-11eb-81c0-7d0478c4c3d8.png" alt="image-20210219102659967"></p>
<ul>
<li>special token을 제안해서 다양한 자연어 처리 task를 가능하게 함</li>
<li>12개의 self-attention block</li>
<li>text prediction: 다음단어 예측하는 language modelling<ul>
<li>입력과 출력이 따로 있지 않음</li>
</ul>
</li>
<li>sentiment analysis, classification과 같은 label된 데이터가 있을때 multi-task learning에 의해서 학습<ul>
<li><EOS>토큰과 다른 extract토큰으로 바꾼 후 인코딩</li>
<li>extract토큰만을 선형변환을 통해 긍부정에 대한 output 예측</li>
</ul>
</li>
<li>entailment task<ul>
<li>두 개의 문장을 하나의 sequence로 만들되 중간에 Delim토큰</li>
<li>extract토큰을 output layer에 통과시켜 분류 시행</li>
</ul>
</li>
<li>extract토큰이 query로 사용되어서 task에 필요한 여러 정보들을 input으로부터 정보를 추출할 수 있어야함</li>
<li>학습된 GPT-1모델을 transfer learning형태로 활용할 때<ul>
<li>가령 긍부정 분류를 하다가 주제분류를 하게되면 downstream task로써</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671172-67c1ee80-7523-11eb-8331-c4bdfb5dafd2.png" alt="image-20210220001443241"></li>
</ul>
</li>
<li>learning rate</li>
</ul>
<h1 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h1><p><img src="https://user-images.githubusercontent.com/46857207/108671138-5ed11d00-7523-11eb-87d7-81d44c7b8ac3.png" alt="image-20210219102816303"></p>
<ul>
<li>다음단어를 예측하는 language modelling방식으로 학습시킨 모델</li>
<li>Pre-training Task in BERT<ul>
<li>Masked Language Model<ul>
<li>얼마나 가릴지 hyperparameter 15%</li>
<li>너무 높거나 낮으면 문제</li>
<li>15% 다 MASK로 바꾸는 것이 아닌<ul>
<li>80(MASK) 10(random word) 10(keep same)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Next Sentence Prediction<ul>
<li>문장레벨에서의 task에 대응하기 위한 기법</li>
<li>두 문장이 인접한 문장인지 구별하는 binary classification</li>
<li>[CLS] : GPT의 extract, 문장의 앞</li>
<li>[SEP] : 문장 사이, 끝날 때</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671141-5f69b380-7523-11eb-98a8-fd465dde2ddb.png" alt="image-20210219103703030"></li>
</ul>
</li>
<li>Summary<ul>
<li>self-attention block</li>
<li>arichitecture<ul>
<li>base: L=12 H(인코딩vector의 차원 수 )=768 A(attention-block)=12</li>
<li>large: L=24 H=1024 A=16</li>
</ul>
</li>
<li>input representation<ul>
<li>word별 embedding vector가 아닌 좀 더 잘게 쪼갠 subword단위</li>
<li>wordPiece embedding(30000)</li>
<li>learned positional embedding -&gt; 단어의 위치 정보</li>
<li>[CLS] [SEP]</li>
<li>segment embedding<ul>
<li>‘he’는 6번쨰 단어이지만 ,2번째 문장의 첫번째 단어</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671145-61337700-7523-11eb-8168-facc67404d04.png" alt="image-20210219104104656"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>GPT vs BERT<ul>
<li>GPT : Masked( 다음 단어를 예측하는것이 task이기 때문에 다음단어 접근 불가) ,BERT: Masked단어를 포함하여 모든 단어 접근 가능</li>
<li>GPT; 800M words, batch size-32000 learning-rate동일</li>
<li>BERT: 2500M words, [CLS] [SEP], segment embedding, batch-size-128000 , learning-rate-optimization</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671148-6264a400-7523-11eb-9da1-f4043ad2b328.png" alt="image-20210219104831286"></li>
</ul>
</li>
<li>FIne tunning process<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108671174-67c1ee80-7523-11eb-833e-223c44f452bf.png" alt="image-20210220014456106"></li>
</ul>
</li>
<li>Machine Reading Comprehension, Question Answering<ul>
<li>기계 독해 기반 질의응답</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671150-6264a400-7523-11eb-9397-9d4dfb5b056b.png" alt="image-20210219105023144"></li>
</ul>
</li>
<li>SQuAD1.1<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108671151-62fd3a80-7523-11eb-87da-cebdee7ddc05.png" alt="image-20210219105502453"></li>
<li>정답 문구의 위치</li>
</ul>
</li>
<li>SQuAD2.0<ul>
<li>답이 없는 경우</li>
<li>[CLS] 을 활용해서 binary classification -&gt; no answer(cross entropy loss)</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671153-62fd3a80-7523-11eb-8731-5aa932ad83c9.png" alt="image-20210219105645078"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671155-6395d100-7523-11eb-9bc3-3dc9453a02d8.png" alt="image-20210219105750385"></li>
</ul>
</li>
<li>On Swag<ul>
<li>다수 문장을 다룰 때 다음에 나타날법한 적절한 문장</li>
<li>매번 서로 다른 문장을 concat해서 [CLS]토큰을 output layer를 통과하여 각기 얻은 scalar값을 softmax</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671158-642e6780-7523-11eb-9a97-992a6c7d4de5.png" alt="image-20210219105826843"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671156-642e6780-7523-11eb-97ad-1b28b7895bd3.png" alt="image-20210219105817057"></li>
</ul>
</li>
<li>모델이 끊임 없이 좋아짐<ul>
<li>layer를 깊게 쌓고 parameter를 늘릴 수록 계속 좋아짐</li>
<li>not asymptoted (점근적이지 않다)</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671159-64c6fe00-7523-11eb-9700-ee93ab525708.png" alt="image-20210219110006966"></li>
</ul>
</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/46857207/108671175-685a8500-7523-11eb-8daf-7e7ebf6b1608.png" alt="image-20210220021600123"></p>
<hr>
<h1 id="Advance-Self-superviesd-pre-training-models"><a href="#Advance-Self-superviesd-pre-training-models" class="headerlink" title="Advance Self-superviesd pre-training models"></a>Advance Self-superviesd pre-training models</h1><h2 id="GPT-2"><a href="#GPT-2" class="headerlink" title="GPT-2"></a>GPT-2</h2><ul>
<li>pre-training-task: language modelling</li>
<li>40GB</li>
<li>dataset is good quality</li>
<li>Language model can perform down-stream tasks in zero-shot setting- without any parameter or architecture modification</li>
<li>motivation<ul>
<li>multitasking learning as question answering</li>
<li>모든 자연어처리 task가 질의응답으로 바뀔 수 있다.</li>
</ul>
</li>
<li>Dataset<ul>
<li>Reddit- 외부 링크도 포함(좋아요3개이상)</li>
<li>preprocess<ul>
<li>bpe</li>
</ul>
</li>
</ul>
</li>
<li>model<ul>
<li>layer normalization</li>
<li>layer가 위로 갈수록 선형변환 값들이 0에 수렴<ul>
<li>위쪽 layer의 역할이 줄어듬</li>
</ul>
</li>
</ul>
</li>
<li>Question Answering<ul>
<li>conversation question answering dataset (CoQA)<ul>
<li>55 F1 score</li>
<li>Fine tuned bert achieved 89 F1</li>
</ul>
</li>
</ul>
</li>
<li>Summarization<ul>
<li>fine tune없이 zero shot으로 inference</li>
<li>TL;RT Too long didnt read</li>
</ul>
</li>
<li>Translation<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108671160-655f9480-7523-11eb-9f6e-a81a746f4a8e.png" alt="image-20210219111840973"></li>
</ul>
</li>
</ul>
<h2 id="GPT-3"><a href="#GPT-3" class="headerlink" title="GPT-3"></a>GPT-3</h2><ul>
<li>parameter수를 많이, 큰 batch-size, 많은 data</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671163-655f9480-7523-11eb-8e9b-a65af9e30642.png" alt="image-20210219112105028"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671165-65f82b00-7523-11eb-8572-c4a0f680c1a0.png" alt="image-20210219112127111"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671176-68f31b80-7523-11eb-831c-ef1c53232c8a.png" alt="image-20210220111947547"></li>
</ul>
<h2 id="ALBERT"><a href="#ALBERT" class="headerlink" title="ALBERT"></a>ALBERT</h2><ul>
<li>장애물<ul>
<li>memory limitation</li>
<li>training speed</li>
</ul>
</li>
<li>A Lite BERT</li>
<li>Factorized Embedding parameterization<ul>
<li>기존의 BERT에서 Embedding vector 사이즈는 hidden vector size 와 같아야 했다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671167-65f82b00-7523-11eb-80d6-c4cc5746a73e.png" alt="image-20210219113056190"></li>
</ul>
</li>
<li>Cross-layer Parameter Sharing<ul>
<li>Shared-FFN</li>
<li>Shared-attention- $W_q ,W_k, W_v$</li>
<li>All-shared</li>
<li>성능 차이 별로 없다</li>
</ul>
</li>
<li>Sentence Order Prediction<ul>
<li>Next sentence Prediction -&gt;BERT에서 실효성이 없음-&gt;masked language modelling만</li>
<li>연속적인 두 문장의 순서를 예측</li>
<li>두 독립적인 문장을 가져와 선후관계를 파악하는 것이 아니라, 항상 연속적인 두 문장을 가져온다.</li>
<li>정오더 or 역오더</li>
<li>이를 <code>negative sample</code>이라고 하는데, 인접 문장이므로 순서와 관계없이 비슷한 단어가 당연히 많이 등장한다.</li>
</ul>
</li>
</ul>
<h2 id="ELECTRA"><a href="#ELECTRA" class="headerlink" title="ELECTRA"></a>ELECTRA</h2><p>efficiently learning an encoder that classifies token replacements accurately</p>
<ul>
<li><p>마스킹된 단어를 복원해주는 모델-<strong><code>Generator</code></strong>를 하나 두고, 또 Generator가 복원한 단어들을 받아 이 단어가 원본인지 또는 generator에 의해 복원된 단어인지를 예측하는 모델-<strong><code>Discriminator</code></strong>를 둔다.</p>
</li>
<li><p>Generator ,Discriminator (GAN아이디어)</p>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671168-6690c180-7523-11eb-9cad-760364410be8.png" alt="image-20210219114720305"></li>
<li>pre-trained Discriminator을 사용</li>
</ul>
<h2 id="Light-weight-Models"><a href="#Light-weight-Models" class="headerlink" title="Light-weight Models"></a>Light-weight Models</h2><ul>
<li>DistillBERT<ul>
<li>teacher model , student model</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108671179-68f31b80-7523-11eb-934c-ce3b2a1bd190.png" alt="image-20210220115245837"></li>
</ul>
</li>
<li>TinyBERT<ul>
<li>Teacher model의 parameter, 중간결과물까지 닮도록 학습</li>
<li>MSE Loss</li>
<li>teacher model과 student model의 차원이 다르면 적용하기 어려울 수 있음<ul>
<li>FCN을 하나 더 둔다</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Fusing-Knowledge-Graph-into-language-Model"><a href="#Fusing-Knowledge-Graph-into-language-Model" class="headerlink" title="Fusing Knowledge Graph into language Model"></a>Fusing Knowledge Graph into language Model</h2><ul>
<li>주어진 문장에서 문맥, 단어들간 유사도는 잘 파악하나 문장에 포함되지 않은 추가적인 정보는 활용 못함</li>
<li>ex) 꽃을 심기 위해 땅을 판다. 집을 짓기 위해 땅을 판다.<ul>
<li>땅을 파기 위한 도구는 문장에 나타나지 않음</li>
<li>외부지식(Knowledge graph)을 통해 학습 땅-파다-도구 ex)삽, 포크레인</li>
</ul>
</li>
</ul>
<h2 id="Further-Question"><a href="#Further-Question" class="headerlink" title="Further Question"></a><strong>Further Question</strong></h2><ul>
<li>BERT의 Masked Language Model의 단점은 무엇이 있을까요? 사람이 실제로 언어를 배우는 방식과의 차이를 생각해보며 떠올려봅시다</li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/19/BoostCamp/Day19/"><img class="fill" src="/img/boostcamp.png" alt="Day19"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-19T06:28:49.000Z" title="2021-2-19 3:28:49 ├F10: PM┤">2021-02-19</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:31:23.074Z" title="2021-3-22 6:31:23 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">6 minutes read (About 876 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/19/BoostCamp/Day19/">Day19</a></h1><div class="content"><h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><p>Attention만을 사용해 RNN대체</p>
<ul>
<li><p>기존 RNN 모델의 한계</p>
<ul>
<li>long-term dependecy problem</li>
</ul>
</li>
<li><p>Bi-Directional RNNs</p>
<ul>
<li>왼쪽, 오른쪽 정보 같이 포함할 수 있도록 forward, backward RNN 두 개의 모듈을 병렬적으로 만듦</li>
</ul>
</li>
<li><h2 id="Transformer-1"><a href="#Transformer-1" class="headerlink" title="Transformer"></a>Transformer</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108466533-1fa69000-72c7-11eb-896f-2d45c0db1895.png" alt="image-20210219150756178"></li>
</ul>
</li>
<li><h2 id="인코더"><a href="#인코더" class="headerlink" title="인코더"></a>인코더</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108466475-13223780-72c7-11eb-8d16-cb9fbcf4146b.png" alt="image-20210218100814381"></li>
</ul>
</li>
<li><p>input vector는 각각 query벡터로 변환</p>
</li>
<li><p>query vector 와 key vector 내적을 통해 새로운 vector 생성</p>
</li>
<li><p>key vector: query vector와 내적, 여러개의 key vector들 중 어느것이 query와 연관있는 지</p>
</li>
<li><p>value: 가중평균 구하는데 쓰이는 재료 vector</p>
</li>
<li><p>value 벡터에 대한 가중편균-&gt; 모든 단어의 정보 고려</p>
</li>
<li><p>seq 길이가 길어도 동일한 key value들로 변환되고 query와 유사도만 높다면 멀리있는 정보도 쉽게 가져올 수 있다.</p>
</li>
<li><p>input을그대로 사용하면 자기 자신과의 내적이 가장 커지는 문제</p>
</li>
<li><p>input q (k,v)</p>
<ul>
<li>q,k의 차원은 같지만 v의 차원은 달라도 됨</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108466479-14ebfb00-72c7-11eb-91b2-cdc1dc03f327.png" alt="image-20210218101313910"></li>
</ul>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/108466482-14ebfb00-72c7-11eb-8202-a8266ec65768.png" alt="image-20210218101348806"></p>
</li>
<li><p>query가 여러개</p>
<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108466483-15849180-72c7-11eb-8f16-8f0c0f16b206.png" alt="image-20210218102201393"></li>
</ul>
</li>
<li><p>병렬적인 행렬 연산을 통해 학습이 빠름</p>
</li>
<li><p>Scaled dot product</p>
<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108466484-161d2800-72c7-11eb-8eb9-d568f68daada.png" alt="image-20210218102425223"></li>
<li>분산이 작을수록 표준편차가 작고 확률분포가 uniform distribution(30~50%)에 가깝게 나타난다</li>
<li>어느 한 key에만 극단적으로 몰리는것을 방지</li>
<li>분산이 1인 형태로 유지</li>
<li>한쪽으로 몰리는 경우 gradient vanishing 발생 가능</li>
</ul>
</li>
</ul>
<hr>
<h2 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi Head Attention"></a>Multi Head Attention</h2><p>여러개의 attention을 사용하여 여러 문장이 있을 때 다양한 관점에서 정보를 뽑는다.</p>
<p>Multi-head attention을 사용하는 이유는 같은 문장에서도 <strong>중점을 두어야 할 단어들이 다를 수 있기 때문</strong></p>
<hr>
<h2 id="복잡도"><a href="#복잡도" class="headerlink" title="복잡도"></a>복잡도</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108466487-161d2800-72c7-11eb-8f76-ae74f3068e23.png" alt="image-20210218112126839"></li>
<li>self-attention의 메모리 사용은 seq에 따라 커질 수 있지만 병렬적으로 수행 사능<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108466488-16b5be80-72c7-11eb-9912-e299fc79f9c9.png" alt="image-20210218112206563"></li>
</ul>
</li>
<li>RNN은 dimension으로 조절할 수 있지만 병렬 수행 불가<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108466492-16b5be80-72c7-11eb-9d17-a217454a1555.png" alt="image-20210218112341946"></li>
</ul>
</li>
<li>Block-Based Model<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108466493-174e5500-72c7-11eb-9313-d24633b02624.png" alt="image-20210218113026170"></li>
<li>2개의 sub layers<ul>
<li>multi-head attention</li>
<li>feed-forward NN with ReLU (Fully connected)</li>
</ul>
</li>
<li>각각 2개의 step<ul>
<li>residual conneciton and layer normalization</li>
<li>LayerNorm(x+sublayer(x))</li>
</ul>
</li>
</ul>
</li>
<li>Layer Normalization<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108466502-19b0af00-72c7-11eb-9d9f-6e85d7c9dd15.png" alt="image-20210218213709260"></li>
<li>평균0 분산1으로 만듦</li>
<li>step1: 각 단어 vector를 평균0 분산1이되도록 normalization</li>
<li>step2: Affine transformation?</li>
</ul>
</li>
<li>Positional Encoding<ul>
<li>순서를 무시</li>
<li>따라서 순서 정보를 포함 시킴</li>
<li>상수vector를 입력vector에 더해줌(주기함수 사용)</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108466494-17e6eb80-72c7-11eb-80ec-dfd431ba890e.png" alt="image-20210218115117713"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108466498-187f8200-72c7-11eb-849e-7ffa7a227617.png" alt="image-20210218115135167"></li>
</ul>
</li>
<li>Learning Rate Scheduling<ul>
<li>Learning Rate를 학습하면서 변화</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108466499-187f8200-72c7-11eb-8d1e-df1d203f915f.png" alt="image-20210218115458743"></li>
</ul>
</li>
<li>Decoder<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108466534-203f2680-72c7-11eb-819b-d88eac10abd3.png" alt="image-20210219152619612"></li>
<li>디코더에서 만든 hidden state vector가 query로 사용<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108466500-19181880-72c7-11eb-864f-d78c2193c45a.png" alt="image-20210218120258199"></li>
</ul>
</li>
<li>Masked Self attention<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108466501-19181880-72c7-11eb-8131-f2448eb66a62.png" alt="image-20210218120848978"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Further-Question"><a href="#Further-Question" class="headerlink" title="Further Question"></a><strong>Further Question</strong></h2><ul>
<li>Attention은 이름 그대로 어떤 단어의 정보를 얼마나 가져올 지 알려주는 직관적인 방법처럼 보입니다. Attention을 모델의 Output을 설명하는 데에 활용할 수 있을까요?</li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/18/BoostCamp/Day18/"><img class="fill" src="/img/boostcamp.png" alt="Day18"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-17T16:42:43.000Z" title="2021-2-18 1:42:43 ├F10: AM┤">2021-02-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:31:18.011Z" title="2021-3-22 6:31:18 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">6 minutes read (About 916 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/18/BoostCamp/Day18/">Day18</a></h1><div class="content"><h1 id="seq2seq-Model"><a href="#seq2seq-Model" class="headerlink" title="seq2seq Model"></a>seq2seq Model</h1><ul>
<li>many to many</li>
<li>인코더와 디코더로 구성</li>
<li>인코더의 마지막 hidden state vector는 디코더의 $h_0$로 사용</li>
<li>디코더에서 첫번쨰 단어로 <SOS> 를 넣어주고 <EOS>나올떄까지 실행</li>
<li>With attention<ul>
<li>정보의 유살때문</li>
<li>인코더의 마지막 hidden state vector하나만 사용하는 것이 아닌 각각 인코더의 hidden state vector 사용</li>
<li>$h^e_1, h^e_2…$</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236943-c9cccd80-718a-11eb-815f-6be934b9f651.png" alt="image-20210217095144796"></li>
<li>Attention output vector: 인코더의 hidden state vector의 가중평균</li>
<li>디코더의 hidden state vector의 2가지 역할<ul>
<li>output layer(다음단어)의 입력</li>
<li>인코더의 hidden state vector중 어떤걸 중점적으로 할지 결정</li>
</ul>
</li>
<li>디코더의 각 timestep에서의 입력은 Ground-truth<ul>
<li>전 단계에서 잘못 예측하더라도 Ground-truth에서 올바른 입력을 넣어줌</li>
<li>Teacher forcing</li>
<li>실제 사용 환경에서 괴리가 있을 수 있다.</li>
</ul>
</li>
<li>학습의 후반부에 예측한 값을 입력으로 줄 수 있다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236946-ca656400-718a-11eb-9a15-93567c02db28.png" alt="image-20210217100915952"></li>
</ul>
</li>
</ul>
<h2 id="Different-Attention-Mechanism"><a href="#Different-Attention-Mechanism" class="headerlink" title="Different Attention Mechanism"></a>Different Attention Mechanism</h2><p>디코더의 hidden state와 인코더의 hidden state와의 유사도를 구하는 다양한 방법</p>
<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236947-cafdfa80-718a-11eb-88e5-a470733c536c.png" alt="image-20210217101552323"></li>
<li>general<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236949-cafdfa80-718a-11eb-8959-4d3663a9a5c1.png" alt="image-20210217102018234"></li>
</ul>
</li>
<li>concat<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236951-cb969100-718a-11eb-81c3-cd81f7822798.png" alt="image-20210217102039870"></li>
</ul>
</li>
</ul>
<h2 id="Attention-is-Great"><a href="#Attention-is-Great" class="headerlink" title="Attention is Great"></a>Attention is Great</h2><ul>
<li><p>기계번역 성능 향상</p>
</li>
<li><p>information bottleneck problem 해결</p>
</li>
<li><p>Gradien vanishing 해결</p>
<ul>
<li>많은 timestep을 거치지 않고 지름길이 만들어짐</li>
<li>backpropagation</li>
</ul>
</li>
<li><p>해석가능성 제공</p>
<ul>
<li>디코더가 인코더상의 어떤단어에 집중했는지 알 수 있다.</li>
</ul>
<hr>
</li>
</ul>
<h1 id="Beam-search"><a href="#Beam-search" class="headerlink" title="Beam search"></a>Beam search</h1><ul>
<li>Greedy decoding<ul>
<li>근시안적인 문제점</li>
<li>잘못생성 시 돌아갈 수 없음</li>
</ul>
</li>
<li>Exhaustive search<ul>
<li>joint probability</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236956-cb969100-718a-11eb-915a-dfc9032822ad.png" alt="image-20210217104450239"></li>
<li>$O(v^t)$</li>
</ul>
</li>
<li>Greedy와 Exhaustive search의 중간</li>
<li>아이디어: 디코더의 timestemp마다 정해진 k개의 가능한 가지 수 고려, beam size</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236962-ccc7be00-718a-11eb-9bdb-6d7f079896d7.png" alt="image-20210217104856537"></li>
<li>Beam size=2<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236966-cd605480-718a-11eb-8acc-e01ad7b98c31.png" alt="image-20210217105235457"></li>
</ul>
</li>
<li>beam search의 디코딩 과정에서는 서로 다른 경로(hypotheses)가 존재하고 각각 다른 시점에서 <END>생성</li>
<li><END>가 생성되면 그 경로는 종료 후 저장</li>
<li>Stop criterion</li>
<li>time step T</li>
<li>least n completed hypotheses</li>
<li>종료 후 완료된 hypotheses들 중 가장 높은 점수를 고른다</li>
<li>문제점<ul>
<li>길이가 길수록 점수가 낮다</li>
<li>Fix: normalize by length<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236968-cd605480-718a-11eb-9357-7d27d3ea10ff.png" alt="image-20210217105749971"></li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h1 id="BLEU-score"><a href="#BLEU-score" class="headerlink" title="BLEU score"></a>BLEU score</h1><p><img src="https://user-images.githubusercontent.com/46857207/108236983-d05b4500-718a-11eb-8af3-bbf831721a32.png" alt="image-20210218013321022"></p>
<p>문제점: 생성된 문장 전체를 비교하는 것이 아니라 고정된 위치의 단어 하나가 나와야 된다는 평가방식</p>
<ul>
<li>precision and recall<ul>
<li>precision: 예측된 결과가 노출되었을 때 실질적으로 느끼는 정확도 ex) 검색결과</li>
<li>recall: 노출되어야 할 것들 중 실제 노출된 것</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236972-cdf8eb00-718a-11eb-822d-a21b3b750c80.png" alt="image-20210217111025148"></li>
<li>F-measure은 조화평균</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236977-cf2a1800-718a-11eb-8ec4-89f7588a0b56.png" alt="image-20210217111943692" style="zoom:33%;" /></li>
<li>순서가 맞지 않음에도 높은 값<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236979-cf2a1800-718a-11eb-8a37-3be3ff4273a0.png" alt="image-20210217112232392"></li>
</ul>
</li>
</ul>
</li>
<li>따라서 BLUE score (BiLingual Evaluation Understudy)<ul>
<li>N-gram<ul>
<li>연속된 n개의 단어로 봤을때 ground-truth와 얼마나 겹치는가</li>
<li>n: 1~4</li>
</ul>
</li>
<li>recall 무시<ul>
<li>어느정도 생략되어도 괜찮기 때문이다</li>
<li>recall이 높아도 명백한 오역이 될 수 있기 때문이다.</li>
</ul>
</li>
<li>기하평균<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236981-cfc2ae80-718a-11eb-8675-de6218c5537a.png" alt="image-20210217113014677" style="zoom:67%;" /></li>
<li>조화평균은 크기가 작은 값에 지나치게 큰 가중치를 준다</li>
<li>예측값이 아무리 길어도 1-&gt; recall도 고려</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236982-cfc2ae80-718a-11eb-81b5-8b71c8625a4e.png" alt="image-20210217113610766" style="zoom:67%;" /></li>
</ul>
</li>
</ul>
<h2 id="Further-Question"><a href="#Further-Question" class="headerlink" title="Further Question"></a><strong>Further Question</strong></h2><ul>
<li>BLEU score가 번역 문장 평가에 있어서 갖는 단점은 무엇이 있을까요?</li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/17/BoostCamp/Day17/"><img class="fill" src="/img/boostcamp.png" alt="Day17"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-17T06:14:12.000Z" title="2021-2-17 3:14:12 ├F10: PM┤">2021-02-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:31:13.066Z" title="2021-3-22 6:31:13 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">7 minutes read (About 998 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/17/BoostCamp/Day17/">Day17</a></h1><div class="content"><h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><p><img src="https://user-images.githubusercontent.com/46857207/108163635-b9890400-7132-11eb-8869-70f809e33298.png" alt="image-20210216094701936"></p>
<p>​ rolled unrolled</p>
<p><img src="https://user-images.githubusercontent.com/46857207/108163637-b9890400-7132-11eb-903b-e6fb18640070.png" alt="image-20210216095054455"></p>
<ul>
<li><p>$y_t$는 매 타임스텝마다 계산할 수도 있도 마지막 타임스텝에만 계산할 수도 있다.</p>
<ul>
<li>품사 분석 -&gt; 매 타임스텝</li>
<li>감정 분석-&gt; 마지막 타임스텝만</li>
</ul>
</li>
<li><p>parameter $W$ 를 공유</p>
<p><img src="https://user-images.githubusercontent.com/46857207/108163639-ba219a80-7132-11eb-8337-0ce9a043b85c.png" alt="image-20210216100449972"></p>
</li>
<li><p>RNN은 왜 tanh를 사용할까?</p>
<ul>
<li>RNN의 Vanishing gradient 문제를 예방하기 위해서 gradient가 <strong>최대한 오래 유지</strong>될 수 있도록 해주는 역할로 tanh가 적합하기 때문입니다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163629-b7bf4080-7132-11eb-920a-9313d930e90b.png" alt="image-20210217011912817"></li>
</ul>
</li>
</ul>
<h2 id="Types-of-RNNs"><a href="#Types-of-RNNs" class="headerlink" title="Types of RNNs"></a>Types of RNNs</h2><ul>
<li>one to one<ul>
<li>standard neural networdk</li>
</ul>
</li>
<li>one to many<ul>
<li>image captionning</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163642-ba219a80-7132-11eb-9d87-0de4bb10bfac.png" alt="image-20210216101013657"></li>
<li>추가적인 입력이 없는 경우 같은 사이즈의 텐서가 들어가되 모두 0으로 채워짐</li>
</ul>
</li>
<li>many to one<ul>
<li>sentiment classification</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163643-baba3100-7132-11eb-8464-232cd2a5fac7.png" alt="image-20210216101315213"></li>
<li>입력의 길이에 따라 RNN cell 확장</li>
</ul>
</li>
<li>many to many<ul>
<li>입력과 출력 모두 sequence</li>
<li>machine translation<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163644-baba3100-7132-11eb-83cc-8fac0e1bf39d.png" alt="image-20210216101450667"></li>
</ul>
</li>
<li>video classification on frame level, pos태깅<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163645-bb52c780-7132-11eb-8bc8-e5393af916b5.png" alt="image-20210216101638717"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="Character-level-Language-Model"><a href="#Character-level-Language-Model" class="headerlink" title="Character level Language Model"></a>Character level Language Model</h1><p><img src="https://user-images.githubusercontent.com/46857207/108163647-bb52c780-7132-11eb-962e-46d38a562187.png" alt="image-20210216101829762"></p>
<ul>
<li>다음 단어를 예측해야함</li>
<li>$h_0$는 0으로 초기화된 값<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163653-bc83f480-7132-11eb-8b31-e26f97e924f7.png" alt="image-20210216102301975"></li>
</ul>
</li>
<li>output layer에 softmax적용</li>
<li>예측값을 다음 타임스텝의 입력으로 넣어줌</li>
<li>ex) 주식가격<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163655-bd1c8b00-7132-11eb-8f91-2d6e2c592c85.png" alt="image-20210216103134380"></li>
</ul>
</li>
<li>셰익스피어의 희곡 학습<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163656-bd1c8b00-7132-11eb-8a44-5515fff9903e.png" alt="image-20210216103325591"></li>
</ul>
</li>
<li>초반에는 의미없는 값 생성<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163657-bdb52180-7132-11eb-912a-75aff9287214.png" alt="image-20210216103435740"></li>
</ul>
</li>
<li>논문 작성 Latex사용</li>
<li>코드 작성</li>
</ul>
<h2 id="Character-level-Language-Model의-학습-과정"><a href="#Character-level-Language-Model의-학습-과정" class="headerlink" title="Character level Language Model의 학습 과정"></a>Character level Language Model의 학습 과정</h2><ul>
<li>Backpropagation throgh time</li>
<li>sequence를 잘라서 학습(truncation)<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163659-be4db800-7132-11eb-8044-834ce5a913c7.png" alt="image-20210216104331347"></li>
<li>RNN에서 필요한 정보를 저장하는 공간은 hidden state vector</li>
<li>hidden state vector 각각의 차원 한개를 고정하고 그 값이 진행됨에 따라서 어떻게 변하는지 분석한다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163661-bee64e80-7132-11eb-84be-e99308de435f.png" alt="image-20210216104710761"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163662-bf7ee500-7132-11eb-802b-77728076e855.png" alt="image-20210216104811189"></li>
<li>특정 dimension(cell)의 역활(따옴표)<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163663-bf7ee500-7132-11eb-8e12-c064085fdd68.png" alt="image-20210216104958945"></li>
</ul>
</li>
<li>if조건문<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163667-c0177b80-7132-11eb-9f86-481374b2be13.png" alt="image-20210216105202357"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Vanilla RNN에서는 Vanishing/Exploding Gradient problem 발생<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163632-b857d700-7132-11eb-9009-1cdb8ef000b5.png" alt="image-20210217021957663"></li>
</ul>
</li>
</ul>
<h1 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h1><ul>
<li>Vanishing/Exploding Gradient 해결</li>
<li>타임스텝이 멀어져도 효과적</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163674-c0b01200-7132-11eb-9be7-3fe0f24f100b.png" alt="image-20210216111926346"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163677-c148a880-7132-11eb-8792-16dfb7890d77.png" alt="image-20210216112339995"></li>
<li>Forget gate<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163678-c148a880-7132-11eb-9e4e-49b691cfaa37.png" alt="image-20210216113442287"></li>
</ul>
</li>
<li>Gate gate<ul>
<li>$i_t$를 곱해주는 것은 $C_{t-1}$에 더해줄 정보에서 값을 덜어내는것</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163684-c279d580-7132-11eb-85cc-e0d178c9ef5a.png" alt="image-20210216113709586"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163682-c1e13f00-7132-11eb-9576-78499ca764e1.png" alt="image-20210216113612505"></li>
</ul>
</li>
<li>$h_t$<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163685-c279d580-7132-11eb-93f9-156ef7414b0b.png" alt="image-20210216114114206"></li>
</ul>
</li>
<li>$C_t$: 기억해야할 모든 정보</li>
<li>$h_t$: output layer의 입력으로 사용, $C_t$에서 당장 필요한 정보만 필터링</li>
</ul>
<h2 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h2><ul>
<li>cell state와 hidden state 합침<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163687-c3126c00-7132-11eb-91da-5d6596c3fe63.png" alt="image-20210216115107357"></li>
</ul>
</li>
<li>계산량, 메모리 요구량 줄임<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163624-b5f57d00-7132-11eb-867a-548521f76b84.png" alt="image-20210216120027992"></li>
</ul>
</li>
<li>input gate가 커질수록 forget gate 작아짐</li>
</ul>
<h2 id="LSTM-GRU-backpropagation"><a href="#LSTM-GRU-backpropagation" class="headerlink" title="LSTM,GRU backpropagation"></a>LSTM,GRU backpropagation</h2><ul>
<li>곱해주는 것이 아닌 필요한 정보를 더하여 vanishing 해결<ul>
<li>멀리있는 타임스텝까지 gradient 변형없이 전달</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163625-b726aa00-7132-11eb-94c7-76d2ed0ac75d.png" alt="image-20210216120411669"></li>
</ul>
</li>
</ul>
<h2 id="Further-Question"><a href="#Further-Question" class="headerlink" title="Further Question"></a>Further Question</h2><ul>
<li>BPTT 이외에 RNN/LSTM/GRU의 구조를 유지하면서 gradient vanishing/exploding 문제를 완화할 수 있는 방법이 있을까요?</li>
<li>RNN/LSTM/GRU 기반의 Language Model에서 초반 time step의 정보를 전달하기 어려운 점을 완화할 수 있는 방법이 있을까요?</li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/16/BoostCamp/Day16/"><img class="fill" src="/img/boostcamp.png" alt="Day16"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-15T17:47:35.000Z" title="2021-2-16 2:47:35 ├F10: AM┤">2021-02-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:31:08.620Z" title="2021-3-22 6:31:08 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">3 minutes read (About 387 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/16/BoostCamp/Day16/">Day16</a></h1><div class="content"><h2 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h2><ul>
<li>Low level<ul>
<li>Tokenizaition, stemming(형태소 분석)</li>
</ul>
</li>
<li>Word and Phase level<ul>
<li>Named entity recognition(NER)-&gt;고유명사 ex)new york times</li>
<li>part-of-speech(POS) tagging-&gt;성분 분석(명사,형용사)</li>
</ul>
</li>
<li>Sentence level<ul>
<li>Sentiment , machine translation</li>
</ul>
</li>
<li>Multi-sentence and paragraph level<ul>
<li>Entailment prediction(문장간 논리), question answering(where did napoleon die?), dialog system(chatbot), summarization</li>
</ul>
</li>
</ul>
<h2 id="Text-mining"><a href="#Text-mining" class="headerlink" title="Text mining"></a>Text mining</h2><ul>
<li>트렌드 분석</li>
<li>clustering (topic modeling)</li>
<li>highly related to computational social science (SNS)</li>
<li>KDD, The WebConf</li>
</ul>
<h2 id="Information-retreival-검색"><a href="#Information-retreival-검색" class="headerlink" title="Information retreival(검색)"></a>Information retreival(검색)</h2><ul>
<li>highly related to computation social science</li>
<li>recommendation system</li>
</ul>
<h2 id="Trends-of-NLP"><a href="#Trends-of-NLP" class="headerlink" title="Trends of NLP"></a>Trends of NLP</h2><ul>
<li>each word can be represented as a vector (Word2Vec or GloVe)</li>
<li>RNN (LSTM, GRUs)</li>
<li>attention ,transformer</li>
<li>in early days, customized models for different NLP tasks</li>
<li>self-supervised-&gt;BERT, GPT-3</li>
</ul>
<h2 id="Bag-of-Words"><a href="#Bag-of-Words" class="headerlink" title="Bag-of-Words"></a>Bag-of-Words</h2><ul>
<li>step1<ul>
<li>중복단어 제거</li>
<li><img src="https://user-images.githubusercontent.com/46857207/107979188-77ac7080-7001-11eb-9c0b-76c04b31312e.png" alt="image-20210215141338130"></li>
</ul>
</li>
<li>step2<ul>
<li>encodng unique words to one-hot vectors</li>
<li>distance is $\sqrt2$</li>
<li>cosine is 0</li>
<li>sentence can be represented as sum of one-hot vectors<ul>
<li>john really really loves this movie</li>
<li>[1 2 1 1 1 0 0 0]</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="NaiveBayes-Classifier"><a href="#NaiveBayes-Classifier" class="headerlink" title="NaiveBayes Classifier"></a>NaiveBayes Classifier</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/107979190-78dd9d80-7001-11eb-97b3-7547b6a5303e.png" alt="image-20210215141542496"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/107979191-78dd9d80-7001-11eb-8486-b223740aac49.png" alt="image-20210215142142512"></li>
</ul>
<h1 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h1><ul>
<li>Express a word as a vector</li>
<li>Same relationship is represented as the same vectors</li>
</ul>
<h2 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h2><ul>
<li><p>인접한 단어들간의 의미가 비슷할 것이다<br><img src="https://user-images.githubusercontent.com/46857207/107979194-79763400-7001-11eb-917b-492bc318e730.png" alt="image-20210215142907516"><br><img src="https://user-images.githubusercontent.com/46857207/108026170-2cc74300-706b-11eb-84be-93a7d18ce7d6.png" alt="image-20210216145150869"><br>-word간의 의미관계를 vector로 잘 표현<br><img src="https://user-images.githubusercontent.com/46857207/108026172-2df87000-706b-11eb-952e-b379798f6f60.png" alt="image-20210216145438632"></p>
</li>
<li><p>Intrusion Detection</p>
<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/107979195-7a0eca80-7001-11eb-9994-73feffc6ae30.png" alt="image-20210215145010841"></li>
</ul>
</li>
<li>application<ul>
<li>translation</li>
<li>sentiment analysis</li>
<li>image captioning</li>
</ul>
</li>
</ul>
<h2 id="GloVe"><a href="#GloVe" class="headerlink" title="GloVe"></a>GloVe</h2><ul>
<li>중복되는 계산을 줄여 빠름<br><img src="https://user-images.githubusercontent.com/46857207/107979198-7aa76100-7001-11eb-9c2e-79d0a08c4fd4.png" alt="image-20210215145143880"></li>
</ul>
<h1 id="Word2Vec-2가지-CBOW-vs-skip-gram"><a href="#Word2Vec-2가지-CBOW-vs-skip-gram" class="headerlink" title="Word2Vec 2가지 CBOW vs skip-gram"></a>Word2Vec 2가지 CBOW vs skip-gram</h1><h2 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108026175-2e910680-706b-11eb-9bb2-3b5c2639aceb.png" alt="image-20210216152106543"></li>
</ul>
<h2 id="skip-gram"><a href="#skip-gram" class="headerlink" title="skip-gram"></a>skip-gram</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108026177-2e910680-706b-11eb-81d8-fdc71fae4bbb.png" alt="image-20210216152158739"></li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/05/BoostCamp/Day15/"><img class="fill" src="/img/boostcamp.png" alt="Day15"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-05T14:59:57.000Z" title="2021-2-5 11:59:57 ├F10: PM┤">2021-02-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:31:03.890Z" title="2021-3-22 6:31:03 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">3 minutes read (About 390 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/05/BoostCamp/Day15/">Day15</a></h1><div class="content"><h1 id="Generative-Models"><a href="#Generative-Models" class="headerlink" title="Generative Models"></a>Generative Models</h1><p>What does it mean to learn a generative model?</p>
<ul>
<li>Generation-&gt;sampling</li>
<li>Densitiy estimation :$p(x)$ should be high if x looks like dog-&gt;explicit models</li>
<li>unsuperviesd representation learning-&gt; feature learning</li>
</ul>
<p>How can we represent $p(x)$</p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050020-21278100-680e-11eb-92a9-a3adb313d298.png" alt="image-20210205094249672"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050025-2258ae00-680e-11eb-82d4-2517b8755db7.png" alt="image-20210205094351518"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050030-22f14480-680e-11eb-964a-02f853cf812e.png" alt="image-20210205094844333"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050031-2389db00-680e-11eb-8c11-5e0d9879dc7e.png" alt="image-20210205094940765"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050032-2389db00-680e-11eb-8205-12196bd09085.png" alt="image-20210205100055253"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050034-24227180-680e-11eb-974f-f0e0016785f6.png" alt="image-20210205100106716"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050036-24227180-680e-11eb-842b-debab00521c9.png" alt="image-20210205100118955"></p>
<h2 id="Auto-regressive-Model"><a href="#Auto-regressive-Model" class="headerlink" title="Auto-regressive Model"></a>Auto-regressive Model</h2><p><img src="https://user-images.githubusercontent.com/46857207/107050037-24bb0800-680e-11eb-830d-f694fdc1ec24.png" alt="image-20210205100530278"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050041-25539e80-680e-11eb-872f-365a5ed7626a.png" alt="image-20210205100658091"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050043-25ec3500-680e-11eb-9b3c-78e7177df52d.png" alt="image-20210205100907226"></p>
<h2 id="Latent-Variable-Models"><a href="#Latent-Variable-Models" class="headerlink" title="Latent Variable Models"></a>Latent Variable Models</h2><p><img src="https://user-images.githubusercontent.com/46857207/107050046-25ec3500-680e-11eb-9291-8c84ebdb0309.png" alt="image-20210205101420955"></p>
<ul>
<li>posterior distribution을 근사할 수 있는 variational distribution을 찾는 것</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/46857207/107050048-2684cb80-680e-11eb-82a9-00fe576352bf.png" alt="image-20210205101542409"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050050-271d6200-680e-11eb-80d6-ae8ad4607a59.png" alt="image-20210205101607611"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050051-27b5f880-680e-11eb-990a-e4565327e27c.png" alt="image-20210205101756220"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050053-27b5f880-680e-11eb-9a5b-f837870532e8.png" alt="image-20210205102126480"></p>
<ul>
<li>explicit하지 않다</li>
<li>reconstruction을 무엇을 해도 되지만 kl-divergence는 가우시안을 사용</li>
<li>isotropic gaussian</li>
<li>단점 : encoder를 활용할 떄 prior fitting term이 kl-divergence를 활용한다는 것</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/46857207/107050059-297fbc00-680e-11eb-916a-b09c38247a78.png" alt="image-20210205102436950"></p>
<h2 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h2><ul>
<li>장점 : discriminator가 점차 좋아진다</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/46857207/107050065-2a185280-680e-11eb-9485-d535e17f3b15.png" alt="image-20210205102802203"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050070-2b497f80-680e-11eb-9730-b73397782eaa.png" alt="image-20210205102852993"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050073-2be21600-680e-11eb-9f98-228660c05c40.png" alt="image-20210205102919069"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050074-2c7aac80-680e-11eb-930c-5869e865a5f0.png" alt="image-20210205103059164"></p>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/04/BoostCamp/Day14/"><img class="fill" src="/img/boostcamp.png" alt="Day14"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-04T13:51:23.000Z" title="2021-2-4 10:51:23 ├F10: PM┤">2021-02-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:30:58.923Z" title="2021-3-22 6:30:58 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">6 minutes read (About 867 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/04/BoostCamp/Day14/">Day14</a></h1><div class="content"><h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><ul>
<li>시계열, sequence 데이터</li>
<li>독립동등분포를 잘 위배한다. ex) 개가사람을 문다. 사람이 개를 문다. 앞뒤 문맥없이 예측하는 것은 힘들다.</li>
<li>데이터의 위치를 함부로 바꾸면 안됨</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901722-72b30b80-673b-11eb-92d7-80b969e81471.png" alt="image-20210204094406393"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901727-73e43880-673b-11eb-84e5-05edcec3fdb5.png" alt="image-20210204094434202"></li>
<li>모든 데이터가 필요한건 아니다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901731-747ccf00-673b-11eb-859d-5b69e091722b.png" alt="image-20210204094819995"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901736-75adfc00-673b-11eb-8cad-fa2d8281da3d.png" alt="image-20210204094855480"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901744-7777bf80-673b-11eb-8d60-690c306189c4.png" alt="image-20210204095002305"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901751-78105600-673b-11eb-816c-f2b1876cca5c.png" alt="image-20210204095025761"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901760-79418300-673b-11eb-9343-16a10843ed7a.png" alt="image-20210204095433338"></li>
<li>위 MLP는 과거의 정보를 다룰 수 없다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901773-7a72b000-673b-11eb-98b8-f1f8eb25687c.png" alt="image-20210204095645274"></li>
<li>가중치 3개 wx1 wh1 w2 ,이것은 t에 따라 변하지 않는다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901783-7ba3dd00-673b-11eb-8db4-5482558e875d.png" alt="image-20210204100018906"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901789-7c3c7380-673b-11eb-88eb-c9d810cba0c9.png" alt="image-20210204100225637"></li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/106901794-7cd50a00-673b-11eb-99e8-35b303c2ce2d.png" alt="image-20210204100409392"></p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/106901799-7e063700-673b-11eb-9692-8500d6119ca9.png" alt="image-20210204101844368"></p>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901802-7e9ecd80-673b-11eb-92dd-5837485cb685.png" alt="image-20210204101913542"><ul>
<li>ex) 내읠 시험 전수는 전날에만 의존한다.</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901804-7f376400-673b-11eb-9677-1ed76b13901d.png" alt="image-20210204102028533"><ul>
<li>중간 hidden state-&gt; 과거의 정보를 요약</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901808-7fcffa80-673b-11eb-9089-4d2c98c62df1.png" alt="image-20210204102325047"><ul>
<li>과거의 정보가 미래까지 살아남기 힘듦</li>
<li>한참 전의 step은 소실</li>
<li>문장이 길어져도 이전의 정보를 고려해야 하는데 그러지 못한다.</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901810-80689100-673b-11eb-9dbe-2f149076283a.png" alt="image-20210204102433119"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901817-83638180-673b-11eb-881d-0306a1dff17f.png" alt="image-20210204102448702"><ul>
<li>activation $\phi$가 sigmoid라면 $h_0$는 의미가 없어지게 된다. Relu를 써도 마찬가지</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901825-8494ae80-673b-11eb-8e3b-9bc0ecc990e3.png" alt="image-20210204102823959"><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106901826-85c5db80-673b-11eb-9dd2-d139df3907c7.png" alt="image-20210204103242662"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901833-878f9f00-673b-11eb-8033-08e4d9f8f0fe.png" alt="image-20210204103306148"><ul>
<li>forget gate: $f_t$는 0~1값 -&gt;이전 cell state에서 어떤걸 버리고 살릴지 결정</li>
<li>input gate: 어떤 정보를 올릴지 결정</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901836-88c0cc00-673b-11eb-9fc6-879a6d89b21a.png" alt="image-20210204103317655"></li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901841-89f1f900-673b-11eb-9789-0ac296027bd7.png" alt="image-20210204103928535"></li>
</ul>
<h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><p><img src="https://user-images.githubusercontent.com/46857207/106901848-8b232600-673b-11eb-8150-5fee83bd984e.png" alt="image-20210204111351566"></p>
<ul>
<li>n개의 단어가 어떻게 한번에 처리되는지</li>
<li>인코더와 디코더 사이의 어떤 정보를 주고 받는지</li>
<li>디코더가 어떻게 generation하는지</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/46857207/106901853-8c545300-673b-11eb-8a4d-b6f0c36dfb96.png" alt="image-20210204112433262"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901859-8d858000-673b-11eb-94aa-884a5eda2f7d.png" alt="image-20210204112521419"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901862-8e1e1680-673b-11eb-8b40-bf5a835e381f.png" alt="image-20210204112626279"></p>
<hr>
<p><img src="https://user-images.githubusercontent.com/46857207/106901867-8f4f4380-673b-11eb-9e07-71b1fba3367f.png" alt="image-20210204112721207"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901872-8fe7da00-673b-11eb-8b7c-a1e240eda4e8.png" alt="image-20210204112809814"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901875-91190700-673b-11eb-8cdb-3ffdf712ae25.png" alt="image-20210204112904451"></p>
<hr>
<p><img src="https://user-images.githubusercontent.com/46857207/106901879-924a3400-673b-11eb-9420-0241c6a37f94.png" alt="image-20210204112925104"></p>
<hr>
<p><img src="https://user-images.githubusercontent.com/46857207/106901883-92e2ca80-673b-11eb-8927-72aa1af7862a.png" alt="image-20210204112944147"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901893-94ac8e00-673b-11eb-9d2c-8a1892c5e982.png" alt="image-20210204113601502"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901901-95ddbb00-673b-11eb-9c60-28133dda215c.png" alt="image-20210204113621666"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901906-95ddbb00-673b-11eb-9f5b-64554a478bd8.png" alt="image-20210204113634221"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901908-96765180-673b-11eb-802f-a2f0fadf5704.png" alt="image-20210204113749880"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901911-970ee800-673b-11eb-91a0-bd13ef7fe00c.png" alt="image-20210204114029713"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901912-97a77e80-673b-11eb-9ada-6c779a48ab57.png" alt="image-20210204114050371"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901913-97a77e80-673b-11eb-9784-7de9b2d475b6.png" alt="image-20210204114134036"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901919-98d8ab80-673b-11eb-9f84-3318618aafb2.png" alt="image-20210204114152577"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901922-99714200-673b-11eb-8cd0-93d0b53eba59.png" alt="image-20210204114234253"></p>
<ul>
<li>bias</li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/03/BoostCamp/Day13/"><img class="fill" src="/img/boostcamp.png" alt="Day13"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-03T13:54:13.000Z" title="2021-2-3 10:54:13 ├F10: PM┤">2021-02-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:30:54.577Z" title="2021-3-22 6:30:54 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">6 minutes read (About 967 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/03/BoostCamp/Day13/">Day13</a></h1><div class="content"><h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106756398-9c543000-6672-11eb-8dce-832ee2926a95.png" alt="image-20210203093748791"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756403-9d855d00-6672-11eb-9b63-c284f48e68c1.png" alt="image-20210203093815981"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756405-9e1df380-6672-11eb-8576-9aa8e192c38f.png" alt="image-20210203093950124"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756407-9eb68a00-6672-11eb-9ed2-fe9111cc7b80.png" alt="image-20210203094233167"></li>
<li>fully connected 없어지는 추세이다<ul>
<li>parameter의 숫자를 줄이기 위해</li>
</ul>
</li>
<li>Stride</li>
<li>Padding</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756411-9eb68a00-6672-11eb-9c08-39472dc017e9.png" alt="image-20210203095453596"></li>
<li>dense layer의 parameter가 많은 이유는 각각의 커널이 모두 적용되기 때문이다.<ul>
<li>parameter를 줄이는 것이 중요-&gt;1x1 convolution</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756414-9f4f2080-6672-11eb-9517-204f5c2e62f4.png" alt="image-20210203095710439"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756418-9fe7b700-6672-11eb-99c1-5725b9c8bfec.png" alt="image-20210203102945124"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756421-a0804d80-6672-11eb-9338-024a041186dd.png" alt="image-20210203103211807"><ul>
<li>11x11 커널은 좋은것은 아니다</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756423-a118e400-6672-11eb-9b55-7a017814ffd3.png" alt="image-20210203103301071"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756428-a118e400-6672-11eb-85e6-6d03b26690cf.png" alt="image-20210203103527759"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756432-a1b17a80-6672-11eb-960b-6b385337189c.png" alt="image-20210203103600510"><ul>
<li>3x3만 사용</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756433-a1b17a80-6672-11eb-94f3-61b8e4a40e16.png" alt="image-20210203103657860"></li>
<li>3x3과 5x5는 receptive field 차원에서는 똑같지만 parameter의 수는 다르다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756435-a24a1100-6672-11eb-911d-b170476343d2.png" alt="image-20210203104045528"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756436-a24a1100-6672-11eb-81ef-fdfdcd07a6f0.png" alt="image-20210203104127907"></li>
<li>인셉션 블록<ul>
<li>여러개의 response를 concatenate하는 효과도 있지만 1x1을 사용함으로써 param수를 줄일 수 있게 된다.</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756438-a2e2a780-6672-11eb-9348-f6fe4a325442.png" alt="image-20210203104319622"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756440-a37b3e00-6672-11eb-8c2b-06e9efe7a9c8.png" alt="image-20210203104609192"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756442-a37b3e00-6672-11eb-8923-e2fdc8b94efb.png" alt="image-20210203104711251"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756445-a413d480-6672-11eb-94d7-aa5c9e530f78.png" alt="image-20210203104859944"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756448-a413d480-6672-11eb-81fe-c9e9752e28c0.png" alt="image-20210203105039998"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756451-a4ac6b00-6672-11eb-9481-13914144d4d9.png" alt="image-20210203105117353"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756453-a4ac6b00-6672-11eb-9f81-482d6e43eb24.png" alt="image-20210203105144072"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756455-a5450180-6672-11eb-9a76-114691240750.png" alt="image-20210203105218644"><ul>
<li>3x3전에 input채널을 줄이고 3x3후에 output채널을 늘린다.</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756460-a5450180-6672-11eb-85fa-4bde9acc0058.png" alt="image-20210203105423758"><ul>
<li>resnet의 더하기 대신 concat</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756463-a5dd9800-6672-11eb-97ad-f2712aacc071.png" alt="image-20210203105456217"><ul>
<li>채널이 점점 커진다 -&gt; param수도 늘어남</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756465-a5dd9800-6672-11eb-9a46-6cd78a82be28.png" alt="image-20210203105526504"><ul>
<li>1x1을 사용해 transition block에서 줄인다</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756468-a6762e80-6672-11eb-8b7c-449516eed4eb.png" alt="image-20210203105629286"></li>
</ul>
<h1 id="Computer-Vision"><a href="#Computer-Vision" class="headerlink" title="Computer Vision"></a>Computer Vision</h1><h2 id="semantic-segmentation"><a href="#semantic-segmentation" class="headerlink" title="semantic segmentation"></a>semantic segmentation</h2><ul>
<li>pixel마다 분류</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756471-a70ec500-6672-11eb-9424-20134ccf06a6.png" alt="image-20210203110023247"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756474-a70ec500-6672-11eb-94f3-3ac893de0b19.png" alt="image-20210203110034830"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756477-a7a75b80-6672-11eb-8417-d5c46b5c4ba3.png" alt="image-20210203110919536"><ul>
<li>param수는 같다</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756481-a7a75b80-6672-11eb-8b40-765c9362a283.png" alt="image-20210203111927437"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756482-a83ff200-6672-11eb-9a41-9083f6f8086e.png" alt="image-20210203112140935"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756484-a83ff200-6672-11eb-82fc-1f2ba2ccce70.png" alt="image-20210203112212553"><ul>
<li>엄밀히 말하면 복원할 수는 없다.</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756488-a8d88880-6672-11eb-950f-5ed99d7bc1eb.png" alt="image-20210203112643710"></li>
</ul>
<h2 id="Detection-R-CNN"><a href="#Detection-R-CNN" class="headerlink" title="Detection R-CNN"></a>Detection R-CNN</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106756491-a9711f00-6672-11eb-8afd-79ab97f376ef.png" alt="image-20210203112922950"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756493-a9711f00-6672-11eb-9761-c831f4b9745a.png" alt="image-20210203112944571"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756494-aa09b580-6672-11eb-9303-00af8ba41fa5.png" alt="image-20210203113006424"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756497-aaa24c00-6672-11eb-8e4b-8d6274f13212.png" alt="image-20210203113150581"></li>
<li>바운딩 박스를 뽑는 것도 네트워크로 학습</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756498-aaa24c00-6672-11eb-9fb5-3cfce0920e33.png" alt="image-20210203113407684"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756500-ab3ae280-6672-11eb-86f1-e67ba1e9a76d.png" alt="image-20210203113440464"></li>
<li>RPN : 이미지로 특정 위치가 바운딩 박스로써 의미가 있을지 없을지 판단</li>
<li>물체가 무엇인지는 판단x</li>
<li>anchor boxes: 미리 정해놓은 바운딩 박스의 크기</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756502-abd37900-6672-11eb-8f78-8b0c29e2d5ae.png" alt="image-20210203113746175"><ul>
<li>size 3개 ration 3개 -&gt;9</li>
<li>width,height,x,y-&gt;4</li>
<li>해당 바운딩 박스가 쓸모있는지 없는지 -&gt;2</li>
</ul>
</li>
</ul>
<h2 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106756503-abd37900-6672-11eb-928c-c6e817ef9dbb.png" alt="image-20210203114056598"></li>
<li>한번에 분류</li>
<li>바운딩 박스를 뽑는 region propoasl이 없다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756506-ac6c0f80-6672-11eb-976d-7241d9b018ba.png" alt="image-20210203114400671"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756507-ac6c0f80-6672-11eb-93e4-2c29d3b9c37f.png" alt="image-20210203114433782"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756508-ad04a600-6672-11eb-9c0d-dc0a6af38a67.png" alt="image-20210203114459536"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756511-ad9d3c80-6672-11eb-8d07-79c6132ffd34.png" alt="image-20210203114510539"></li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/02/BoostCamp/Day12/"><img class="fill" src="/img/boostcamp.png" alt="Day12"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-02T14:15:26.000Z" title="2021-2-2 11:15:26 ├F10: PM┤">2021-02-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:30:49.132Z" title="2021-3-22 6:30:49 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">5 minutes read (About 709 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/02/BoostCamp/Day12/">Day12</a></h1><div class="content"><h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><h2 id="Generalization"><a href="#Generalization" class="headerlink" title="Generalization"></a>Generalization</h2><ul>
<li>일반화 성능을 높이는 것이 목적</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612385-69dfff80-65ac-11eb-9439-980189fda245.png" alt="image-20210202094729954"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612391-6a789600-65ac-11eb-8ca8-ec742ac7b76a.png" alt="image-20210202094827828"></li>
</ul>
<h2 id="Cross-validation-k-fold"><a href="#Cross-validation-k-fold" class="headerlink" title="Cross-validation(k fold)"></a>Cross-validation(k fold)</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612393-6b112c80-65ac-11eb-9b99-81345d272205.png" alt="image-20210202095010576"><ul>
<li>하이퍼 파라미터가 많이 존재하기 때문에(lr) cross-validation을 통해 최적의 하이퍼파라미터를 찾고 이를 고정시킨 상태에서 학습시킬 때는 모든 데이터를 사용</li>
</ul>
</li>
</ul>
<h2 id="Bias-and-variance"><a href="#Bias-and-variance" class="headerlink" title="Bias and variance"></a>Bias and variance</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612397-6b112c80-65ac-11eb-806f-f358ba57c760.png" alt="image-20210202095253714"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612399-6ba9c300-65ac-11eb-9cff-6a994f23080c.png" alt="image-20210202095334982"></li>
<li>학습데이터에 노이즈가 있을 경우 bias와 variance를 둘 다 줄이기는 힘들다</li>
</ul>
<h2 id="Boostrapping"><a href="#Boostrapping" class="headerlink" title="Boostrapping"></a>Boostrapping</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612400-6ba9c300-65ac-11eb-83df-dc1391a48eab.png" alt="image-20210202095706825"></li>
</ul>
<h2 id="Bagging-vs-Boosting"><a href="#Bagging-vs-Boosting" class="headerlink" title="Bagging vs Boosting"></a>Bagging vs Boosting</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612403-6c425980-65ac-11eb-9658-cc33fb4b0b30.png" alt="image-20210202095744157"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612405-6c425980-65ac-11eb-897c-f24b8ed5eda3.png" alt="image-20210202095957714"></li>
</ul>
<h1 id="Gradient-Descent-Methods"><a href="#Gradient-Descent-Methods" class="headerlink" title="Gradient Descent Methods"></a>Gradient Descent Methods</h1><p><img src="https://user-images.githubusercontent.com/46857207/106612407-6cdaf000-65ac-11eb-867c-96ec6eef286c.png" alt="image-20210202100022003"></p>
<h2 id="Batch-size-Matters"><a href="#Batch-size-Matters" class="headerlink" title="Batch-size Matters"></a>Batch-size Matters</h2><ul>
<li>배치 너무 크면 sharp minimizers 너무 작으면 flat minimizers</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612409-6cdaf000-65ac-11eb-8adf-87052d3ed18f.png" alt="image-20210202100221345"></li>
</ul>
<h2 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612410-6d738680-65ac-11eb-9066-68ce008ea357.png" alt="image-20210202100516783"></li>
</ul>
<h2 id="Nesterov-Accelerated-Gradient"><a href="#Nesterov-Accelerated-Gradient" class="headerlink" title="Nesterov Accelerated Gradient"></a>Nesterov Accelerated Gradient</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612412-6d738680-65ac-11eb-8fb0-c150c8462c84.png" alt="image-20210202100721271"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612414-6e0c1d00-65ac-11eb-98b2-cb56b4edc704.png" alt="image-20210202100801665"></li>
</ul>
<h2 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612415-6ea4b380-65ac-11eb-9299-1c40bfff7195.png" alt="image-20210202100949467"></li>
</ul>
<h2 id="Adadelta"><a href="#Adadelta" class="headerlink" title="Adadelta"></a>Adadelta</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612419-6f3d4a00-65ac-11eb-8267-bbb232edf400.png" alt="image-20210202101417140"></li>
</ul>
<h2 id="RMSporp"><a href="#RMSporp" class="headerlink" title="RMSporp"></a>RMSporp</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612421-6f3d4a00-65ac-11eb-836a-30e8f2c94ba0.png" alt="image-20210202101549058"></li>
</ul>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612423-6fd5e080-65ac-11eb-9d03-3786e44e723c.png" alt="image-20210202101719251"></li>
</ul>
<h1 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h1><p>학습데이터뿐만 아니라 테스트 데이터에도 잘 작동하도록 규제하는 것</p>
<ul>
<li>Early stopping<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612425-6fd5e080-65ac-11eb-9020-578d7c6e3660.png" alt="image-20210202102041270"></li>
</ul>
</li>
<li>parameter norm penalty<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612431-706e7700-65ac-11eb-99f6-1fbaf680a96c.png" alt="image-20210202102124376"></li>
<li>파라미터가 너무 크지 않게 하는 것</li>
</ul>
</li>
<li>Data augmentation<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612435-71070d80-65ac-11eb-98d5-fe14123bc0aa.png" alt="image-20210202102231187"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612441-72d0d100-65ac-11eb-8a6e-f55a932b4f0c.png" alt="image-20210202102316277"></li>
</ul>
</li>
<li>Noise robustness<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612447-7401fe00-65ac-11eb-8975-062214773ffe.png" alt="image-20210202102434701"></li>
</ul>
</li>
<li>Label smoothing<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612450-7401fe00-65ac-11eb-8077-2ae1857b6b86.png" alt="image-20210202102514810"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612465-76645800-65ac-11eb-90ea-13a9aebd57d6.png" alt="image-20210202102535614"></li>
</ul>
</li>
<li>Dropout<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612468-76fcee80-65ac-11eb-8e29-0e9d88f552be.png" alt="image-20210202102754838"></li>
</ul>
</li>
<li>Batch normalization<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612472-77958500-65ac-11eb-9d24-70850ceaf0e7.png" alt="image-20210202102858482"></li>
<li>Internal Covariate(feature) Shift를 줄인다</li>
<li>성능은 올라간다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612489-7cf2cf80-65ac-11eb-9a6a-8bd6f3617738.png" alt="image-20210202103046288"></li>
</ul>
</li>
</ul>
<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612492-7d8b6600-65ac-11eb-880f-699d2d5929f0.png" alt="image-20210202114306774"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612493-7e23fc80-65ac-11eb-9ee0-f9661a6e7266.png" alt="image-20210202114701974"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612494-7e23fc80-65ac-11eb-9b14-4f52767faca1.png" alt="image-20210202114913967"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612498-7ebc9300-65ac-11eb-8474-4dcae868648f.png" alt="image-20210202121512613"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612500-7f552980-65ac-11eb-9459-5df6876e97a1.png" alt="image-20210202121858772"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612501-7f552980-65ac-11eb-95cd-3aad9a9fdf37.png" alt="image-20210202122245445"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612503-7fedc000-65ac-11eb-9d00-475d81684f3c.png" alt="image-20210202122453543"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612504-7fedc000-65ac-11eb-9ece-be5f7ae67ae0.png" alt="image-20210202122539283"></li>
</ul>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/AI/page/2/">Previous</a></div><div class="pagination-next"><a href="/categories/AI/page/4/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/AI/">1</a></li><li><a class="pagination-link" href="/categories/AI/page/2/">2</a></li><li><a class="pagination-link is-current" href="/categories/AI/page/3/">3</a></li><li><a class="pagination-link" href="/categories/AI/page/4/">4</a></li><li><a class="pagination-link" href="/categories/AI/page/5/">5</a></li></ul></nav></div><div class="column column-left is-3-tablet is-3-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/./img/avatar.jpg" alt="Keonwoo Choi"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Keonwoo Choi</p><p class="is-size-6 is-block">blog</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Korea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">42</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/KeonwooChoi" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/KeonwooChoi"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">42</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI/BoostCamp/"><span class="level-start"><span class="level-item">BoostCamp</span></span><span class="level-end"><span class="level-item tag">41</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI/BoostCamp/Project-Stage/"><span class="level-start"><span class="level-item">Project Stage</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/AI/Pytorch/"><span class="level-start"><span class="level-item">Pytorch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-01T15:10:20.000Z">2021-04-02</time></p><p class="title"><a href="/2021/04/02/BoostCamp/Project%20Stage/Day44/">Day44</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a> / <a href="/categories/AI/BoostCamp/Project-Stage/">Project Stage</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-01T15:10:08.000Z">2021-04-02</time></p><p class="title"><a href="/2021/04/02/BoostCamp/Project%20Stage/Day43/">Day43</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a> / <a href="/categories/AI/BoostCamp/Project-Stage/">Project Stage</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-30T16:32:26.000Z">2021-03-31</time></p><p class="title"><a href="/2021/03/31/BoostCamp/Project%20Stage/Day42/">Day42-Augmentation</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a> / <a href="/categories/AI/BoostCamp/Project-Stage/">Project Stage</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-29T16:00:24.000Z">2021-03-30</time></p><p class="title"><a href="/2021/03/30/BoostCamp/Project%20Stage/Day41/">Day41-EDA</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a> / <a href="/categories/AI/BoostCamp/Project-Stage/">Project Stage</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-22T06:59:30.000Z">2021-03-22</time></p><p class="title"><a href="/2021/03/22/BoostCamp/Day40/">Day40</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">April 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/03/"><span class="level-start"><span class="level-item">March 2021</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/02/"><span class="level-start"><span class="level-item">February 2021</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">January 2021</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></div></div></div><!--!--></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">blog</a><p class="is-size-7"><span>&copy; 2021 Keonwoo Choi</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>