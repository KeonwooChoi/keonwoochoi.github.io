<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: AI - blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="blog"><meta name="msapplication-TileImage" content="./img/favicon3.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="blog"><meta property="og:url" content="https://keonwoochoi.github.io/"><meta property="og:site_name" content="blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://keonwoochoi.github.io/img/og_image.png"><meta property="article:author" content="Keonwoo Choi"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://keonwoochoi.github.io"},"headline":"blog","image":["https://keonwoochoi.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Keonwoo Choi"},"description":""}</script><link rel="icon" href="/./img/favicon3.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">blog</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-10-tablet is-10-desktop is-10-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">AI</a></li></ul></nav></div></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/18/BoostCamp/Day18/"><img class="fill" src="/img/boostcamp.png" alt="Day18"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-17T16:42:43.000Z" title="2021-2-18 1:42:43 ├F10: AM┤">2021-02-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:31:18.011Z" title="2021-3-22 6:31:18 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">6 minutes read (About 916 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/18/BoostCamp/Day18/">Day18</a></h1><div class="content"><h1 id="seq2seq-Model"><a href="#seq2seq-Model" class="headerlink" title="seq2seq Model"></a>seq2seq Model</h1><ul>
<li>many to many</li>
<li>인코더와 디코더로 구성</li>
<li>인코더의 마지막 hidden state vector는 디코더의 $h_0$로 사용</li>
<li>디코더에서 첫번쨰 단어로 <SOS> 를 넣어주고 <EOS>나올떄까지 실행</li>
<li>With attention<ul>
<li>정보의 유살때문</li>
<li>인코더의 마지막 hidden state vector하나만 사용하는 것이 아닌 각각 인코더의 hidden state vector 사용</li>
<li>$h^e_1, h^e_2…$</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236943-c9cccd80-718a-11eb-815f-6be934b9f651.png" alt="image-20210217095144796"></li>
<li>Attention output vector: 인코더의 hidden state vector의 가중평균</li>
<li>디코더의 hidden state vector의 2가지 역할<ul>
<li>output layer(다음단어)의 입력</li>
<li>인코더의 hidden state vector중 어떤걸 중점적으로 할지 결정</li>
</ul>
</li>
<li>디코더의 각 timestep에서의 입력은 Ground-truth<ul>
<li>전 단계에서 잘못 예측하더라도 Ground-truth에서 올바른 입력을 넣어줌</li>
<li>Teacher forcing</li>
<li>실제 사용 환경에서 괴리가 있을 수 있다.</li>
</ul>
</li>
<li>학습의 후반부에 예측한 값을 입력으로 줄 수 있다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236946-ca656400-718a-11eb-9a15-93567c02db28.png" alt="image-20210217100915952"></li>
</ul>
</li>
</ul>
<h2 id="Different-Attention-Mechanism"><a href="#Different-Attention-Mechanism" class="headerlink" title="Different Attention Mechanism"></a>Different Attention Mechanism</h2><p>디코더의 hidden state와 인코더의 hidden state와의 유사도를 구하는 다양한 방법</p>
<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236947-cafdfa80-718a-11eb-88e5-a470733c536c.png" alt="image-20210217101552323"></li>
<li>general<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236949-cafdfa80-718a-11eb-8959-4d3663a9a5c1.png" alt="image-20210217102018234"></li>
</ul>
</li>
<li>concat<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236951-cb969100-718a-11eb-81c3-cd81f7822798.png" alt="image-20210217102039870"></li>
</ul>
</li>
</ul>
<h2 id="Attention-is-Great"><a href="#Attention-is-Great" class="headerlink" title="Attention is Great"></a>Attention is Great</h2><ul>
<li><p>기계번역 성능 향상</p>
</li>
<li><p>information bottleneck problem 해결</p>
</li>
<li><p>Gradien vanishing 해결</p>
<ul>
<li>많은 timestep을 거치지 않고 지름길이 만들어짐</li>
<li>backpropagation</li>
</ul>
</li>
<li><p>해석가능성 제공</p>
<ul>
<li>디코더가 인코더상의 어떤단어에 집중했는지 알 수 있다.</li>
</ul>
<hr>
</li>
</ul>
<h1 id="Beam-search"><a href="#Beam-search" class="headerlink" title="Beam search"></a>Beam search</h1><ul>
<li>Greedy decoding<ul>
<li>근시안적인 문제점</li>
<li>잘못생성 시 돌아갈 수 없음</li>
</ul>
</li>
<li>Exhaustive search<ul>
<li>joint probability</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236956-cb969100-718a-11eb-915a-dfc9032822ad.png" alt="image-20210217104450239"></li>
<li>$O(v^t)$</li>
</ul>
</li>
<li>Greedy와 Exhaustive search의 중간</li>
<li>아이디어: 디코더의 timestemp마다 정해진 k개의 가능한 가지 수 고려, beam size</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236962-ccc7be00-718a-11eb-9bdb-6d7f079896d7.png" alt="image-20210217104856537"></li>
<li>Beam size=2<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236966-cd605480-718a-11eb-8acc-e01ad7b98c31.png" alt="image-20210217105235457"></li>
</ul>
</li>
<li>beam search의 디코딩 과정에서는 서로 다른 경로(hypotheses)가 존재하고 각각 다른 시점에서 <END>생성</li>
<li><END>가 생성되면 그 경로는 종료 후 저장</li>
<li>Stop criterion</li>
<li>time step T</li>
<li>least n completed hypotheses</li>
<li>종료 후 완료된 hypotheses들 중 가장 높은 점수를 고른다</li>
<li>문제점<ul>
<li>길이가 길수록 점수가 낮다</li>
<li>Fix: normalize by length<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236968-cd605480-718a-11eb-9357-7d27d3ea10ff.png" alt="image-20210217105749971"></li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h1 id="BLEU-score"><a href="#BLEU-score" class="headerlink" title="BLEU score"></a>BLEU score</h1><p><img src="https://user-images.githubusercontent.com/46857207/108236983-d05b4500-718a-11eb-8af3-bbf831721a32.png" alt="image-20210218013321022"></p>
<p>문제점: 생성된 문장 전체를 비교하는 것이 아니라 고정된 위치의 단어 하나가 나와야 된다는 평가방식</p>
<ul>
<li>precision and recall<ul>
<li>precision: 예측된 결과가 노출되었을 때 실질적으로 느끼는 정확도 ex) 검색결과</li>
<li>recall: 노출되어야 할 것들 중 실제 노출된 것</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236972-cdf8eb00-718a-11eb-822d-a21b3b750c80.png" alt="image-20210217111025148"></li>
<li>F-measure은 조화평균</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236977-cf2a1800-718a-11eb-8ec4-89f7588a0b56.png" alt="image-20210217111943692" style="zoom:33%;" /></li>
<li>순서가 맞지 않음에도 높은 값<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236979-cf2a1800-718a-11eb-8a37-3be3ff4273a0.png" alt="image-20210217112232392"></li>
</ul>
</li>
</ul>
</li>
<li>따라서 BLUE score (BiLingual Evaluation Understudy)<ul>
<li>N-gram<ul>
<li>연속된 n개의 단어로 봤을때 ground-truth와 얼마나 겹치는가</li>
<li>n: 1~4</li>
</ul>
</li>
<li>recall 무시<ul>
<li>어느정도 생략되어도 괜찮기 때문이다</li>
<li>recall이 높아도 명백한 오역이 될 수 있기 때문이다.</li>
</ul>
</li>
<li>기하평균<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108236981-cfc2ae80-718a-11eb-8675-de6218c5537a.png" alt="image-20210217113014677" style="zoom:67%;" /></li>
<li>조화평균은 크기가 작은 값에 지나치게 큰 가중치를 준다</li>
<li>예측값이 아무리 길어도 1-&gt; recall도 고려</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108236982-cfc2ae80-718a-11eb-81b5-8b71c8625a4e.png" alt="image-20210217113610766" style="zoom:67%;" /></li>
</ul>
</li>
</ul>
<h2 id="Further-Question"><a href="#Further-Question" class="headerlink" title="Further Question"></a><strong>Further Question</strong></h2><ul>
<li>BLEU score가 번역 문장 평가에 있어서 갖는 단점은 무엇이 있을까요?</li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/17/BoostCamp/Day17/"><img class="fill" src="/img/boostcamp.png" alt="Day17"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-17T06:14:12.000Z" title="2021-2-17 3:14:12 ├F10: PM┤">2021-02-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:31:13.066Z" title="2021-3-22 6:31:13 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">7 minutes read (About 998 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/17/BoostCamp/Day17/">Day17</a></h1><div class="content"><h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><p><img src="https://user-images.githubusercontent.com/46857207/108163635-b9890400-7132-11eb-8869-70f809e33298.png" alt="image-20210216094701936"></p>
<p>​ rolled unrolled</p>
<p><img src="https://user-images.githubusercontent.com/46857207/108163637-b9890400-7132-11eb-903b-e6fb18640070.png" alt="image-20210216095054455"></p>
<ul>
<li><p>$y_t$는 매 타임스텝마다 계산할 수도 있도 마지막 타임스텝에만 계산할 수도 있다.</p>
<ul>
<li>품사 분석 -&gt; 매 타임스텝</li>
<li>감정 분석-&gt; 마지막 타임스텝만</li>
</ul>
</li>
<li><p>parameter $W$ 를 공유</p>
<p><img src="https://user-images.githubusercontent.com/46857207/108163639-ba219a80-7132-11eb-8337-0ce9a043b85c.png" alt="image-20210216100449972"></p>
</li>
<li><p>RNN은 왜 tanh를 사용할까?</p>
<ul>
<li>RNN의 Vanishing gradient 문제를 예방하기 위해서 gradient가 <strong>최대한 오래 유지</strong>될 수 있도록 해주는 역할로 tanh가 적합하기 때문입니다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163629-b7bf4080-7132-11eb-920a-9313d930e90b.png" alt="image-20210217011912817"></li>
</ul>
</li>
</ul>
<h2 id="Types-of-RNNs"><a href="#Types-of-RNNs" class="headerlink" title="Types of RNNs"></a>Types of RNNs</h2><ul>
<li>one to one<ul>
<li>standard neural networdk</li>
</ul>
</li>
<li>one to many<ul>
<li>image captionning</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163642-ba219a80-7132-11eb-9d87-0de4bb10bfac.png" alt="image-20210216101013657"></li>
<li>추가적인 입력이 없는 경우 같은 사이즈의 텐서가 들어가되 모두 0으로 채워짐</li>
</ul>
</li>
<li>many to one<ul>
<li>sentiment classification</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163643-baba3100-7132-11eb-8464-232cd2a5fac7.png" alt="image-20210216101315213"></li>
<li>입력의 길이에 따라 RNN cell 확장</li>
</ul>
</li>
<li>many to many<ul>
<li>입력과 출력 모두 sequence</li>
<li>machine translation<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163644-baba3100-7132-11eb-83cc-8fac0e1bf39d.png" alt="image-20210216101450667"></li>
</ul>
</li>
<li>video classification on frame level, pos태깅<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163645-bb52c780-7132-11eb-8bc8-e5393af916b5.png" alt="image-20210216101638717"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="Character-level-Language-Model"><a href="#Character-level-Language-Model" class="headerlink" title="Character level Language Model"></a>Character level Language Model</h1><p><img src="https://user-images.githubusercontent.com/46857207/108163647-bb52c780-7132-11eb-962e-46d38a562187.png" alt="image-20210216101829762"></p>
<ul>
<li>다음 단어를 예측해야함</li>
<li>$h_0$는 0으로 초기화된 값<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163653-bc83f480-7132-11eb-8b31-e26f97e924f7.png" alt="image-20210216102301975"></li>
</ul>
</li>
<li>output layer에 softmax적용</li>
<li>예측값을 다음 타임스텝의 입력으로 넣어줌</li>
<li>ex) 주식가격<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163655-bd1c8b00-7132-11eb-8f91-2d6e2c592c85.png" alt="image-20210216103134380"></li>
</ul>
</li>
<li>셰익스피어의 희곡 학습<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163656-bd1c8b00-7132-11eb-8a44-5515fff9903e.png" alt="image-20210216103325591"></li>
</ul>
</li>
<li>초반에는 의미없는 값 생성<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163657-bdb52180-7132-11eb-912a-75aff9287214.png" alt="image-20210216103435740"></li>
</ul>
</li>
<li>논문 작성 Latex사용</li>
<li>코드 작성</li>
</ul>
<h2 id="Character-level-Language-Model의-학습-과정"><a href="#Character-level-Language-Model의-학습-과정" class="headerlink" title="Character level Language Model의 학습 과정"></a>Character level Language Model의 학습 과정</h2><ul>
<li>Backpropagation throgh time</li>
<li>sequence를 잘라서 학습(truncation)<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163659-be4db800-7132-11eb-8044-834ce5a913c7.png" alt="image-20210216104331347"></li>
<li>RNN에서 필요한 정보를 저장하는 공간은 hidden state vector</li>
<li>hidden state vector 각각의 차원 한개를 고정하고 그 값이 진행됨에 따라서 어떻게 변하는지 분석한다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163661-bee64e80-7132-11eb-84be-e99308de435f.png" alt="image-20210216104710761"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163662-bf7ee500-7132-11eb-802b-77728076e855.png" alt="image-20210216104811189"></li>
<li>특정 dimension(cell)의 역활(따옴표)<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163663-bf7ee500-7132-11eb-8e12-c064085fdd68.png" alt="image-20210216104958945"></li>
</ul>
</li>
<li>if조건문<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163667-c0177b80-7132-11eb-9f86-481374b2be13.png" alt="image-20210216105202357"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Vanilla RNN에서는 Vanishing/Exploding Gradient problem 발생<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163632-b857d700-7132-11eb-9009-1cdb8ef000b5.png" alt="image-20210217021957663"></li>
</ul>
</li>
</ul>
<h1 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h1><ul>
<li>Vanishing/Exploding Gradient 해결</li>
<li>타임스텝이 멀어져도 효과적</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163674-c0b01200-7132-11eb-9be7-3fe0f24f100b.png" alt="image-20210216111926346"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163677-c148a880-7132-11eb-8792-16dfb7890d77.png" alt="image-20210216112339995"></li>
<li>Forget gate<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163678-c148a880-7132-11eb-9e4e-49b691cfaa37.png" alt="image-20210216113442287"></li>
</ul>
</li>
<li>Gate gate<ul>
<li>$i_t$를 곱해주는 것은 $C_{t-1}$에 더해줄 정보에서 값을 덜어내는것</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163684-c279d580-7132-11eb-85cc-e0d178c9ef5a.png" alt="image-20210216113709586"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163682-c1e13f00-7132-11eb-9576-78499ca764e1.png" alt="image-20210216113612505"></li>
</ul>
</li>
<li>$h_t$<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163685-c279d580-7132-11eb-93f9-156ef7414b0b.png" alt="image-20210216114114206"></li>
</ul>
</li>
<li>$C_t$: 기억해야할 모든 정보</li>
<li>$h_t$: output layer의 입력으로 사용, $C_t$에서 당장 필요한 정보만 필터링</li>
</ul>
<h2 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h2><ul>
<li>cell state와 hidden state 합침<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163687-c3126c00-7132-11eb-91da-5d6596c3fe63.png" alt="image-20210216115107357"></li>
</ul>
</li>
<li>계산량, 메모리 요구량 줄임<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108163624-b5f57d00-7132-11eb-867a-548521f76b84.png" alt="image-20210216120027992"></li>
</ul>
</li>
<li>input gate가 커질수록 forget gate 작아짐</li>
</ul>
<h2 id="LSTM-GRU-backpropagation"><a href="#LSTM-GRU-backpropagation" class="headerlink" title="LSTM,GRU backpropagation"></a>LSTM,GRU backpropagation</h2><ul>
<li>곱해주는 것이 아닌 필요한 정보를 더하여 vanishing 해결<ul>
<li>멀리있는 타임스텝까지 gradient 변형없이 전달</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108163625-b726aa00-7132-11eb-94c7-76d2ed0ac75d.png" alt="image-20210216120411669"></li>
</ul>
</li>
</ul>
<h2 id="Further-Question"><a href="#Further-Question" class="headerlink" title="Further Question"></a>Further Question</h2><ul>
<li>BPTT 이외에 RNN/LSTM/GRU의 구조를 유지하면서 gradient vanishing/exploding 문제를 완화할 수 있는 방법이 있을까요?</li>
<li>RNN/LSTM/GRU 기반의 Language Model에서 초반 time step의 정보를 전달하기 어려운 점을 완화할 수 있는 방법이 있을까요?</li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/16/BoostCamp/Day16/"><img class="fill" src="/img/boostcamp.png" alt="Day16"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-15T17:47:35.000Z" title="2021-2-16 2:47:35 ├F10: AM┤">2021-02-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:31:08.620Z" title="2021-3-22 6:31:08 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">3 minutes read (About 387 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/16/BoostCamp/Day16/">Day16</a></h1><div class="content"><h2 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h2><ul>
<li>Low level<ul>
<li>Tokenizaition, stemming(형태소 분석)</li>
</ul>
</li>
<li>Word and Phase level<ul>
<li>Named entity recognition(NER)-&gt;고유명사 ex)new york times</li>
<li>part-of-speech(POS) tagging-&gt;성분 분석(명사,형용사)</li>
</ul>
</li>
<li>Sentence level<ul>
<li>Sentiment , machine translation</li>
</ul>
</li>
<li>Multi-sentence and paragraph level<ul>
<li>Entailment prediction(문장간 논리), question answering(where did napoleon die?), dialog system(chatbot), summarization</li>
</ul>
</li>
</ul>
<h2 id="Text-mining"><a href="#Text-mining" class="headerlink" title="Text mining"></a>Text mining</h2><ul>
<li>트렌드 분석</li>
<li>clustering (topic modeling)</li>
<li>highly related to computational social science (SNS)</li>
<li>KDD, The WebConf</li>
</ul>
<h2 id="Information-retreival-검색"><a href="#Information-retreival-검색" class="headerlink" title="Information retreival(검색)"></a>Information retreival(검색)</h2><ul>
<li>highly related to computation social science</li>
<li>recommendation system</li>
</ul>
<h2 id="Trends-of-NLP"><a href="#Trends-of-NLP" class="headerlink" title="Trends of NLP"></a>Trends of NLP</h2><ul>
<li>each word can be represented as a vector (Word2Vec or GloVe)</li>
<li>RNN (LSTM, GRUs)</li>
<li>attention ,transformer</li>
<li>in early days, customized models for different NLP tasks</li>
<li>self-supervised-&gt;BERT, GPT-3</li>
</ul>
<h2 id="Bag-of-Words"><a href="#Bag-of-Words" class="headerlink" title="Bag-of-Words"></a>Bag-of-Words</h2><ul>
<li>step1<ul>
<li>중복단어 제거</li>
<li><img src="https://user-images.githubusercontent.com/46857207/107979188-77ac7080-7001-11eb-9c0b-76c04b31312e.png" alt="image-20210215141338130"></li>
</ul>
</li>
<li>step2<ul>
<li>encodng unique words to one-hot vectors</li>
<li>distance is $\sqrt2$</li>
<li>cosine is 0</li>
<li>sentence can be represented as sum of one-hot vectors<ul>
<li>john really really loves this movie</li>
<li>[1 2 1 1 1 0 0 0]</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="NaiveBayes-Classifier"><a href="#NaiveBayes-Classifier" class="headerlink" title="NaiveBayes Classifier"></a>NaiveBayes Classifier</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/107979190-78dd9d80-7001-11eb-97b3-7547b6a5303e.png" alt="image-20210215141542496"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/107979191-78dd9d80-7001-11eb-8486-b223740aac49.png" alt="image-20210215142142512"></li>
</ul>
<h1 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h1><ul>
<li>Express a word as a vector</li>
<li>Same relationship is represented as the same vectors</li>
</ul>
<h2 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h2><ul>
<li><p>인접한 단어들간의 의미가 비슷할 것이다<br><img src="https://user-images.githubusercontent.com/46857207/107979194-79763400-7001-11eb-917b-492bc318e730.png" alt="image-20210215142907516"><br><img src="https://user-images.githubusercontent.com/46857207/108026170-2cc74300-706b-11eb-84be-93a7d18ce7d6.png" alt="image-20210216145150869"><br>-word간의 의미관계를 vector로 잘 표현<br><img src="https://user-images.githubusercontent.com/46857207/108026172-2df87000-706b-11eb-952e-b379798f6f60.png" alt="image-20210216145438632"></p>
</li>
<li><p>Intrusion Detection</p>
<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/107979195-7a0eca80-7001-11eb-9994-73feffc6ae30.png" alt="image-20210215145010841"></li>
</ul>
</li>
<li>application<ul>
<li>translation</li>
<li>sentiment analysis</li>
<li>image captioning</li>
</ul>
</li>
</ul>
<h2 id="GloVe"><a href="#GloVe" class="headerlink" title="GloVe"></a>GloVe</h2><ul>
<li>중복되는 계산을 줄여 빠름<br><img src="https://user-images.githubusercontent.com/46857207/107979198-7aa76100-7001-11eb-9c2e-79d0a08c4fd4.png" alt="image-20210215145143880"></li>
</ul>
<h1 id="Word2Vec-2가지-CBOW-vs-skip-gram"><a href="#Word2Vec-2가지-CBOW-vs-skip-gram" class="headerlink" title="Word2Vec 2가지 CBOW vs skip-gram"></a>Word2Vec 2가지 CBOW vs skip-gram</h1><h2 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108026175-2e910680-706b-11eb-9bb2-3b5c2639aceb.png" alt="image-20210216152106543"></li>
</ul>
<h2 id="skip-gram"><a href="#skip-gram" class="headerlink" title="skip-gram"></a>skip-gram</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108026177-2e910680-706b-11eb-81d8-fdc71fae4bbb.png" alt="image-20210216152158739"></li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/05/BoostCamp/Day15/"><img class="fill" src="/img/boostcamp.png" alt="Day15"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-05T14:59:57.000Z" title="2021-2-5 11:59:57 ├F10: PM┤">2021-02-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:31:03.890Z" title="2021-3-22 6:31:03 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">3 minutes read (About 390 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/05/BoostCamp/Day15/">Day15</a></h1><div class="content"><h1 id="Generative-Models"><a href="#Generative-Models" class="headerlink" title="Generative Models"></a>Generative Models</h1><p>What does it mean to learn a generative model?</p>
<ul>
<li>Generation-&gt;sampling</li>
<li>Densitiy estimation :$p(x)$ should be high if x looks like dog-&gt;explicit models</li>
<li>unsuperviesd representation learning-&gt; feature learning</li>
</ul>
<p>How can we represent $p(x)$</p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050020-21278100-680e-11eb-92a9-a3adb313d298.png" alt="image-20210205094249672"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050025-2258ae00-680e-11eb-82d4-2517b8755db7.png" alt="image-20210205094351518"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050030-22f14480-680e-11eb-964a-02f853cf812e.png" alt="image-20210205094844333"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050031-2389db00-680e-11eb-8c11-5e0d9879dc7e.png" alt="image-20210205094940765"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050032-2389db00-680e-11eb-8205-12196bd09085.png" alt="image-20210205100055253"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050034-24227180-680e-11eb-974f-f0e0016785f6.png" alt="image-20210205100106716"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050036-24227180-680e-11eb-842b-debab00521c9.png" alt="image-20210205100118955"></p>
<h2 id="Auto-regressive-Model"><a href="#Auto-regressive-Model" class="headerlink" title="Auto-regressive Model"></a>Auto-regressive Model</h2><p><img src="https://user-images.githubusercontent.com/46857207/107050037-24bb0800-680e-11eb-830d-f694fdc1ec24.png" alt="image-20210205100530278"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050041-25539e80-680e-11eb-872f-365a5ed7626a.png" alt="image-20210205100658091"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050043-25ec3500-680e-11eb-9b3c-78e7177df52d.png" alt="image-20210205100907226"></p>
<h2 id="Latent-Variable-Models"><a href="#Latent-Variable-Models" class="headerlink" title="Latent Variable Models"></a>Latent Variable Models</h2><p><img src="https://user-images.githubusercontent.com/46857207/107050046-25ec3500-680e-11eb-9291-8c84ebdb0309.png" alt="image-20210205101420955"></p>
<ul>
<li>posterior distribution을 근사할 수 있는 variational distribution을 찾는 것</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/46857207/107050048-2684cb80-680e-11eb-82a9-00fe576352bf.png" alt="image-20210205101542409"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050050-271d6200-680e-11eb-80d6-ae8ad4607a59.png" alt="image-20210205101607611"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050051-27b5f880-680e-11eb-990a-e4565327e27c.png" alt="image-20210205101756220"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050053-27b5f880-680e-11eb-9a5b-f837870532e8.png" alt="image-20210205102126480"></p>
<ul>
<li>explicit하지 않다</li>
<li>reconstruction을 무엇을 해도 되지만 kl-divergence는 가우시안을 사용</li>
<li>isotropic gaussian</li>
<li>단점 : encoder를 활용할 떄 prior fitting term이 kl-divergence를 활용한다는 것</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/46857207/107050059-297fbc00-680e-11eb-916a-b09c38247a78.png" alt="image-20210205102436950"></p>
<h2 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h2><ul>
<li>장점 : discriminator가 점차 좋아진다</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/46857207/107050065-2a185280-680e-11eb-9485-d535e17f3b15.png" alt="image-20210205102802203"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050070-2b497f80-680e-11eb-9730-b73397782eaa.png" alt="image-20210205102852993"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050073-2be21600-680e-11eb-9f98-228660c05c40.png" alt="image-20210205102919069"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/107050074-2c7aac80-680e-11eb-930c-5869e865a5f0.png" alt="image-20210205103059164"></p>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/04/BoostCamp/Day14/"><img class="fill" src="/img/boostcamp.png" alt="Day14"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-04T13:51:23.000Z" title="2021-2-4 10:51:23 ├F10: PM┤">2021-02-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:30:58.923Z" title="2021-3-22 6:30:58 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">6 minutes read (About 867 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/04/BoostCamp/Day14/">Day14</a></h1><div class="content"><h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><ul>
<li>시계열, sequence 데이터</li>
<li>독립동등분포를 잘 위배한다. ex) 개가사람을 문다. 사람이 개를 문다. 앞뒤 문맥없이 예측하는 것은 힘들다.</li>
<li>데이터의 위치를 함부로 바꾸면 안됨</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901722-72b30b80-673b-11eb-92d7-80b969e81471.png" alt="image-20210204094406393"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901727-73e43880-673b-11eb-84e5-05edcec3fdb5.png" alt="image-20210204094434202"></li>
<li>모든 데이터가 필요한건 아니다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901731-747ccf00-673b-11eb-859d-5b69e091722b.png" alt="image-20210204094819995"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901736-75adfc00-673b-11eb-8cad-fa2d8281da3d.png" alt="image-20210204094855480"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901744-7777bf80-673b-11eb-8d60-690c306189c4.png" alt="image-20210204095002305"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901751-78105600-673b-11eb-816c-f2b1876cca5c.png" alt="image-20210204095025761"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901760-79418300-673b-11eb-9343-16a10843ed7a.png" alt="image-20210204095433338"></li>
<li>위 MLP는 과거의 정보를 다룰 수 없다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901773-7a72b000-673b-11eb-98b8-f1f8eb25687c.png" alt="image-20210204095645274"></li>
<li>가중치 3개 wx1 wh1 w2 ,이것은 t에 따라 변하지 않는다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901783-7ba3dd00-673b-11eb-8db4-5482558e875d.png" alt="image-20210204100018906"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901789-7c3c7380-673b-11eb-88eb-c9d810cba0c9.png" alt="image-20210204100225637"></li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/106901794-7cd50a00-673b-11eb-99e8-35b303c2ce2d.png" alt="image-20210204100409392"></p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/106901799-7e063700-673b-11eb-9692-8500d6119ca9.png" alt="image-20210204101844368"></p>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901802-7e9ecd80-673b-11eb-92dd-5837485cb685.png" alt="image-20210204101913542"><ul>
<li>ex) 내읠 시험 전수는 전날에만 의존한다.</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901804-7f376400-673b-11eb-9677-1ed76b13901d.png" alt="image-20210204102028533"><ul>
<li>중간 hidden state-&gt; 과거의 정보를 요약</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901808-7fcffa80-673b-11eb-9089-4d2c98c62df1.png" alt="image-20210204102325047"><ul>
<li>과거의 정보가 미래까지 살아남기 힘듦</li>
<li>한참 전의 step은 소실</li>
<li>문장이 길어져도 이전의 정보를 고려해야 하는데 그러지 못한다.</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901810-80689100-673b-11eb-9dbe-2f149076283a.png" alt="image-20210204102433119"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901817-83638180-673b-11eb-881d-0306a1dff17f.png" alt="image-20210204102448702"><ul>
<li>activation $\phi$가 sigmoid라면 $h_0$는 의미가 없어지게 된다. Relu를 써도 마찬가지</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901825-8494ae80-673b-11eb-8e3b-9bc0ecc990e3.png" alt="image-20210204102823959"><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106901826-85c5db80-673b-11eb-9dd2-d139df3907c7.png" alt="image-20210204103242662"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901833-878f9f00-673b-11eb-8033-08e4d9f8f0fe.png" alt="image-20210204103306148"><ul>
<li>forget gate: $f_t$는 0~1값 -&gt;이전 cell state에서 어떤걸 버리고 살릴지 결정</li>
<li>input gate: 어떤 정보를 올릴지 결정</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901836-88c0cc00-673b-11eb-9fc6-879a6d89b21a.png" alt="image-20210204103317655"></li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106901841-89f1f900-673b-11eb-9789-0ac296027bd7.png" alt="image-20210204103928535"></li>
</ul>
<h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><p><img src="https://user-images.githubusercontent.com/46857207/106901848-8b232600-673b-11eb-8150-5fee83bd984e.png" alt="image-20210204111351566"></p>
<ul>
<li>n개의 단어가 어떻게 한번에 처리되는지</li>
<li>인코더와 디코더 사이의 어떤 정보를 주고 받는지</li>
<li>디코더가 어떻게 generation하는지</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/46857207/106901853-8c545300-673b-11eb-8a4d-b6f0c36dfb96.png" alt="image-20210204112433262"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901859-8d858000-673b-11eb-94aa-884a5eda2f7d.png" alt="image-20210204112521419"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901862-8e1e1680-673b-11eb-8b40-bf5a835e381f.png" alt="image-20210204112626279"></p>
<hr>
<p><img src="https://user-images.githubusercontent.com/46857207/106901867-8f4f4380-673b-11eb-9e07-71b1fba3367f.png" alt="image-20210204112721207"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901872-8fe7da00-673b-11eb-8b7c-a1e240eda4e8.png" alt="image-20210204112809814"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901875-91190700-673b-11eb-8cdb-3ffdf712ae25.png" alt="image-20210204112904451"></p>
<hr>
<p><img src="https://user-images.githubusercontent.com/46857207/106901879-924a3400-673b-11eb-9420-0241c6a37f94.png" alt="image-20210204112925104"></p>
<hr>
<p><img src="https://user-images.githubusercontent.com/46857207/106901883-92e2ca80-673b-11eb-8927-72aa1af7862a.png" alt="image-20210204112944147"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901893-94ac8e00-673b-11eb-9d2c-8a1892c5e982.png" alt="image-20210204113601502"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901901-95ddbb00-673b-11eb-9c60-28133dda215c.png" alt="image-20210204113621666"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901906-95ddbb00-673b-11eb-9f5b-64554a478bd8.png" alt="image-20210204113634221"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901908-96765180-673b-11eb-802f-a2f0fadf5704.png" alt="image-20210204113749880"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901911-970ee800-673b-11eb-91a0-bd13ef7fe00c.png" alt="image-20210204114029713"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901912-97a77e80-673b-11eb-9ada-6c779a48ab57.png" alt="image-20210204114050371"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901913-97a77e80-673b-11eb-9784-7de9b2d475b6.png" alt="image-20210204114134036"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901919-98d8ab80-673b-11eb-9f84-3318618aafb2.png" alt="image-20210204114152577"></p>
<p><img src="https://user-images.githubusercontent.com/46857207/106901922-99714200-673b-11eb-8cd0-93d0b53eba59.png" alt="image-20210204114234253"></p>
<ul>
<li>bias</li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/03/BoostCamp/Day13/"><img class="fill" src="/img/boostcamp.png" alt="Day13"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-03T13:54:13.000Z" title="2021-2-3 10:54:13 ├F10: PM┤">2021-02-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:30:54.577Z" title="2021-3-22 6:30:54 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">6 minutes read (About 967 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/03/BoostCamp/Day13/">Day13</a></h1><div class="content"><h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106756398-9c543000-6672-11eb-8dce-832ee2926a95.png" alt="image-20210203093748791"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756403-9d855d00-6672-11eb-9b63-c284f48e68c1.png" alt="image-20210203093815981"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756405-9e1df380-6672-11eb-8576-9aa8e192c38f.png" alt="image-20210203093950124"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756407-9eb68a00-6672-11eb-9ed2-fe9111cc7b80.png" alt="image-20210203094233167"></li>
<li>fully connected 없어지는 추세이다<ul>
<li>parameter의 숫자를 줄이기 위해</li>
</ul>
</li>
<li>Stride</li>
<li>Padding</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756411-9eb68a00-6672-11eb-9c08-39472dc017e9.png" alt="image-20210203095453596"></li>
<li>dense layer의 parameter가 많은 이유는 각각의 커널이 모두 적용되기 때문이다.<ul>
<li>parameter를 줄이는 것이 중요-&gt;1x1 convolution</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756414-9f4f2080-6672-11eb-9517-204f5c2e62f4.png" alt="image-20210203095710439"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756418-9fe7b700-6672-11eb-99c1-5725b9c8bfec.png" alt="image-20210203102945124"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756421-a0804d80-6672-11eb-9338-024a041186dd.png" alt="image-20210203103211807"><ul>
<li>11x11 커널은 좋은것은 아니다</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756423-a118e400-6672-11eb-9b55-7a017814ffd3.png" alt="image-20210203103301071"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756428-a118e400-6672-11eb-85e6-6d03b26690cf.png" alt="image-20210203103527759"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756432-a1b17a80-6672-11eb-960b-6b385337189c.png" alt="image-20210203103600510"><ul>
<li>3x3만 사용</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756433-a1b17a80-6672-11eb-94f3-61b8e4a40e16.png" alt="image-20210203103657860"></li>
<li>3x3과 5x5는 receptive field 차원에서는 똑같지만 parameter의 수는 다르다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756435-a24a1100-6672-11eb-911d-b170476343d2.png" alt="image-20210203104045528"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756436-a24a1100-6672-11eb-81ef-fdfdcd07a6f0.png" alt="image-20210203104127907"></li>
<li>인셉션 블록<ul>
<li>여러개의 response를 concatenate하는 효과도 있지만 1x1을 사용함으로써 param수를 줄일 수 있게 된다.</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756438-a2e2a780-6672-11eb-9348-f6fe4a325442.png" alt="image-20210203104319622"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756440-a37b3e00-6672-11eb-8c2b-06e9efe7a9c8.png" alt="image-20210203104609192"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756442-a37b3e00-6672-11eb-8923-e2fdc8b94efb.png" alt="image-20210203104711251"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756445-a413d480-6672-11eb-94d7-aa5c9e530f78.png" alt="image-20210203104859944"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756448-a413d480-6672-11eb-81fe-c9e9752e28c0.png" alt="image-20210203105039998"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756451-a4ac6b00-6672-11eb-9481-13914144d4d9.png" alt="image-20210203105117353"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756453-a4ac6b00-6672-11eb-9f81-482d6e43eb24.png" alt="image-20210203105144072"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756455-a5450180-6672-11eb-9a76-114691240750.png" alt="image-20210203105218644"><ul>
<li>3x3전에 input채널을 줄이고 3x3후에 output채널을 늘린다.</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756460-a5450180-6672-11eb-85fa-4bde9acc0058.png" alt="image-20210203105423758"><ul>
<li>resnet의 더하기 대신 concat</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756463-a5dd9800-6672-11eb-97ad-f2712aacc071.png" alt="image-20210203105456217"><ul>
<li>채널이 점점 커진다 -&gt; param수도 늘어남</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756465-a5dd9800-6672-11eb-9a46-6cd78a82be28.png" alt="image-20210203105526504"><ul>
<li>1x1을 사용해 transition block에서 줄인다</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756468-a6762e80-6672-11eb-8b7c-449516eed4eb.png" alt="image-20210203105629286"></li>
</ul>
<h1 id="Computer-Vision"><a href="#Computer-Vision" class="headerlink" title="Computer Vision"></a>Computer Vision</h1><h2 id="semantic-segmentation"><a href="#semantic-segmentation" class="headerlink" title="semantic segmentation"></a>semantic segmentation</h2><ul>
<li>pixel마다 분류</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756471-a70ec500-6672-11eb-9424-20134ccf06a6.png" alt="image-20210203110023247"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756474-a70ec500-6672-11eb-94f3-3ac893de0b19.png" alt="image-20210203110034830"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756477-a7a75b80-6672-11eb-8417-d5c46b5c4ba3.png" alt="image-20210203110919536"><ul>
<li>param수는 같다</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756481-a7a75b80-6672-11eb-8b40-765c9362a283.png" alt="image-20210203111927437"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756482-a83ff200-6672-11eb-9a41-9083f6f8086e.png" alt="image-20210203112140935"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756484-a83ff200-6672-11eb-82fc-1f2ba2ccce70.png" alt="image-20210203112212553"><ul>
<li>엄밀히 말하면 복원할 수는 없다.</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756488-a8d88880-6672-11eb-950f-5ed99d7bc1eb.png" alt="image-20210203112643710"></li>
</ul>
<h2 id="Detection-R-CNN"><a href="#Detection-R-CNN" class="headerlink" title="Detection R-CNN"></a>Detection R-CNN</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106756491-a9711f00-6672-11eb-8afd-79ab97f376ef.png" alt="image-20210203112922950"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756493-a9711f00-6672-11eb-9761-c831f4b9745a.png" alt="image-20210203112944571"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756494-aa09b580-6672-11eb-9303-00af8ba41fa5.png" alt="image-20210203113006424"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756497-aaa24c00-6672-11eb-8e4b-8d6274f13212.png" alt="image-20210203113150581"></li>
<li>바운딩 박스를 뽑는 것도 네트워크로 학습</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756498-aaa24c00-6672-11eb-9fb5-3cfce0920e33.png" alt="image-20210203113407684"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756500-ab3ae280-6672-11eb-86f1-e67ba1e9a76d.png" alt="image-20210203113440464"></li>
<li>RPN : 이미지로 특정 위치가 바운딩 박스로써 의미가 있을지 없을지 판단</li>
<li>물체가 무엇인지는 판단x</li>
<li>anchor boxes: 미리 정해놓은 바운딩 박스의 크기</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756502-abd37900-6672-11eb-8f78-8b0c29e2d5ae.png" alt="image-20210203113746175"><ul>
<li>size 3개 ration 3개 -&gt;9</li>
<li>width,height,x,y-&gt;4</li>
<li>해당 바운딩 박스가 쓸모있는지 없는지 -&gt;2</li>
</ul>
</li>
</ul>
<h2 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106756503-abd37900-6672-11eb-928c-c6e817ef9dbb.png" alt="image-20210203114056598"></li>
<li>한번에 분류</li>
<li>바운딩 박스를 뽑는 region propoasl이 없다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756506-ac6c0f80-6672-11eb-976d-7241d9b018ba.png" alt="image-20210203114400671"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756507-ac6c0f80-6672-11eb-93e4-2c29d3b9c37f.png" alt="image-20210203114433782"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756508-ad04a600-6672-11eb-9c0d-dc0a6af38a67.png" alt="image-20210203114459536"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106756511-ad9d3c80-6672-11eb-8d07-79c6132ffd34.png" alt="image-20210203114510539"></li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/02/BoostCamp/Day12/"><img class="fill" src="/img/boostcamp.png" alt="Day12"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-02T14:15:26.000Z" title="2021-2-2 11:15:26 ├F10: PM┤">2021-02-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:30:49.132Z" title="2021-3-22 6:30:49 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">5 minutes read (About 709 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/02/BoostCamp/Day12/">Day12</a></h1><div class="content"><h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><h2 id="Generalization"><a href="#Generalization" class="headerlink" title="Generalization"></a>Generalization</h2><ul>
<li>일반화 성능을 높이는 것이 목적</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612385-69dfff80-65ac-11eb-9439-980189fda245.png" alt="image-20210202094729954"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612391-6a789600-65ac-11eb-8ca8-ec742ac7b76a.png" alt="image-20210202094827828"></li>
</ul>
<h2 id="Cross-validation-k-fold"><a href="#Cross-validation-k-fold" class="headerlink" title="Cross-validation(k fold)"></a>Cross-validation(k fold)</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612393-6b112c80-65ac-11eb-9b99-81345d272205.png" alt="image-20210202095010576"><ul>
<li>하이퍼 파라미터가 많이 존재하기 때문에(lr) cross-validation을 통해 최적의 하이퍼파라미터를 찾고 이를 고정시킨 상태에서 학습시킬 때는 모든 데이터를 사용</li>
</ul>
</li>
</ul>
<h2 id="Bias-and-variance"><a href="#Bias-and-variance" class="headerlink" title="Bias and variance"></a>Bias and variance</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612397-6b112c80-65ac-11eb-806f-f358ba57c760.png" alt="image-20210202095253714"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612399-6ba9c300-65ac-11eb-9cff-6a994f23080c.png" alt="image-20210202095334982"></li>
<li>학습데이터에 노이즈가 있을 경우 bias와 variance를 둘 다 줄이기는 힘들다</li>
</ul>
<h2 id="Boostrapping"><a href="#Boostrapping" class="headerlink" title="Boostrapping"></a>Boostrapping</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612400-6ba9c300-65ac-11eb-83df-dc1391a48eab.png" alt="image-20210202095706825"></li>
</ul>
<h2 id="Bagging-vs-Boosting"><a href="#Bagging-vs-Boosting" class="headerlink" title="Bagging vs Boosting"></a>Bagging vs Boosting</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612403-6c425980-65ac-11eb-9658-cc33fb4b0b30.png" alt="image-20210202095744157"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612405-6c425980-65ac-11eb-897c-f24b8ed5eda3.png" alt="image-20210202095957714"></li>
</ul>
<h1 id="Gradient-Descent-Methods"><a href="#Gradient-Descent-Methods" class="headerlink" title="Gradient Descent Methods"></a>Gradient Descent Methods</h1><p><img src="https://user-images.githubusercontent.com/46857207/106612407-6cdaf000-65ac-11eb-867c-96ec6eef286c.png" alt="image-20210202100022003"></p>
<h2 id="Batch-size-Matters"><a href="#Batch-size-Matters" class="headerlink" title="Batch-size Matters"></a>Batch-size Matters</h2><ul>
<li>배치 너무 크면 sharp minimizers 너무 작으면 flat minimizers</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612409-6cdaf000-65ac-11eb-8adf-87052d3ed18f.png" alt="image-20210202100221345"></li>
</ul>
<h2 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612410-6d738680-65ac-11eb-9066-68ce008ea357.png" alt="image-20210202100516783"></li>
</ul>
<h2 id="Nesterov-Accelerated-Gradient"><a href="#Nesterov-Accelerated-Gradient" class="headerlink" title="Nesterov Accelerated Gradient"></a>Nesterov Accelerated Gradient</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612412-6d738680-65ac-11eb-8fb0-c150c8462c84.png" alt="image-20210202100721271"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612414-6e0c1d00-65ac-11eb-98b2-cb56b4edc704.png" alt="image-20210202100801665"></li>
</ul>
<h2 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612415-6ea4b380-65ac-11eb-9299-1c40bfff7195.png" alt="image-20210202100949467"></li>
</ul>
<h2 id="Adadelta"><a href="#Adadelta" class="headerlink" title="Adadelta"></a>Adadelta</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612419-6f3d4a00-65ac-11eb-8267-bbb232edf400.png" alt="image-20210202101417140"></li>
</ul>
<h2 id="RMSporp"><a href="#RMSporp" class="headerlink" title="RMSporp"></a>RMSporp</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612421-6f3d4a00-65ac-11eb-836a-30e8f2c94ba0.png" alt="image-20210202101549058"></li>
</ul>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612423-6fd5e080-65ac-11eb-9d03-3786e44e723c.png" alt="image-20210202101719251"></li>
</ul>
<h1 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h1><p>학습데이터뿐만 아니라 테스트 데이터에도 잘 작동하도록 규제하는 것</p>
<ul>
<li>Early stopping<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612425-6fd5e080-65ac-11eb-9020-578d7c6e3660.png" alt="image-20210202102041270"></li>
</ul>
</li>
<li>parameter norm penalty<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612431-706e7700-65ac-11eb-99f6-1fbaf680a96c.png" alt="image-20210202102124376"></li>
<li>파라미터가 너무 크지 않게 하는 것</li>
</ul>
</li>
<li>Data augmentation<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612435-71070d80-65ac-11eb-98d5-fe14123bc0aa.png" alt="image-20210202102231187"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612441-72d0d100-65ac-11eb-8a6e-f55a932b4f0c.png" alt="image-20210202102316277"></li>
</ul>
</li>
<li>Noise robustness<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612447-7401fe00-65ac-11eb-8975-062214773ffe.png" alt="image-20210202102434701"></li>
</ul>
</li>
<li>Label smoothing<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612450-7401fe00-65ac-11eb-8077-2ae1857b6b86.png" alt="image-20210202102514810"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612465-76645800-65ac-11eb-90ea-13a9aebd57d6.png" alt="image-20210202102535614"></li>
</ul>
</li>
<li>Dropout<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612468-76fcee80-65ac-11eb-8e29-0e9d88f552be.png" alt="image-20210202102754838"></li>
</ul>
</li>
<li>Batch normalization<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612472-77958500-65ac-11eb-9d24-70850ceaf0e7.png" alt="image-20210202102858482"></li>
<li>Internal Covariate(feature) Shift를 줄인다</li>
<li>성능은 올라간다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612489-7cf2cf80-65ac-11eb-9a6a-8bd6f3617738.png" alt="image-20210202103046288"></li>
</ul>
</li>
</ul>
<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106612492-7d8b6600-65ac-11eb-880f-699d2d5929f0.png" alt="image-20210202114306774"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612493-7e23fc80-65ac-11eb-9ee0-f9661a6e7266.png" alt="image-20210202114701974"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612494-7e23fc80-65ac-11eb-9b14-4f52767faca1.png" alt="image-20210202114913967"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612498-7ebc9300-65ac-11eb-8474-4dcae868648f.png" alt="image-20210202121512613"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612500-7f552980-65ac-11eb-9459-5df6876e97a1.png" alt="image-20210202121858772"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612501-7f552980-65ac-11eb-95cd-3aad9a9fdf37.png" alt="image-20210202122245445"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612503-7fedc000-65ac-11eb-9d00-475d81684f3c.png" alt="image-20210202122453543"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106612504-7fedc000-65ac-11eb-9ece-be5f7ae67ae0.png" alt="image-20210202122539283"></li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/01/BoostCamp/Day11/"><img class="fill" src="/img/boostcamp.png" alt="Day11"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-01T13:25:39.000Z" title="2021-2-1 10:25:39 ├F10: PM┤">2021-02-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:30:42.232Z" title="2021-3-22 6:30:42 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">2 minutes read (About 280 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/01/BoostCamp/Day11/">Day11</a></h1><div class="content"><h1 id="베이즈-통계학"><a href="#베이즈-통계학" class="headerlink" title="베이즈 통계학"></a>베이즈 통계학</h1><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106464472-0eded780-64dc-11eb-96e3-c573e54d70cc.png" alt="image-20210201094448636"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464476-0f776e00-64dc-11eb-855a-89634920a563.png" alt="image-20210201095022429"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464478-0eded780-64dc-11eb-9e34-28c4a777d7f0.png" alt="image-20210201095133695"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464482-10a89b00-64dc-11eb-9671-2abed84da047.png" alt="image-20210201095215517"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464484-10a89b00-64dc-11eb-8d34-1c2833205c57.png" alt="image-20210201095240862"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464489-11d9c800-64dc-11eb-8ad9-a4fee5fa6d06.png" alt="image-20210201095735886"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464493-12725e80-64dc-11eb-9408-b22801b5da7d.png" alt="image-20210201100255131"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464501-13a38b80-64dc-11eb-81ec-1355e7332671.png" alt="image-20210201100429912"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464507-143c2200-64dc-11eb-8453-db69545d0ac9.png" alt="image-20210201101049406"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464508-14d4b880-64dc-11eb-947f-c0b54ec62ca6.png" alt="image-20210201101125132"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464510-14d4b880-64dc-11eb-8995-6c8e8886c025.png" alt="image-20210201101211505"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464511-156d4f00-64dc-11eb-844a-cf591b44da73.png" alt="image-20210201101355285"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464512-1605e580-64dc-11eb-934f-19cb6bf3a49a.png" alt="image-20210201101730345"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464514-1605e580-64dc-11eb-89e3-2c90de2a2a6d.png" alt="image-20210201101757825"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106464515-169e7c00-64dc-11eb-852a-2472e5c9e782.png" alt="image-20210201101810959"></li>
</ul>
<h1 id="History"><a href="#History" class="headerlink" title="History"></a>History</h1><p><img src="https://user-images.githubusercontent.com/46857207/106464516-169e7c00-64dc-11eb-84ed-b94fbb1e03b9.png" alt="image-20210201103012731"></p>
<h1 id="Pytorchs"><a href="#Pytorchs" class="headerlink" title="Pytorchs"></a>Pytorchs</h1><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106464518-17371280-64dc-11eb-88b9-428c83582326.png" alt="image-20210201105621889"></li>
</ul>
<p><img src="https://user-images.githubusercontent.com/46857207/106464519-17cfa900-64dc-11eb-83c9-15886caaac60.png" alt="image-20210201123006561"></p>
<h2 id="Kaiming-initialization"><a href="#Kaiming-initialization" class="headerlink" title="Kaiming initialization"></a>Kaiming initialization</h2><ul>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/understand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138">https://towardsdatascience.com/understand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138</a></li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/01/29/BoostCamp/Day10/"><img class="fill" src="/img/boostcamp.png" alt="Day10"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-01-29T10:56:44.000Z" title="2021-1-29 7:56:44 ├F10: PM┤">2021-01-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:30:37.507Z" title="2021-3-22 6:30:37 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">8 minutes read (About 1169 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/29/BoostCamp/Day10/">Day10</a></h1><div class="content"><h1 id="Data-Visualization"><a href="#Data-Visualization" class="headerlink" title="Data Visualization"></a>Data Visualization</h1><h2 id="matplotlib"><a href="#matplotlib" class="headerlink" title="matplotlib"></a>matplotlib</h2><ul>
<li>pyplot객체를 사용</li>
<li>단점 : argument를 kwargs받음</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266883-4fd0b500-626c-11eb-9d72-de4200292022.png" alt="image-20210129094707049"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266889-5101e200-626c-11eb-8b4b-5809e0d5d8b3.png" alt="image-20210129095038186"></li>
<li>set linestyle</li>
<li><a target="_blank" rel="noopener" href="https://matplotlib.org/examples/lines_bars_and_markers/linestyles.html">https://matplotlib.org/examples/lines_bars_and_markers/linestyles.html</a></li>
<li>title</li>
<li>xlabel, ylabel</li>
<li>legen<ul>
<li>범례</li>
</ul>
</li>
<li>scatter</li>
<li>bar</li>
</ul>
<h2 id="seaborn"><a href="#seaborn" class="headerlink" title="seaborn"></a>seaborn</h2><ul>
<li>hue : 카테고리 데이터<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106266893-519a7880-626c-11eb-881c-9e3817a17962.png" alt="image-20210129102243081"></li>
</ul>
</li>
<li>scatterplot : 퍼짐<ul>
<li>regplot : regression line</li>
</ul>
</li>
<li>countplot ==value_counts()</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266896-52330f00-626c-11eb-99e7-a6a9fd6fa85e.png" alt="image-20210129103422608"></li>
</ul>
<hr>
<h1 id="통계학"><a href="#통계학" class="headerlink" title="통계학"></a>통계학</h1><h2 id="모수"><a href="#모수" class="headerlink" title="모수"></a>모수</h2><ul>
<li>통계적 모델링은 적절한 가정 위에서 확률분포를 추정하는 것이 목표</li>
<li>유한한 개수의 데이터를 관찰해서 모집단의 분포를 정확하게 알아내는 것은 불가능, 근사적으로 확률분포를 추정할 수 밖에 없다.</li>
<li>예측모형의 목적은 분포를 정확하게 맞추는 것보다 데이터와 추정 방법의 불확식성을 고려해서 위험을 최소화하는 것이다.</li>
<li>데이터가 특정 확률분포를 따른다고 선험적으로(a priori) 가정한 후 그 분포를 결정하는 모수(parameter)를 추정하는 방법을 모수적방법론 (평균과 분산을 추정하는 방법을 통해서 데이터를 학습하는 방법을 모수적 방법론)</li>
<li>특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌면 비모수방법론이라 부른다.<ul>
<li>비모수 방법론은 모수가 없는 것이 아니라 무한히 많거나 모수의 개수가 데이터에 따라서 바뀌는 경우이다.</li>
</ul>
</li>
<li>둘의 차이는 어떤 가정을 미리 부여하는지 아닌지에 따라서 구별된다.</li>
<li>예제<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106266900-52cba580-626c-11eb-855a-e9422b3fe981.png" alt="image-20210129104309331"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266907-53643c00-626c-11eb-9ac3-41a123ae3a27.png" alt="image-20210129104431833"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266910-53643c00-626c-11eb-93dc-6ad8f54eccf2.png" alt="image-20210129104704172"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266912-53fcd280-626c-11eb-8648-d286c466b572.png" alt="image-20210129105035616"></li>
<li>표본분포(sample distribution)과 표집분포는 다르다</li>
<li>표집분포 : 표본평균과 표본분산의 확률분포</li>
<li>모집단의 분포가 정규분포를 따르지 않으면 표본분포는 데이터를 많이 모아도 정규분포가 될 수 없다.</li>
<li>모집단의 분포가 정규분포를 따르지 않아도 표본평균의 표집분포는 정규분포를 따른다</li>
<li>표본평균의 분산$\sigma^2\over n$는 데이터의 개수(n)이 늘어나면 0으로 수렴<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106266915-53fcd280-626c-11eb-89d7-c5e6f6e49c5f.png" alt="image-20210129105953177"></li>
</ul>
</li>
<li>원래 확률분포는 이항분포이고 이항분포의 표본분포는 데이터를 모아도 정규분포가 되지 않지만 이항분포에서 추출한 통계량, 즉 표본평균의 확률분포는 정규분포로 가고 이를 중심극한 정리라고 한다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266916-54956900-626c-11eb-83a5-d45bfff4af3d.png" alt="image-20210129110301104"></li>
<li>표본평균과 표본분산만으로 확률분포를 추정하는 것은 위험하고 최대가능도 추정법을 활용</li>
<li>확률밀도함수, 확률질량함수와 같다. 단지 관점의 차이<ul>
<li>확률밀도함수는 모수($\theta$)가 주어져 있을 때 x에 대한 함수로 해석</li>
<li>가능도함수는 주어진 데이터($x$)에 대해서 모수($\theta$)를 변수로둔 함수로 해석-&gt; 데이터가 주어진 상황에서 ($\theta$)를 변형시킴에 따라 값이 바뀌는 함수</li>
<li>($\theta$)에 대한 확률로 해석하면 안되고 가능도는 오로지 ($\theta$)에 대해서 크고 작음에 따른 대소비교가 가능한 함수로 이해하자</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266918-552dff80-626c-11eb-8f22-80d468a7ec62.png" alt="image-20210129110955840"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266919-552dff80-626c-11eb-873a-0b8abb07ca4e.png" alt="image-20210129111107354"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266920-55c69600-626c-11eb-8c08-4bbaf8d12313.png" alt="image-20210129111746332"><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106266923-55c69600-626c-11eb-8236-1077b25b68ea.png" alt="image-20210129111918730"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266926-565f2c80-626c-11eb-8c3a-d3e0990704b0.png" alt="image-20210129112411029"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266929-56f7c300-626c-11eb-9bdd-f92a7a35a488.png" alt="image-20210129112426517"></li>
<li>이산확률변수 카테고리 예제</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266932-57905980-626c-11eb-8a6c-3eaac2676cb0.png" alt="image-20210129114151746"></li>
<li>원핫벡터</li>
<li>$x_(i,k)$는 0,1만 가진다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266936-57905980-626c-11eb-83a3-7ca2d01208c0.png" alt="image-20210129114437830"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266938-58c18680-626c-11eb-8082-00c67e6e305a.png" alt="image-20210129114821088"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266940-58c18680-626c-11eb-9b88-67fdf48db3e2.png" alt="image-20210129114928261"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266944-59f2b380-626c-11eb-8c43-0e20cbc3e925.png" alt="image-20210129115153833"></li>
</ul>
</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266945-59f2b380-626c-11eb-91f8-dcfa6b6d7606.png" alt="image-20210129115450824"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106266946-5a8b4a00-626c-11eb-9b52-f8769ef30b4c.png" alt="image-20210129115804360"></li>
</ul>
<p>-</p>
<h2 id="further-question"><a href="#further-question" class="headerlink" title="further question"></a>further question</h2><ul>
<li>확률 VS 가능도</li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/01/28/BoostCamp/Day9/"><img class="fill" src="/img/boostcamp.png" alt="Day9"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-01-28T14:25:06.000Z" title="2021-1-28 11:25:06 ├F10: PM┤">2021-01-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:30:32.415Z" title="2021-3-22 6:30:32 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">6 minutes read (About 877 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/28/BoostCamp/Day9/">Day9</a></h1><div class="content"><h2 id="Groupby"><a href="#Groupby" class="headerlink" title="Groupby"></a>Groupby</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">h_index = df.groupby([<span class="string">&quot;Team&quot;</span>, <span class="string">&quot;Year&quot;</span>])[<span class="string">&quot;Points&quot;</span>].<span class="built_in">sum</span>()</span><br><span class="line">h_index</span><br></pre></td></tr></table></figure>
<pre><code>Team    Year
Devils  2014    863
        2015    673
Kings   2014    741
        2016    756
        2017    788
Riders  2014    876
        2015    789
        2016    694
        2017    690
Royals  2014    701
        2015    804
kings   2015    812
Name: Points, dtype: int64
</code></pre><ul>
<li>sort_index()</li>
<li>sort_values()</li>
<li>agg(aggregation)</li>
<li>transform</li>
<li>filter</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dateutil</span><br><span class="line"></span><br><span class="line">df_phone[<span class="string">&quot;date&quot;</span>] = df_phone[<span class="string">&quot;date&quot;</span>].apply(dateutil.parser.parse, dayfirst=<span class="literal">True</span>)</span><br><span class="line">df_phone.dtypes</span><br></pre></td></tr></table></figure>
<pre><code>index                    int64
date            datetime64[ns]
duration               float64
item                    object
month                   object
network                 object
network_type            object
dtype: object
</code></pre><ul>
<li>add_prefix</li>
<li>pivot_table</li>
<li>crosstab</li>
<li>merge(a,b,on=’ ‘)</li>
<li>merge(left, right, left_on=’ ‘,right_on=’ ‘)</li>
<li>merge(how=’ ‘) left,right,outer</li>
<li>concat</li>
<li>db conneciton</li>
</ul>
<hr>
<h1 id="확률론"><a href="#확률론" class="headerlink" title="확률론"></a>확률론</h1><ul>
<li>손실함수(lossfunction)들의 작동원리는데이터 공간을 통계적으로 해석해서 유도</li>
<li>회귀분석에서 손실함수로 사용되는 L2-노름은 예측오차의 분산을 가장 최소화하는 방향으로 학습하도록 유도</li>
<li>교차엔트로피(cross-entropy)는 모델예측의 불확실성을 최소화하는 방향으로 학습하도록 유도</li>
<li>이산확률변수 vs 연속확률변수<ul>
<li>데이터공간 xy에 의해 결정되는 것으로 오해를 하지만 확률변수의분포D에 의해 결정된다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106152004-4ee24980-61c0-11eb-8bba-2a145b5d467b.png" alt="image-20210128110619296"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106152012-50ac0d00-61c0-11eb-82ad-42808db79e29.png" alt="image-20210128113243715"></li>
<li>회귀문제의 경우 연속활률 변수를 다뤄 밀도함수로 해석</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106152019-530e6700-61c0-11eb-8b32-6bdee36a5431.png" alt="image-20210128113329252"></li>
<li>데이터가 robust하면 중앙값을 사용하기도 함</li>
<li><strong>로버스트(robust) 한 통계량은</strong> <strong>이상치/에러값으로 부터 영향을 크게 받지 않는 (건장한) 통계량</strong></li>
<li>기대값?</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106152025-54d82a80-61c0-11eb-8af7-4ac600736d1e.png" alt="image-20210128114915484"></li>
<li>연속 : 확률밀도함수-&gt;적분, 이산 : 확률질량함수-&gt;sum</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106152031-5570c100-61c0-11eb-9a8a-b7d110e22e1e.png" alt="image-20210128115104516"></li>
</ul>
</li>
</ul>
<h2 id="몬테카를로-샘플링"><a href="#몬테카를로-샘플링" class="headerlink" title="몬테카를로 샘플링"></a>몬테카를로 샘플링</h2><ul>
<li>밀도함수나 질량함수를 알고있으면 기대값을 계산할 때 적분이사 sum을 해주면 되지만 확률분포를 명시적으로 모르는 상황에서 샘플링하는 방법을 알고있으면 적분이나 sum대신에 샘플링을 통해 기대값을 계산할 수 있다.<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/106152035-56a1ee00-61c0-11eb-9c93-8a62ff60570a.png" alt="image-20210128115921876"></li>
<li>x자리에 샘플링한 데이터를 대입</li>
<li>$f(x^(i))$값들의 산술평균이 기대값에 근사, 독립적으로 샘플링을 해야한다.</li>
<li>독립추출이 보장되면 대수의법치겡 의해 수렴성을 보장</li>
<li><img src="https://user-images.githubusercontent.com/46857207/106152040-57d31b00-61c0-11eb-8ba5-ffdfb148d376.png" alt="image-20210128120207036"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/106152044-59044800-61c0-11eb-853f-88c0f58f1e65.png" alt="image-20210128120341997"></li>
<li>샘플사이즈가 적으면 오차범위가 커질 수 있다.</li>
</ul>
</li>
</ul>
<h2 id="further-queston"><a href="#further-queston" class="headerlink" title="further queston"></a>further queston</h2><ul>
<li><p>몬테카를로 방법으로 원주율 계산하기</p>
<ul>
<li><p><img src="https://user-images.githubusercontent.com/46857207/106152053-5b66a200-61c0-11eb-84b2-5ca727a0607a.png" alt="image-20210128152117681"></p>
</li>
<li><p>정사각형넓이 =$4r^2$ ,원의 넓이=$\pi r^2$</p>
</li>
<li><p>정사각형 안의 임의의 점이 원안에 있을 확율=$\pi r^2\over4r^2$=$\pi\over4$</p>
</li>
<li><p>(정사각형 안의 임의의 점이 원안에 있을 확율)*4=$\pi$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> random</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_in</span>(<span class="params">r</span>):</span></span><br><span class="line">    x=random()*r*<span class="number">2</span></span><br><span class="line">    y=random()*r*<span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> (x-r)**<span class="number">2</span>+(y-r)**<span class="number">2</span>&lt;=r**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">total=<span class="number">5000</span></span><br><span class="line">success=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(total):</span><br><span class="line">    <span class="keyword">if</span> random_in(<span class="number">1</span>)==<span class="literal">True</span>:</span><br><span class="line">        success+=<span class="number">1</span></span><br><span class="line">pi=success/total*<span class="number">4</span></span><br><span class="line">print(pi)</span><br></pre></td></tr></table></figure>
<pre><code>3.1904
</code></pre></li>
</ul>
</li>
</ul>
<h2 id="question"><a href="#question" class="headerlink" title="question"></a>question</h2><p><img src="https://user-images.githubusercontent.com/46857207/106152049-5a357500-61c0-11eb-9a4a-a4a3b7eeff5d.png" alt="image-20210128141914202"></p>
<ul>
<li>각 벡터마다 max값을 뺴는 이유?<ul>
<li>softmax함수는 exp()힘수를 사용하므로 오버플로우가 발생할 수 있다. 따라서 max값을 벡터의 모든 요소에서 빼면 벡터의 요소들은 -max~0의 값을 가져 exp()함수의 출력은 0~1의 값을 가지게 된다.</li>
</ul>
</li>
</ul>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/AI/page/2/">Previous</a></div><div class="pagination-next"><a href="/categories/AI/page/4/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/AI/">1</a></li><li><a class="pagination-link" href="/categories/AI/page/2/">2</a></li><li><a class="pagination-link is-current" href="/categories/AI/page/3/">3</a></li><li><a class="pagination-link" href="/categories/AI/page/4/">4</a></li></ul></nav></div><div class="column column-left is-3-tablet is-3-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/./img/avatar.jpg" alt="Keonwoo Choi"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Keonwoo Choi</p><p class="is-size-6 is-block">blog</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Korea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">39</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/KeonwooChoi" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/KeonwooChoi"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">39</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI/BoostCamp/"><span class="level-start"><span class="level-item">BoostCamp</span></span><span class="level-end"><span class="level-item tag">38</span></span></a></li><li><a class="level is-mobile" href="/categories/AI/Pytorch/"><span class="level-start"><span class="level-item">Pytorch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-29T16:00:24.000Z">2021-03-30</time></p><p class="title"><a href="/2021/03/30/BoostCamp/Project%20Stage/Day41/">Day41</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-22T06:59:30.000Z">2021-03-22</time></p><p class="title"><a href="/2021/03/22/BoostCamp/Day40/">Day40</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-19T06:59:34.000Z">2021-03-19</time></p><p class="title"><a href="/2021/03/19/BoostCamp/Day39/">Day39</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-18T06:38:26.000Z">2021-03-18</time></p><p class="title"><a href="/2021/03/18/BoostCamp/Day38/">Day38</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-18T06:38:19.000Z">2021-03-18</time></p><p class="title"><a href="/2021/03/18/BoostCamp/Day37/">Day37</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/03/"><span class="level-start"><span class="level-item">March 2021</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/02/"><span class="level-start"><span class="level-item">February 2021</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">January 2021</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></div></div></div><!--!--></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">blog</a><p class="is-size-7"><span>&copy; 2021 Keonwoo Choi</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>