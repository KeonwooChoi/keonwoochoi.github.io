<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="blog"><meta name="msapplication-TileImage" content="./img/favicon3.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="blog"><meta property="og:url" content="https://keonwoochoi.github.io/"><meta property="og:site_name" content="blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://keonwoochoi.github.io/img/og_image.png"><meta property="article:author" content="Keonwoo Choi"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://keonwoochoi.github.io"},"headline":"blog","image":["https://keonwoochoi.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Keonwoo Choi"},"description":""}</script><link rel="icon" href="/./img/favicon3.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">blog</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-10-tablet is-10-desktop is-10-widescreen"><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/03/10/BoostCamp/Day32/"><img class="fill" src="/img/boostcamp.png" alt="Day32"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-10T06:23:14.000Z" title="2021-3-10 3:23:14 ├F10: PM┤">2021-03-10</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:32:51.989Z" title="2021-3-22 6:32:51 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">11 minutes read (About 1606 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/03/10/BoostCamp/Day32/">Day32</a></h1><div class="content"><h1 id="Problems-with-deeper-layers"><a href="#Problems-with-deeper-layers" class="headerlink" title="Problems with deeper layers"></a>Problems with deeper layers</h1><h2 id="Going-deeper-with-convolutions"><a href="#Going-deeper-with-convolutions" class="headerlink" title="Going deeper with convolutions"></a>Going deeper with convolutions</h2><ul>
<li>larger receptive fields</li>
<li>more capacity and non linearity</li>
<li>but gradient vanishing/exploding, computationally complex</li>
<li>degradation problem, not overfitting</li>
</ul>
<h1 id="CNN-artchitectures-for-image-classification"><a href="#CNN-artchitectures-for-image-classification" class="headerlink" title="CNN artchitectures for image classification"></a>CNN artchitectures for image classification</h1><h2 id="GoogLenet"><a href="#GoogLenet" class="headerlink" title="GoogLenet"></a>GoogLenet</h2><ul>
<li><p>여러 합성곱 및 풀링 레이어에 대한 병렬적 연산을 수행-&gt;concat</p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110585642-727fb300-81b4-11eb-8f0f-ba86c6795084.png" alt="image-20210309091646305"></p>
</li>
<li>The increased network size increases the use of computational resources -&gt; 1x1 conv<ul>
<li>필터 수가 출력의 채널이 되어, 채널을 줄일 수 있게 됨</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585644-73184980-81b4-11eb-9667-108221994f06.png" alt="image-20210309091759394"></li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585647-73184980-81b4-11eb-8c5f-cebb63f266ca.png" alt="image-20210309092141934"><ul>
<li>각 Inception 블록마다 단계별로 loss값을 구하는 경로를 마련</li>
<li>최종 Output에 대한 loss와 Auxiliary Classifier로부터 얻은 loss를 모두 종합하여 역전파 수행</li>
</ul>
</li>
</ul>
<h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><ul>
<li>depth가 성능에 중요</li>
<li>overfitting이 아니라 degradation problem</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585649-73b0e000-81b4-11eb-9642-83d24d1927b5.png" alt="image-20210309093050034"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585650-73b0e000-81b4-11eb-9821-0880873bafb9.png" alt="image-20210309093132356"><ul>
<li>Skip-Connection을 하나 추가할 때마다 Gradient 전파경로의 경우의 수가 2배 증가하여, Gradient 전파에 대한 시간 복잡도는 O(2^n)</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1605.06431.pdf">[참고]Residual Networks Behave Like Ensembles of Relatively Shallow Networks</a></li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585653-74497680-81b4-11eb-8b65-d4659e7d30d8.png" alt="image-20210309093258843"></li>
</ul>
<h2 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h2><ul>
<li>이전의 모든 레이어에 대한 정보들을 입력값으로 넣어줌-&gt; Concat하며 학습</li>
<li>채널이 늘어남으로 메모리도 늘어남 ,but feature 보존</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585657-757aa380-81b4-11eb-989f-a22351e490a2.png" alt="image-20210309094132892"></li>
</ul>
<h2 id="SENet"><a href="#SENet" class="headerlink" title="SENet"></a>SENet</h2><ul>
<li><p><strong>Squeeze &amp; Excitation Block</strong></p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110585659-757aa380-81b4-11eb-9527-52052db5ff04.png" alt="image-20210309094258516"></p>
</li>
</ul>
<h2 id="EfficientNet"><a href="#EfficientNet" class="headerlink" title="EfficientNet"></a>EfficientNet</h2><ul>
<li>성능을 높이는 방법에 따라 Saturation Point가 다름</li>
<li><p>각각의 유용한 방법들을 적절한 비율로 동시 scaling 함</p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110585663-76abd080-81b4-11eb-9cf6-f671e5d36b72.png" alt="image-20210309094415737"></p>
</li>
</ul>
<h2 id="Deformable-convolution"><a href="#Deformable-convolution" class="headerlink" title="Deformable convolution"></a>Deformable convolution</h2><ul>
<li>사람과 동물같은 deformable한 형태를 고려</li>
<li><p>리드를 활용하여 객체를 유연하게 파악</p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110585665-77dcfd80-81b4-11eb-9522-a8db2e012546.png" alt="image-20210309094743706"></p>
</li>
</ul>
<h1 id="Semantic-segmentation"><a href="#Semantic-segmentation" class="headerlink" title="Semantic segmentation"></a>Semantic segmentation</h1><ul>
<li>이미지 분류를 영상 단위가 아니라 픽셀 별로 하는 것. 단, 같은 클래스(종류)이면서 서로 다른 물체(개체)를 구분하지는 않는다</li>
</ul>
<h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><h2 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h2><ul>
<li>입력부터 출력까지 모두 인공신경망으로만 구성된 end-to-end 구조</li>
<li>어떤 사이즈의 이미지도 입력할 수 있고, 입력 이미지와 동일한 크기의 Segmentation 결과를 얻을 수 있음</li>
<li>Fully Connected 구조를 사용하지 않고 업샘플링을 적용하여 저해상도 문제를 해결<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/110585666-77dcfd80-81b4-11eb-8fab-4fb8c8ff1bfc.png" alt="image-20210309101313587"></li>
</ul>
</li>
<li>1×1 Conv 레이어를 활용하여 Spatial Information을 유지-&gt;히트맵을 얻음<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/110585668-78759400-81b4-11eb-9910-4034bf304129.png" alt="image-20210309101701902"></li>
<li>1×1 Conv 레이어를 활용하면 채널 간 압축 과정 일어남</li>
<li>이는 기존의 Feature Map을 채널을 주축으로 Flatten하여 FC 레이어를 적용하는 것과 같음</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585838-9b07ad00-81b4-11eb-902d-65550b438112.png" alt="image-20210310132814603"></li>
</ul>
</li>
</ul>
<h2 id="Upsampling"><a href="#Upsampling" class="headerlink" title="Upsampling"></a>Upsampling</h2><ul>
<li>저해상도 문제를 회피하기 위한 방법</li>
<li>Conv, Pooling 레이어를 줄일수록 receptive field가 줄어들기 떄문에 일단은 작게 만들어서 receptive field 키워서 영상의 전반적인 context 파악할 수 있게 함</li>
<li><p>이후 upsampling을 통해 강제로 해상도 맞춰줌</p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110585669-790e2a80-81b4-11eb-8c7f-3021367be96e.png" alt="image-20210309102112044"></p>
</li>
<li>Tranposed convolution<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/110585839-9b07ad00-81b4-11eb-9aae-8ef4ccac3448.png" alt="image-20210310133454920"></li>
<li>입력 이미지에 필터를 적용하여 사이즈를 크게 변환하는 방법</li>
<li>연산 과정에서 중첩 문제가 발생하는데 (checkboard artifact), 때문에 필터 사이즈와 Stride에 대한 튜닝이 필수적</li>
<li>overlap되는 구간은 다른 구간들보다 상대적으로 출력값이 높아 진해짐</li>
</ul>
</li>
<li>upsample and convolution<ul>
<li>interpolution과 convolution을 분리</li>
<li>upsampling을 통해 중첩 문제가 없이 골고루 영향을 받게 함</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585670-79a6c100-81b4-11eb-85fc-1264294a779d.png" alt="image-20210309102334856"></li>
</ul>
</li>
<li>low-level의 detail, local + high-leve의 global<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/110585671-79a6c100-81b4-11eb-82e2-dd584518ab98.png" alt="image-20210309102435541"></li>
<li>높은 layer의 activation map을 upsampling하여 해상도를 크게 끌어올린다.</li>
<li>이에 맞추어 중간 layer의 activation map을 upsampling하여 가져오고, concat한다.</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585674-7a3f5780-81b4-11eb-8d2c-aa0fe4b79d3e.png" alt="image-20210309102546068"></li>
</ul>
<h2 id="Hypercolumns-for-object-segmentation"><a href="#Hypercolumns-for-object-segmentation" class="headerlink" title="Hypercolumns for object segmentation"></a>Hypercolumns for object segmentation</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/110585676-7ad7ee00-81b4-11eb-8564-ed6fb656d312.png" alt="image-20210309102627045"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585677-7b708480-81b4-11eb-8487-e0aa45fc0567.png" alt="image-20210309102645821"></li>
</ul>
<h2 id="U-Net"><a href="#U-Net" class="headerlink" title="U-Net"></a>U-Net</h2><ul>
<li><p>FCN기반</p>
</li>
<li><p>낮은 레이어와 높은 레이어에 있는 결과를 더 잘 결합하는 방법을 제시함</p>
</li>
<li>Contracting Path<ul>
<li>풀링하면서 receptive field를 크게 확보하기 위해 해상도를 낮추고 채널수를 늘림</li>
</ul>
</li>
<li><p>Expanding Path</p>
<ul>
<li>채널 사이즈가 점점 줄어들지만 해상도는 늘어남</li>
<li>대칭되는 Contracting path의 layer에서 skip connection을 통해 대칭되는 feature map들을 가져와서 concat</li>
<li>한번에 Upsampling 하지 않고 차례대로 단계적으로 해상도를 올려줌</li>
</ul>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110585680-7c091b00-81b4-11eb-8df0-b7deecea8cb0.png" alt="image-20210309102718011"></p>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585681-7c091b00-81b4-11eb-8ec9-e7e2bb327e2e.png" alt="image-20210309102801471"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585683-7ca1b180-81b4-11eb-92e8-26e681db668e.png" alt="image-20210309102812247"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585687-7ca1b180-81b4-11eb-9b00-0d8177c03100.png" alt="image-20210309102900873"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585690-7d3a4800-81b4-11eb-8f69-e8b0d1f0863a.png" alt="image-20210309102912950"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585693-7dd2de80-81b4-11eb-9463-d10cfa6fa7c7.png" alt="image-20210309102925369"></li>
<li>이미지 사이즈를 모두 짝수로 유지해야 함<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/110585695-7dd2de80-81b4-11eb-92e6-7605f09878e4.png" alt="image-20210309102939118"></li>
</ul>
</li>
</ul>
<h2 id="DeepLab"><a href="#DeepLab" class="headerlink" title="DeepLab"></a>DeepLab</h2><ul>
<li>후처리에 CRFs 사용<ul>
<li>픽셀과 픽셀 사이의 관계 이어줌</li>
<li>regular한 pixel map을 그리드로 봄→ 최적화를 통해 경계 잘 찾을 수 있도록 모델링</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585697-7e6b7500-81b4-11eb-89d6-4382ddc15e9d.png" alt="image-20210309104221164"></li>
</ul>
</li>
<li>Atrous convolution<ul>
<li>컨볼루션 필터 사이에 Dilation factor 만큼 일정한 공간을 넣어줌</li>
<li>파라미터 수는 늘리지 않으면서 receptive field는 exponential하게 키울 수 있다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585699-7f040b80-81b4-11eb-86ee-840b32229dd2.png" alt="image-20210309104357419"></li>
</ul>
</li>
<li>Depthwise separable convolution<ul>
<li>기존의 convolution 연산은 하나의 필터를 모든 input 채널에 대입시켰다.</li>
<li>기본 convolution 연산을 둘로 나눠서 conv 의 표현력을 어느정도 유지하면서 계산량은 획기적으로 줄어듦</li>
<li>채널 별로 conv 해서 각각 값을 뽑음 + 1x1 conv 통해 하나의 값으로 출력되게 만듦</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585700-7f9ca200-81b4-11eb-9155-26bd1eb08655.png" alt="image-20210309104416065"></li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585704-80353880-81b4-11eb-8891-7bdb21048ce1.png" alt="image-20210309104555324"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585706-80cdcf00-81b4-11eb-945b-f727edcb2181.png" alt="image-20210309104605246"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110585709-81666580-81b4-11eb-8923-7bb34e41dad7.png" alt="image-20210309104614535"></li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/03/09/BoostCamp/Day31/"><img class="fill" src="/img/boostcamp.png" alt="Day31"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-09T04:29:29.000Z" title="2021-3-9 1:29:29 ├F10: PM┤">2021-03-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:32:45.726Z" title="2021-3-22 6:32:45 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">15 minutes read (About 2232 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/03/09/BoostCamp/Day31/">Day31</a></h1><div class="content"><h1 id="Course-overview"><a href="#Course-overview" class="headerlink" title="Course overview"></a>Course overview</h1><h2 id="What-is-computer-vision"><a href="#What-is-computer-vision" class="headerlink" title="What is computer vision?"></a>What is computer vision?</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/110418652-4e9c6e80-80db-11eb-88bc-33457d710002.png" alt="image-20210308091617960"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418654-4f350500-80db-11eb-905a-20146863ecc4.png" alt="image-20210308091711863"><ul>
<li>시각적 데이터에서 representation을 추출하는 일을 Inverse Rendering이라고 한다</li>
<li>representation을 통해 장면에 해당하는 이미지나 3D 모델을 재구현하는것을 Computer Graphics, 또는 렌더링(Rendering)이라고 한다.</li>
</ul>
</li>
<li>How to implement?<ul>
<li>머신러닝: feature를 사용자가 직접 지정해주는 작업 필요 =&gt; 딥러닝의 경사하강법을 통한 feature extraction과 대조</li>
<li>딥러닝: 이미지를 입력받아 내부적으로 추상적인 변수를 추출(feature extraction)<ul>
<li>정답을 예측하는 과정에서 feature를 update</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418656-4fcd9b80-80db-11eb-89f5-ee8bb21264b0.png" alt="image-20210308092029375"></li>
</ul>
</li>
</ul>
<h2 id="What-you-will-learn-in-this-course"><a href="#What-you-will-learn-in-this-course" class="headerlink" title="What you will learn in this course"></a>What you will learn in this course</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/110418658-4fcd9b80-80db-11eb-8a63-6965c218c280.png" alt="image-20210308092307918"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418661-50fec880-80db-11eb-996f-5b0e4d3076e9.png" alt="image-20210308092341446"></li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110418663-50fec880-80db-11eb-9510-7f9c895633de.png" alt="image-20210308092351755"></p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110418666-51975f00-80db-11eb-97c3-82a1234f5887.png" alt="image-20210308092413994"></p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110418667-522ff580-80db-11eb-936d-9708c5d48f85.png" alt="image-20210308092424390"></p>
</li>
</ul>
<h1 id="Image-classification"><a href="#Image-classification" class="headerlink" title="Image classification"></a>Image classification</h1><h2 id="What-is-classification"><a href="#What-is-classification" class="headerlink" title="What is classification"></a>What is classification</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/110418668-522ff580-80db-11eb-9f11-b6a55c452250.png" alt="image-20210308092643818"></li>
</ul>
<h2 id="An-ideal-approach-for-image-recognition"><a href="#An-ideal-approach-for-image-recognition" class="headerlink" title="An ideal approach for image recognition"></a>An ideal approach for image recognition</h2><ul>
<li><p>가장 이상적인 classifier는 세상에 존재하는 <strong>모든 이미지 데이터를 “유사한” 이미지끼리 모아서<code>KNN(K-Nearest Neighbors)</code> 을 적용</strong>하는 것이다. <img src="https://user-images.githubusercontent.com/46857207/110418669-52c88c00-80db-11eb-991f-430cb0c1e390.png" alt="image-20210308092742426"></p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110418671-53612280-80db-11eb-91c4-43c468161e7f.png" alt="image-20210308092943271"></p>
</li>
<li>영상간 유사도를 정의하는 것도 쉬운일이 아님</li>
</ul>
<h2 id="NN-vs-CNN"><a href="#NN-vs-CNN" class="headerlink" title="NN vs CNN"></a>NN vs CNN</h2><ul>
<li><p>NN의 가장 큰 문제점은 <strong>이미지 전체의 패턴에 대해 학습</strong>했기 때문에, 가령 <strong>반쯤 잘리거나 학습된 이미지의 패턴과는 전혀 다른 이미지가 주어진다면 올바른 결과를 내지 못하는 것에 있다.</strong> 또한 <strong>이미지의 크기가 커진다면 학습해야할 파라미터의 수가 증가</strong>한다</p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110418673-53612280-80db-11eb-9e25-b38d17b2fabf.png" alt="image-20210308093038831"></p>
</li>
<li>CNN 은 Fully-connected layer가 아닌 Locally-connected layer 를 통해 <strong>local feature들을 학습</strong>하게 하고, <strong>파라미터를 공유(shared parameter)</strong> 함으로써 <strong>학습해야 할 파라미터의 수를 줄일수 있도록</strong> 디자인 하였다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418675-53f9b900-80db-11eb-9625-556ce9a3b175.png" alt="image-20210308093513900"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418677-53f9b900-80db-11eb-84fa-de40fb2c3e96.png" alt="image-20210308093714664"></li>
</ul>
<h1 id="CNN-architectures-for-image-classification1"><a href="#CNN-architectures-for-image-classification1" class="headerlink" title="CNN architectures for image classification1"></a>CNN architectures for image classification1</h1><h1 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h1><ul>
<li>2012년 ILSVRC에서 1위를 차지한 모델</li>
<li>합성곱 연산과 풀링 연산이 반복되는 구조<ul>
<li>합성곱 필터 크기/stride: 11×11, 5×5, 3×3 / 1<ul>
<li>이전의 LeNet보다 크기가 큰 이미지를 입력받아, 더 큰 필터를 사용</li>
</ul>
</li>
<li>풀링 필터 크기/stride: 2 × 2 / 2</li>
</ul>
</li>
<li>7개의 레이어, 605K개의 노드, 60M개의 파라미터</li>
<li>1.2M개의 학습 데이터를 활용</li>
<li><p>ReLU, Dropout 활용</p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110418678-54924f80-80db-11eb-98ad-596d4933d447.png" alt="image-20210308093857600"></p>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418682-552ae600-80db-11eb-9d9c-77128ca3cfef.png" alt="image-20210308094240009"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418683-552ae600-80db-11eb-9aeb-037723918c7a.png" alt="image-20210308094352038"><ul>
<li>명암을 normalization</li>
<li>지금은 사용 안함</li>
<li>대신 batch normalization 사용</li>
</ul>
</li>
<li>Receptive field<ul>
<li>입력된 이미지 일부가 합성곱/풀링 과정을 거쳐 한 픽셀로 맵핑되었을 떄, 일부 입력의 크기를 의미</li>
<li>즉, 각 필터가 입력 이미지의 어느 부분만큼 인식하는 지를 의미</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418686-55c37c80-80db-11eb-8b30-81cd37cf6ae4.png" alt="image-20210308094625467"></li>
</ul>
</li>
</ul>
<h2 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/110418690-578d4000-80db-11eb-8ff1-306cc0becdb5.png" alt="image-20210308094708282"><ul>
<li>깊은 레이어</li>
<li>no local response normalization</li>
<li>only 3x3 filter, 2x2 max pool<ul>
<li>커널 사이즈가 커지면 receptive field 가 커지고, 그만큼 많은 영역의 정보를 파악할 수 있다. 반면 학습해야하는 parameter의 수가 커지는 문제점이 있다</li>
<li><strong><code>5x5</code> receptive field 는 두개의 <code>3x3</code> 커널을 이용하는 것 과 같으면서 parameter의 수는 줄어든다</strong></li>
</ul>
</li>
<li>better performance</li>
<li>better generalization<ul>
<li>다른 task적용</li>
</ul>
</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418693-5825d680-80db-11eb-8b1d-e402307d8ab2.png" alt="image-20210308094900090"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418696-59570380-80db-11eb-8adf-281dff9c524b.png" alt="image-20210308094945220"><ul>
<li>작은 커널 사이즈로도 깊게 쌓으면 큰 receptive field를 얻을 수 있다-&gt; 이미지 많은 부븐을 고려 할 수 있다</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418698-59570380-80db-11eb-8060-b1e8c16cbdc1.png" alt="image-20210308095117725"></li>
</ul>
<h1 id="Data-augmentation"><a href="#Data-augmentation" class="headerlink" title="Data augmentation"></a>Data augmentation</h1><h2 id="Learning-representation-of-dataset"><a href="#Learning-representation-of-dataset" class="headerlink" title="Learning representation of dataset"></a>Learning representation of dataset</h2><ul>
<li>Dataset is (almost) always biased<ul>
<li>Images taken by camera(trainingdata)≠ realdata</li>
</ul>
</li>
<li>양질의 이미지를 얻기는 어렵고 고비용 =&gt; 기존의 이미지를 변형하여 학습 데이터로 활용</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418699-59ef9a00-80db-11eb-8436-353f7653e5b1.png" alt="image-20210308100103147"></li>
<li>Augmenting data to fill more space and to close the gap</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418703-5a883080-80db-11eb-9659-4543ea7380de.png" alt="image-20210308100420379"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418705-5a883080-80db-11eb-846d-672cf018efd4.png" alt="image-20210308100431686"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418707-5b20c700-80db-11eb-8b88-2ee5de06816d.png" alt="image-20210308100451092"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418710-5bb95d80-80db-11eb-8caf-53b73c457f8b.png" alt="image-20210308100509050"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418712-5c51f400-80db-11eb-8c17-ca15a2f13c92.png" alt="image-20210308100915719"></li>
<li>어떤 aug사용?</li>
<li>많은 augmentation 기법이 존재하지만 최적의 기법을 찾는것은 어렵다. 또한 한번의 augmentation이 아닌 <strong>일련의 augmentation(Policy)</strong> 을 수행할 필요도 있다.</li>
<li>RandAugment는 자동으로 <strong>최적의 policy를 찾아 어느정도의 강도로 적용할지 찾는 것을 목표</strong>로 한다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418714-5c51f400-80db-11eb-912e-e02654591272.png" alt="image-20210308101030019"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418717-5cea8a80-80db-11eb-8497-065f6b90784b.png" alt="image-20210308101107163"></li>
</ul>
<h1 id="Leveraging-pre-trained-information"><a href="#Leveraging-pre-trained-information" class="headerlink" title="Leveraging pre-trained information"></a>Leveraging pre-trained information</h1><h2 id="Transfer-learning"><a href="#Transfer-learning" class="headerlink" title="Transfer learning"></a>Transfer learning</h2><ul>
<li>The high-quality dataset is expensive and hard to obtain</li>
<li>Knowledge learned from one dataset can be applied to other datasets!</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418719-5cea8a80-80db-11eb-9efb-c8da6c3d2c0b.png" alt="image-20210308101518481"><ul>
<li>Pre-trained model에서 기존의 FC layer를 target task에 맞는 FC layer를 적용하여 pretrained model의 convolution layer 들의 가중치는 freeze 하고 FC layer의 가중치만 학습을 하는 방법이다. 따라서 <strong>학습데이터셋이 적더라도 적은 파라미터만 학습 시키기 때문에 효율적으로 학습</strong>시킬 수 있다.</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418721-5e1bb780-80db-11eb-96d0-b0205b5a522b.png" alt="image-20210308101543371"><ul>
<li><strong>pretrained model 의 convolution layer도 같이 학습</strong>하게 하는데, <strong>convolution layer 의 learning rate 는 낮게</strong> / <strong>target task를 위한 FC layer 는 높게 학습</strong> 하도록 하여 target task 에 빠르게 적응하도록 한다. 따라서 위의 방법보단 더 많은 파라미터를 학습시키기 때문에 조금 더 많은 데이터셋이 필요할 수 있다.</li>
</ul>
</li>
</ul>
<h2 id="Knowledge-distillation"><a href="#Knowledge-distillation" class="headerlink" title="Knowledge distillation"></a>Knowledge distillation</h2><ul>
<li><strong>pretrained model(Teacher Model) 의 학습된 지식을 더 작은 model(Student Model)로 지식을 전달하여 모델을 압축</strong>하는 방법이다.<strong><code>KL-divergence loss</code> 를 통해 teacher model의 output distribution과 student model 의 output distribution 이 유사해지도록 학습</strong>을 한다. 이때, <strong>student model의 데이터셋이 없다면 unsupervised-learning</strong> 으로 진행되어 <strong>student model 만을 업데이트</strong>하게 된다</li>
<li><p>teacher model의 출력 label(예측)을 ground truth 레이블인 것 처럼 소형 모델에게 학습시키는 <code>pseudo-labeling</code> 방식으로도 사용되고 있다.</p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110418723-5e1bb780-80db-11eb-8f1a-6a08fbb7f689.png" alt="image-20210308101727950"></p>
</li>
<li>레이블을 활용하지 않는 경우<ul>
<li>Student 모델이 Teacher 모델의 Inference와 가까워지도록 학습</li>
<li>KL-div</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418841-873c4800-80db-11eb-85c5-603ca7162ac0.png" alt="image-20210309132604257"></li>
</ul>
</li>
<li>레이블을 활용할 경우<ul>
<li>Teacher 모델의 Inference와 Ground Truth를 모두 참고하여 학습. 즉, Teacher 모델을 모사함과 동시에 정확성을 높이는 셈</li>
<li>Teacher 모델의 Inference와의 괴리와 Ground Truth와의 괴리를 가중합한 Loss를 바탕으로 역전파, Student 모델을 업데이트</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418838-86a3b180-80db-11eb-89b9-e5b0055c7a5c.png" alt="image-20210309132509440"></li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418729-5f4ce480-80db-11eb-858d-139ee0b4ce9c.png" alt="image-20210308102055943"></li>
<li><code>softmax with temperature T(Soft Prediction)</code>의 경우 <strong>출력의 값을 smooth 하게 만들어주는 기능</strong> 을 한다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418843-87d4de80-80db-11eb-9071-cab62feb6bed.png" alt="image-20210309132632857"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418732-6116a800-80db-11eb-9253-bfcc0f36b2ac.png" alt="image-20210308102436978"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418735-62e06b80-80db-11eb-83d4-203e210b5368.png" alt="image-20210308102624212"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/110430442-c1afe000-80ef-11eb-8b2c-04f33a81d3f8.png" alt="image-20210309155414114"></li>
</ul>
<h1 id="Leveraging-unlabeled-dataset-for-training"><a href="#Leveraging-unlabeled-dataset-for-training" class="headerlink" title="Leveraging unlabeled dataset for training"></a>Leveraging unlabeled dataset for training</h1><p>일반적으로 <strong>많은 데이터들은 unlabeled data 이며 labeled data 는 극히 일부분</strong>이다. 그렇다면 <strong>unlabeled data를 활용하여 학습할 수 있는 방법</strong>은 없을까?</p>
<h2 id="Semi-supervised-learning"><a href="#Semi-supervised-learning" class="headerlink" title="Semi-supervised learning"></a>Semi-supervised learning</h2><ul>
<li><strong>labeled data를 활용하여 학습된 pretrained model</strong> 로 <strong>unlabeled data를 예측하여 pseudo-labeled data를 생성</strong>하고 <strong>labeled data 와 pseudo-labeled data를 활용하여 pretrained model 또는 새로운 model을 재학습</strong>한다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418760-6ecc2d80-80db-11eb-9c48-a38812782ef3.png" alt="image-20210308102830818"></li>
</ul>
<h2 id="Self-training"><a href="#Self-training" class="headerlink" title="Self-training"></a>Self-training</h2><ul>
<li>Augmentation + Teacher-Student Network + Semi-supervised Learning</li>
<li>사전학습된 Teacher Model을 통해 Pseudo Labeling을 진행, 사용 가능한 모든 데이터를 통해 Student Model을 학습</li>
<li>Knowledge Distillation의 학습 방식과 같이, Ground Truth와 Teacher Model의 Inference를 모두 고려하여 학습</li>
<li><p>Student 모델이 Teacher Model의 성능을 넘을 경우, 해당 모델을 Teacher Model로 대체. 다시 위 과정을 반복</p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/110418776-755aa500-80db-11eb-960a-6bebd52542fe.png" alt="image-20210308102910633"></p>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418784-78ee2c00-80db-11eb-9c6c-b414d20b1642.png" alt="image-20210308103040541"><ul>
<li>student model이 계속 커짐</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/110418786-78ee2c00-80db-11eb-8e24-3e353cf0a391.png" alt="image-20210308103128975"></li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/03/05/BoostCamp/Day30/"><img class="fill" src="/img/boostcamp.png" alt="Day30"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-05T06:35:03.000Z" title="2021-3-5 3:35:03 ├F10: PM┤">2021-03-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:32:40.179Z" title="2021-3-22 6:32:40 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">a few seconds read (About 6 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/03/05/BoostCamp/Day30/">Day30</a></h1><div class="content"><h1 id="AI-ML-퀀트"><a href="#AI-ML-퀀트" class="headerlink" title="AI/ML 퀀트"></a>AI/ML 퀀트</h1><h1 id="AI-Ethics"><a href="#AI-Ethics" class="headerlink" title="AI Ethics"></a>AI Ethics</h1></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/03/05/BoostCamp/Day29/"><img class="fill" src="/img/boostcamp.png" alt="Day29"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-05T06:34:42.000Z" title="2021-3-5 3:34:42 ├F10: PM┤">2021-03-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:32:36.097Z" title="2021-3-22 6:32:36 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">a few seconds read (About 21 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/03/05/BoostCamp/Day29/">Day29</a></h1><div class="content"><h1 id="언어-모델링"><a href="#언어-모델링" class="headerlink" title="언어 모델링"></a>언어 모델링</h1><h1 id="내가-만든-AI-모델은-합법일까-불법일까"><a href="#내가-만든-AI-모델은-합법일까-불법일까" class="headerlink" title="내가 만든 AI 모델은 합법일까, 불법일까"></a>내가 만든 AI 모델은 합법일까, 불법일까</h1></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/03/03/BoostCamp/Day28/"><img class="fill" src="/img/boostcamp.png" alt="Day28"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-03T06:30:12.000Z" title="2021-3-3 3:30:12 ├F10: PM┤">2021-03-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:32:29.892Z" title="2021-3-22 6:32:29 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">a few seconds read (About 31 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/03/03/BoostCamp/Day28/">Day28</a></h1><div class="content"><h1 id="캐글-경진대회-노하우"><a href="#캐글-경진대회-노하우" class="headerlink" title="캐글 경진대회 노하우"></a>캐글 경진대회 노하우</h1><ul>
<li>자신만의 파이프라인 구축</li>
<li>notebooks탭 참고</li>
<li>stratified k fold</li>
</ul>
<h2 id="Full-stack-ML-Engineer"><a href="#Full-stack-ML-Engineer" class="headerlink" title="Full stack ML Engineer"></a>Full stack ML Engineer</h2></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/03/03/BoostCamp/Day27/"><img class="fill" src="/img/boostcamp.png" alt="Day27"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-03T06:30:04.000Z" title="2021-3-3 3:30:04 ├F10: PM┤">2021-03-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:32:22.423Z" title="2021-3-22 6:32:22 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">7 minutes read (About 999 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/03/03/BoostCamp/Day27/">Day27</a></h1><div class="content"><h1 id="서비스-향-AI-모델-개발-VS-수업-학교-연구-AI-모델-개발"><a href="#서비스-향-AI-모델-개발-VS-수업-학교-연구-AI-모델-개발" class="headerlink" title="서비스 향 AI 모델 개발 VS 수업/학교/연구 AI 모델 개발"></a>서비스 향 AI 모델 개발 VS 수업/학교/연구 AI 모델 개발</h1><h2 id="연구-관점에서-AI-개발이란"><a href="#연구-관점에서-AI-개발이란" class="headerlink" title="연구 관점에서 AI 개발이란?"></a>연구 관점에서 AI 개발이란?</h2><ul>
<li>보통 수업/학교/연구에서는 정해진 데이터셋/평가 방식에서 더 좋은 모델을 찾는 일을 한다</li>
</ul>
<h2 id="서비스-관점에서-AI-개발이란"><a href="#서비스-관점에서-AI-개발이란" class="headerlink" title="서비스 관점에서 AI 개발이란?"></a>서비스 관점에서 AI 개발이란?</h2><ul>
<li>서비스 개발 시에는 학습 데이터셋도 없고, 테스트 데이터셋과 테스트 방법도 없다.</li>
<li>서비스 개발 시에는 서비스 요구 사항만이 있다.</li>
<li>그래서, 첫 번째로 해야 할 일은 학습 데이터셋을 준비하는 것이다.</li>
<li>정확히는 서비스 요구사항으로 부터 학습 데이터셋의 종류/수량/정답을 정해야 한다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109763297-3e951280-7c35-11eb-9c1a-3a359fd840b4.png" alt="image-20210302091752781"></li>
<li>지금까지의 이야기를 종합하면, 다음과 같은 입출력을 갖는 기술 모듈을 개발해 달라는 요청</li>
<li>결국 학습 데이터 준비를 하려면 모델 파이프 라인 설계가 되어 있어야 한다!</li>
<li>그런데, 모델 파이프 라인 설계 하려면 어느 정도 데이터가 있어야 한다!</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109763304-3fc63f80-7c35-11eb-8747-46fe2b19d5d1.png" alt="image-20210302092917232"></li>
</ul>
<h2 id="자-본인이-학습-데이터셋-준비-담당자라고-해보고-어떤-일을-겪게-되는지-살펴보자"><a href="#자-본인이-학습-데이터셋-준비-담당자라고-해보고-어떤-일을-겪게-되는지-살펴보자" class="headerlink" title="자! 본인이 학습 데이터셋 준비 담당자라고 해보고, 어떤 일을 겪게 되는지 살펴보자."></a>자! 본인이 학습 데이터셋 준비 담당자라고 해보고, 어떤 일을 겪게 되는지 살펴보자.</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109763307-3fc63f80-7c35-11eb-82b8-82437cbde0c7.png" alt="image-20210302093238647"></li>
<li>다시 한 번 정리해 보면…</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109763309-405ed600-7c35-11eb-9b5f-72ab272f119e.png" alt="image-20210302093255134"></li>
<li>테스트 데이터셋은 학습 데이터셋에서 일부 사용한다고 하고, (사실은 이것도 할 얘기가 많지만..) 서비스 요구사항으로부터 테스트 방법을 도출해야 한다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109763311-40f76c80-7c35-11eb-8754-3291b67918d2.png" alt="image-20210302093355918"></li>
<li>테스트 방법에 대해 다음처럼 정리할 수 있다.<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109763313-40f76c80-7c35-11eb-9b22-f5e5762c1cee.png" alt="image-20210302093751870"></li>
</ul>
</li>
</ul>
<h2 id="추가로-모델에-관련한-요구사항을-도출해야-합니다"><a href="#추가로-모델에-관련한-요구사항을-도출해야-합니다" class="headerlink" title="추가로, 모델에 관련한 요구사항을 도출해야 합니다."></a>추가로, 모델에 관련한 요구사항을 도출해야 합니다.</h2><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109763315-41900300-7c35-11eb-8236-fab2d117d4e6.png" alt="image-20210302094115890"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109763317-41900300-7c35-11eb-802f-3591b1b0efad.png" alt="image-20210302094318205"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109763318-42289980-7c35-11eb-80dd-2f4532f06717.png" alt="image-20210302094455960"></li>
</ul>
<h2 id="서비스-향-AI-모델-개발-기술팀의-조직-구성"><a href="#서비스-향-AI-모델-개발-기술팀의-조직-구성" class="headerlink" title="서비스 향 AI 모델 개발 기술팀의 조직 구성"></a>서비스 향 AI 모델 개발 기술팀의 조직 구성</h2><ul>
<li>AI 기술팀에게는 서비스 요구사항이 오고, 이에 맞는 AI 모델을 개발해야 한다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109763320-42289980-7c35-11eb-8295-4a4f378a67a5.png" alt="image-20210302094808974"></li>
<li>그런데, 기술팀에 AI 모델 Serving까지 요구되면 필요한 인력은 늘어난다.<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109763322-42c13000-7c35-11eb-8854-54c5779b0e74.png" alt="image-20210302095004548"></li>
</ul>
</li>
<li>마지막으로 모델을 실제 서빙하기 위한 추가 작업들이 end device에 맞춰 더 있다.<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109763325-4359c680-7c35-11eb-94c6-cf5df1f6fb73.png" alt="image-20210302095037789"></li>
</ul>
</li>
</ul>
<h2 id="AI쪽으로-커리어를-쌓고자-하시는-분들에게-드리고-싶은-말씀"><a href="#AI쪽으로-커리어를-쌓고자-하시는-분들에게-드리고-싶은-말씀" class="headerlink" title="AI쪽으로 커리어를 쌓고자 하시는 분들에게 드리고 싶은 말씀"></a>AI쪽으로 커리어를 쌓고자 하시는 분들에게 드리고 싶은 말씀</h2><ul>
<li>개발자 ⇒ AI 관련 전환<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109763327-4359c680-7c35-11eb-81ff-6e44aca10562.png" alt="image-20210302095147607"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109763329-43f25d00-7c35-11eb-8cd5-e27657667bda.png" alt="image-20210302095203154"></li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109763331-43f25d00-7c35-11eb-9b59-c1b0ab35e6c9.png" alt="image-20210302095225118"></li>
</ul>
<hr>
<h1 id="AI-시대의-커리어-빌딩"><a href="#AI-시대의-커리어-빌딩" class="headerlink" title="AI 시대의 커리어 빌딩"></a>AI 시대의 커리어 빌딩</h1><h2 id="Careers-in-AI"><a href="#Careers-in-AI" class="headerlink" title="Careers in AI"></a>Careers in AI</h2><ul>
<li>학교를 가야하나요? 회사를 가야하나요?</li>
<li>AI를 다루는 회사의 종류<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109763334-448af380-7c35-11eb-97ca-bc99a14ca448.png" alt="image-20210302095852320"></li>
</ul>
</li>
<li>AI를 다루는 팀의 구성<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109763336-448af380-7c35-11eb-91e3-27f52bd75a3e.png" alt="image-20210302095936606"></li>
</ul>
</li>
<li>AI 팀에서 엔지니어가 되면 어떤 일을 할까요? 보통 논문 읽고 모델 학습하는 일을 떠올리는 분들이 많습니다만…</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109763339-45238a00-7c35-11eb-9b3d-8083c51830fd.png" alt="image-20210302100038662"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109763342-45bc2080-7c35-11eb-94ab-3e570b8ea47a.png" alt="image-20210302100111645"></li>
<li>현실에서는 정말 다양한 역할이 있고 100% 하나의 포지션의 역할을 수행하는 경우는 드묾</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109763345-45bc2080-7c35-11eb-968b-a34616dc949d.png" alt="image-20210302100215142"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109763348-4654b700-7c35-11eb-8574-864f76b8ed8b.png" alt="image-20210302100651701"></li>
</ul>
<h2 id="How-to-start-my-AI-engineering-career"><a href="#How-to-start-my-AI-engineering-career" class="headerlink" title="How to start my AI engineering career"></a>How to start my AI engineering career</h2><ul>
<li>Understand yourself</li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/03/02/BoostCamp/Day25/"><img class="fill" src="/img/boostcamp.png" alt="Day25"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-02T06:01:15.000Z" title="2021-3-2 3:01:15 ├F10: PM┤">2021-03-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:32:13.481Z" title="2021-3-22 6:32:13 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">18 minutes read (About 2748 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/03/02/BoostCamp/Day25/">Day25</a></h1><div class="content"><h1 id="정점-표현-학습-복습"><a href="#정점-표현-학습-복습" class="headerlink" title="정점 표현 학습 복습"></a>정점 표현 학습 복습</h1><ul>
<li>정점 표현 학습이란 그래프의 정점들을 벡터의 형태로 표현하는 것</li>
<li>정점 임베딩(Node Embedding)</li>
<li>그래프에서의 정점간 유사도를 임베딩 공간에서도 “보존”하는 것</li>
<li>그래프에서 두 정점의 유사도는 어떻게 정의할까<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605141-11c6f980-7b68-11eb-865e-966f1c409d9a.png" alt="image-20210226093909989"></li>
</ul>
</li>
<li>지금까지 소개한 정점 임베딩 방법들을 변환식(Transductive) 방법<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605142-125f9000-7b68-11eb-82ca-23867baee200.png" alt="image-20210226094153894"></li>
</ul>
</li>
<li>출력으로 임베딩 자체를 얻는 변환식 임베딩 방법은 여러 한계를 갖습니다<ol>
<li>학습이 진행된 이후에 추가된 정점에 대해서는 임베딩을 얻을 수 없습니다</li>
<li>모든 정점에 대한 임베딩을 미리 계산하여 저장해두어야 합니다</li>
<li>정점이 속성(Attribute) 정보를 가진 경우에 이를 활용할 수 없습니다</li>
</ol>
</li>
<li>출력으로 인코더를 얻는 귀납식 임베딩 방법은 여러 장점을 갖습니다</li>
</ul>
<ol>
<li>학습이 진행된 이후에 추가된 정점에 대해서도 임베딩을 얻을 수 있습니다</li>
<li>모든 정점에 대한 임베딩을 미리 계산하여 저장해둘 필요가 없습니다</li>
<li>정점이 속성(Attribute) 정보를 가진 경우에 이를 활용할 수 있습니다</li>
</ol>
<h1 id="그래프-신경망-기본"><a href="#그래프-신경망-기본" class="headerlink" title="그래프 신경망 기본"></a>그래프 신경망 기본</h1><h2 id="그래프-신경망-구조"><a href="#그래프-신경망-구조" class="headerlink" title="그래프 신경망 구조"></a>그래프 신경망 구조</h2><ul>
<li>그래프 신경망은 그래프와 정점의 속성 정보를 입력으로 받습니다</li>
<li>정점의 속성의 예시는 다음과 같습니다<ul>
<li>온라인 소셜 네트워크에서 사용자의 지역, 성별, 연령, 프로필 사진 등</li>
<li>논문 인용 그래프에서 논문에 사용된 키워드에 대한 원-핫 벡터</li>
<li>PageRank 등의 정점 중심성, 군집 계수(Clustering Coefficient) 등</li>
</ul>
</li>
<li>그래프 신경망은 이웃 정점들의 정보를 집계하는 과정을 반복하여 임베딩을 얻습니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605144-125f9000-7b68-11eb-8bc1-1f113097bf9a.png" alt="image-20210226095242773"></li>
</ul>
</li>
<li>각 집계 단계를 층(Layer)이라고 부르고, 각 층마다 임베딩을 얻습니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605146-12f82680-7b68-11eb-8d10-6a017869e476.png" alt="image-20210226095302247"></li>
</ul>
</li>
</ul>
<h2 id="그래프-신경망-구조-1"><a href="#그래프-신경망-구조-1" class="headerlink" title="그래프 신경망 구조"></a>그래프 신경망 구조</h2><ul>
<li>대상 정점 마다 집계되는 정보가 상이합니다<ul>
<li>대상 정점 별 집계되는 구조를 계산 그래프(Computation Graph)라고 부릅니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109605150-1390bd00-7b68-11eb-9b59-aef8ed6602ed.png" alt="image-20210226095524752"></li>
</ul>
</li>
<li>서로 다른 대상 정점간에도 층 별 집계 함수는 공유합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605151-1390bd00-7b68-11eb-9ddd-3d656fb3d0ca.png" alt="image-20210226100451998"></li>
</ul>
</li>
<li>서로 다른 구조의 계산 그래프를 처리하기 위해서는 어떤 형태의 집계 함수가 필요할까요?<ul>
<li>집계 함수는 (1) 이웃들 정보의 평균을 계산하고 (2) 신경망에 적용하는 단계를 거칩니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109605152-14295380-7b68-11eb-8617-38114d578cde.png" alt="image-20210226100555822"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109605154-14295380-7b68-11eb-8f79-52fed981cd4c.png" alt="image-20210226100618238"></li>
</ul>
</li>
<li>마지막 층에서의 정점 별 임베딩이 해당 정점의 출력 임베딩입니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605155-14c1ea00-7b68-11eb-8fdd-5a98ffefcb6b.png" alt="image-20210226100815736"></li>
</ul>
</li>
</ul>
<h2 id="그래프-신경망의-학습"><a href="#그래프-신경망의-학습" class="headerlink" title="그래프 신경망의 학습"></a>그래프 신경망의 학습</h2><ul>
<li>그래프 신경망의 학습 변수(Trainable Parameter)는 층 별 신경망의 가중치입니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605158-14c1ea00-7b68-11eb-9ac6-b00ea57645a3.png" alt="image-20210226101307119"></li>
</ul>
</li>
<li>먼저 손실함수를 결정합니다. 정점간 거리를 “보존”하는 것을 목표로 할 수 있습니다<ul>
<li>(그래프 신경망은 비지도 학습, 지도 학습이 모두 가능합니다)</li>
<li>비지도 학습에서는 정점간 거리를 “보존”하는 것을 목표로 합니다</li>
<li>지도 학습에서는 후속 과제의 손실함수를 이용해 종단종 학습을 합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109605159-155a8080-7b68-11eb-808c-3cd8c3a27dfb.png" alt="image-20210226101351951"></li>
</ul>
</li>
<li>후속 과제(Downstream Task)의 손실함수를 이용한 종단종(End-to-End) 학습도 가능합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605160-15f31700-7b68-11eb-95ae-559655f4f009.png" alt="image-20210226101411794"></li>
<li>임베딩이 그래프의 유사도를 보존하는지 여부는 관심이 아니고 분류기의 정확도를 높이는 것이 목표</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109605162-15f31700-7b68-11eb-9371-45c6782e0dbf.png" alt="image-20210226101557375"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109605163-168bad80-7b68-11eb-9573-3301b3064996.png" alt="image-20210226101654895"></li>
</ul>
</li>
<li>그래프 신경망과 변환적 정점 임베딩을 이용한 정점 분류<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605165-168bad80-7b68-11eb-9d06-4485ff209e1b.png" alt="image-20210226101746055"></li>
</ul>
</li>
<li>손실함수를 정의한 후 학습에 사용할 대상 정점을 결정하여 학습 데이터를 구성합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605167-17244400-7b68-11eb-9222-68492883e5e6.png" alt="image-20210226101903383"></li>
</ul>
</li>
<li>마지막으로 오차역전파(Backpropagation)을 통해 손실함수를 최소화합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605168-17244400-7b68-11eb-8954-51320720515e.png" alt="image-20210226101920599"></li>
</ul>
</li>
</ul>
<h2 id="그래프-신경망의-활용"><a href="#그래프-신경망의-활용" class="headerlink" title="그래프 신경망의 활용"></a>그래프 신경망의 활용</h2><ul>
<li>학습된 신경망을 적용하여, 학습에 사용되지 않은 정점의 임베딩을 얻을 수 있습니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605169-17bcda80-7b68-11eb-88b6-56624412c88d.png" alt="image-20210226101958027"></li>
</ul>
</li>
<li>마찬가지로, 학습 이후에 추가된 정점의 임베딩도 얻을 수 있습니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605171-17bcda80-7b68-11eb-952f-6a1d720a3d41.png" alt="image-20210226102022878"></li>
</ul>
</li>
<li>학습된 그래프 신경망을, 새로운 그래프에 적용할 수도 있습니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605172-18557100-7b68-11eb-9439-4ecb97dc2fea.png" alt="image-20210226102046596"></li>
</ul>
</li>
</ul>
<h1 id="그래프-신경망-변형"><a href="#그래프-신경망-변형" class="headerlink" title="그래프 신경망 변형"></a>그래프 신경망 변형</h1><h2 id="그래프-합성곱-신경망"><a href="#그래프-합성곱-신경망" class="headerlink" title="그래프 합성곱 신경망"></a>그래프 합성곱 신경망</h2><ul>
<li>소개한 것 이외에도 다양한 형태의 집계 함수를 사용할 수 있습니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109605173-18557100-7b68-11eb-97ae-37a12b1b1d9a.png" alt="image-20210226102159031"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109605175-18ee0780-7b68-11eb-83ca-e97d9fd7f5fa.png" alt="image-20210226102220785"></li>
</ul>
<h2 id="GraphSAGE"><a href="#GraphSAGE" class="headerlink" title="GraphSAGE"></a>GraphSAGE</h2><ul>
<li>GraphSAGE의 집계 함수입니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605177-19869e00-7b68-11eb-887b-78f3626c3828.png" alt="image-20210226102310506"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109605179-1a1f3480-7b68-11eb-9f9b-fa480c63bc62.png" alt="image-20210226102336009"></li>
</ul>
</li>
</ul>
<h1 id="합성곱-신경망과의-비교"><a href="#합성곱-신경망과의-비교" class="headerlink" title="합성곱 신경망과의 비교"></a>합성곱 신경망과의 비교</h1><h2 id="합성곱-신경망과-그래프-신경망의-유사성"><a href="#합성곱-신경망과-그래프-신경망의-유사성" class="headerlink" title="합성곱 신경망과 그래프 신경망의 유사성"></a>합성곱 신경망과 그래프 신경망의 유사성</h2><ul>
<li>합성곱 신경망과 그래프 신경망은 모두 이웃의 정보를 집계하는 과정을 반복합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605180-1a1f3480-7b68-11eb-8631-167ec7b95918.png" alt="image-20210226102504509"></li>
</ul>
</li>
<li>합성곱 신경망에서는 이웃의 수가 균일하지만, 그래프 신경망에서는 아닙니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605181-1ab7cb00-7b68-11eb-830e-526dfd490c3c.png" alt="image-20210226102536470"></li>
</ul>
</li>
<li>그래프의 인접 행렬에 합성곱 신경망을 적용하면 효과적일까요?<ul>
<li>그래프에는 합성곱 신경망이 아닌 그래프 신경망을 적용하여야 합니다! 많은 분들이 흔히 범하는 실수입니다</li>
<li>합성곱 신경망이 주로 쓰이는 이미지에서는 인접 픽셀이 유용한 정보를 담고 있을 가능성이 높습니다</li>
<li>하지만, 그래프의 인접 행렬에서의 인접 원소는 제한된 정보를 가집니다 특히나, 인접 행렬의 행과 열의 순서는 임의로 결정되는 경우가 많습니다</li>
</ul>
</li>
</ul>
<h1 id="그래프-신경망에서의-어텐션"><a href="#그래프-신경망에서의-어텐션" class="headerlink" title="그래프 신경망에서의 어텐션"></a>그래프 신경망에서의 어텐션</h1><h2 id="기본-그래프-신경망의-한계"><a href="#기본-그래프-신경망의-한계" class="headerlink" title="기본 그래프 신경망의 한계"></a>기본 그래프 신경망의 한계</h2><ul>
<li>기본 그래프 신경망에서는 이웃들의 정보를 동일한 가중치로 평균을 냅니다</li>
<li>그래프 합성곱 신경망에서 역시 단순히 연결성을 고려한 가중치로 평균을 냅니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605185-1b506180-7b68-11eb-88b9-42cf1b10e7be.png" alt="image-20210226111652422"></li>
</ul>
</li>
<li>그래프 어텐션 신경망(Graph Attention Network, GAT)에서는 가중치 자체도 학습합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605186-1be8f800-7b68-11eb-93fe-b38766e8904d.png" alt="image-20210226111708990"></li>
</ul>
</li>
<li>각 층에서 정점 𝑖로부터 이웃 𝑗로의 가중치 𝜶𝒊𝒋는 세 단계를 통해 계산합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605187-1c818e80-7b68-11eb-9b6e-1c007d2e3104.png" alt="image-20210226111748352"></li>
</ul>
</li>
<li>여러 개의 어텐션을 동시에 학습한 뒤, 결과를 연결하여 사용할 수 있다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605188-1c818e80-7b68-11eb-9b93-e93ebfc377f5.png" alt="image-20210226111854772"></li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109605189-1d1a2500-7b68-11eb-95df-502379b2961c.png" alt="image-20210226111912416"></li>
</ul>
<h2 id="그래프-표현-학습과-그래프-풀링"><a href="#그래프-표현-학습과-그래프-풀링" class="headerlink" title="그래프 표현 학습과 그래프 풀링"></a>그래프 표현 학습과 그래프 풀링</h2><h2 id="그래프-표현-학습"><a href="#그래프-표현-학습" class="headerlink" title="그래프 표현 학습"></a>그래프 표현 학습</h2><ul>
<li>그래프 표현 학습, 혹은 그래프 임베딩이란 정점이 아닌 그래프 전체를 벡터의 형태로 표현하는 것입니다</li>
<li>개별 정점을 벡터의 형태로 표현하는 정점 표현 학습과 구분됩니다</li>
<li>그래프 임베딩은 벡터의 형태로 표현된 그래프 자체를 의미하기도 합니다</li>
<li>그래프 임베딩은 그래프 분류 등에 활용됩니다<ul>
<li>그래프 형태로 표현된 화합물의 분자 구조로부터 특성을 예측하는 것이 한가지 예시입니다</li>
</ul>
</li>
</ul>
<h2 id="그래프-풀링"><a href="#그래프-풀링" class="headerlink" title="그래프 풀링"></a>그래프 풀링</h2><ul>
<li>그래프 풀링(Graph Pooling)이란 정점 임베딩들로부터 그래프 임베딩(그래프 전체를 표현하는 벡터)을 얻는 과정입니다</li>
<li>평균 등 단순한 방법보다 그래프의 구조를 고려한 방법을 사용할 경우 그래프 분류 등의 후속 과제에서 더 높은 성능을 얻는 것으로 알려져 있습니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109605191-1db2bb80-7b68-11eb-8594-f158c00124ca.png" alt="image-20210226112121596"><ul>
<li>미분 가능한 풀링은 그래프 신경망의 여러곳에서 사용 가능<ul>
<li>개별정점의 임베딩을 얻는데</li>
<li>군집을 찾는데</li>
<li>군집을 합산하는데</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="지나친-획일화-문제"><a href="#지나친-획일화-문제" class="headerlink" title="지나친 획일화 문제"></a>지나친 획일화 문제</h1><h2 id="지나친-획일화-문제-1"><a href="#지나친-획일화-문제-1" class="headerlink" title="지나친 획일화 문제"></a>지나친 획일화 문제</h2><ul>
<li>지나친 획일화(Over-smoothing) 문제란 그래프 신경망의 층의 수가 증가하면서 정점의 임베딩이 서로 유사해지는 현상을 의미합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605193-1db2bb80-7b68-11eb-90c3-2c105c227d8a.png" alt="image-20210226112522775"></li>
<li>수 많은 정점들로부터 정보를 합산하기 떄문에 그래프의 전반을 집계하는 효과가 있다</li>
</ul>
</li>
<li>지나친 획일화의 결과로 그래프 신경망의 층의 수를 늘렸을 때, 후속 과제에서의 정확도가 감소하는 현상이 발견되었습니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605195-1e4b5200-7b68-11eb-9664-6a970da427ac.png" alt="image-20210226112644804"></li>
</ul>
</li>
</ul>
<h2 id="지나친-획일화-문제에-대한-대응"><a href="#지나친-획일화-문제에-대한-대응" class="headerlink" title="지나친 획일화 문제에 대한 대응"></a>지나친 획일화 문제에 대한 대응</h2><ul>
<li>획일화 문제에 대한 대응으로 JK 네트워크(Jumping Knowledge Network)는 마지막 층의 임베딩 뿐 아니라, 모든 층의 임베딩을 함께 사용합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605197-1ee3e880-7b68-11eb-87b7-a41c719cd206.png" alt="image-20210226112742714"></li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109605199-1ee3e880-7b68-11eb-9a53-b54394cfd22a.png" alt="image-20210226112822802"><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605200-1f7c7f00-7b68-11eb-8dad-6e94da152c29.png" alt="image-20210226112911814"></li>
</ul>
</li>
</ul>
<h1 id="그래프-데이터의-증강"><a href="#그래프-데이터의-증강" class="headerlink" title="그래프 데이터의 증강"></a>그래프 데이터의 증강</h1><h2 id="그래프-데이터-증강"><a href="#그래프-데이터-증강" class="headerlink" title="그래프 데이터 증강"></a>그래프 데이터 증강</h2><ul>
<li>데이터 증강(Data Augmentation)은 다양한 기계학습 문제에서 효과적입니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605204-20151580-7b68-11eb-8b27-6a342e7d391e.png" alt="image-20210226113004671"></li>
</ul>
</li>
<li>그래프 데이터 증강의 결과 정점 분류의 정확도가 개선되는 것을 확인했습니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109605206-20151580-7b68-11eb-8eae-55f938b877a3.png" alt="image-20210226113057726"></li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/26/BoostCamp/Day24/"><img class="fill" src="/img/boostcamp.png" alt="Day24"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-26T05:58:26.000Z" title="2021-2-26 2:58:26 ├F10: PM┤">2021-02-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:32:01.419Z" title="2021-3-22 6:32:01 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">20 minutes read (About 2992 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/26/BoostCamp/Day24/">Day24</a></h1><div class="content"><h1 id="정점-표현-학습"><a href="#정점-표현-학습" class="headerlink" title="정점 표현 학습"></a>정점 표현 학습</h1><h2 id="정점-표현-학습이란"><a href="#정점-표현-학습이란" class="headerlink" title="정점 표현 학습이란"></a>정점 표현 학습이란</h2><ul>
<li>정점 표현 학습이란 그래프의 정점들을 벡터의 형태로 표현하는 것입니다</li>
<li>정점 표현 학습은 간단히 정점 임베딩(Node Embedding)이라고도 부릅니다</li>
<li>정점 임베딩은 벡터 형태의 표현 그 자체를 의미하기도 합니다 정점이 표현되는 벡터 공간을 임베딩 공간이라고 부릅시다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261281-f47dec80-7842-11eb-860e-ea60bd7db502.png" alt="image-20210225103605447"></li>
</ul>
<h2 id="정점-표현-학습의-이유"><a href="#정점-표현-학습의-이유" class="headerlink" title="정점 표현 학습의 이유"></a>정점 표현 학습의 이유</h2><ul>
<li>정점 임베딩의 결과로, 벡터 형태의 데이터를 위한 도구들을 그래프에도 적용할 수 있습니다</li>
<li>분류기(로지스틱 회귀분석, 다층 퍼셉트론 등) 그리고 군집 분석 알고리즘(K-Means, DBSCAN 등)은 벡터 형태로 표현된 사례(Instance)들을 입력으로 받습니다</li>
<li>정점 분류(Node Classification), 군집 분석(Community Detection) 등에 활용</li>
</ul>
<h2 id="정점-표현-학습의-목표"><a href="#정점-표현-학습의-목표" class="headerlink" title="정점 표현 학습의 목표"></a>정점 표현 학습의 목표</h2><ul>
<li>어떤 기준으로 정점을 벡터로 변환해야할까요?<ul>
<li>그래프에서의 정점간 유사도를 임베딩 공간에서도 “보존”하는 것을 목표로 합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261283-f5168300-7842-11eb-9e5a-120f8f2d33da.png" alt="image-20210225103834225"></li>
<li>임베딩 공간에서의 유사도로는 내적(Inner Product)를 사용합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261284-f5168300-7842-11eb-99fa-a3f6a23163aa.png" alt="image-20210225104001731"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261285-f5af1980-7842-11eb-8d22-e6f5857240f3.png" alt="image-20210225104305559"></li>
<li>먼저 인접성을 바탕으로 한 접근법</li>
</ul>
</li>
</ul>
<h1 id="인접성-기반-접근법"><a href="#인접성-기반-접근법" class="headerlink" title="인접성 기반 접근법"></a>인접성 기반 접근법</h1><h2 id="인접성-기반-접근법-1"><a href="#인접성-기반-접근법-1" class="headerlink" title="인접성 기반 접근법"></a>인접성 기반 접근법</h2><ul>
<li>인접성(Adjacency) 기반 접근법에서는 두 정점이 인접할 때 유사하다고 간주합니다</li>
<li>두 정점 𝑢와 𝑣가 인접하다는 것은 둘을 직접 연결하는 간선 (𝑢, 𝑣)가 있음을 의미합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261287-f5af1980-7842-11eb-97dd-0116a42ab597.png" alt="image-20210225104509964"></li>
<li>인접성 기반 접근법의 손실 함수<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261288-f647b000-7842-11eb-9906-dd6dd31a4f2c.png" alt="image-20210225104540249"></li>
</ul>
</li>
<li>인접성만으로 유사도를 판단하는 것은 한계가 있습니다<ul>
<li>빨간색 정점과 파란색 정점은 거리가 3인 반면 초록색 정점과 파란색 정점은 거리가 2입니다</li>
<li>인접성만을 고려할 경우 이러한 사실에 대한 고려 없이, 두 경우의 유사도는 0으로 같습니다</li>
<li>군집 관점에서는 빨간색 정점과 파란색 정점은 다른 군집에 속하는 반면 초록색 정점과 파란색 정점은 같은 군집에 속합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261289-f647b000-7842-11eb-9d75-fcb2cdebd8f8.png" alt="image-20210225105104693"></li>
</ul>
</li>
</ul>
<h1 id="거리-경로-중첩-기반-접근법"><a href="#거리-경로-중첩-기반-접근법" class="headerlink" title="거리/경로/중첩 기반 접근법"></a>거리/경로/중첩 기반 접근법</h1><h2 id="거리-기반-접근법"><a href="#거리-기반-접근법" class="headerlink" title="거리 기반 접근법"></a>거리 기반 접근법</h2><ul>
<li>거리 기반 접근법에서는 두 정점 사이의 거리가 충분히 가까운 경우 유사하다고 간주합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261291-f6e04680-7842-11eb-88b0-bf607dc865c2.png" alt="image-20210225105312470"></li>
</ul>
<h2 id="경로-기반-접근법"><a href="#경로-기반-접근법" class="headerlink" title="경로 기반 접근법"></a>경로 기반 접근법</h2><ul>
<li>경로 기반 접근법에서는 두 정점 사이의 경로가 많을 수록 유사하다고 간주합니다<ul>
<li>복습</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261294-f778dd00-7842-11eb-8937-2f509cbb0d0b.png" alt="image-20210225105528816"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261368-03fd3580-7843-11eb-9a10-b140db1e0f1b.png" alt="image-20210225202814595"></li>
<li>1 4 6 8</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261295-f778dd00-7842-11eb-9854-3e04e9c8abf8.png" alt="image-20210225105735510"></li>
</ul>
<h2 id="중첩-기반-접근법"><a href="#중첩-기반-접근법" class="headerlink" title="중첩 기반 접근법"></a>중첩 기반 접근법</h2><ul>
<li>중첩 기반 접근법에서는 두 정점이 많은 이웃을 공유할 수록 유사하다고 간주합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261297-f8117380-7842-11eb-8657-84eb0f11fc40.png" alt="image-20210225105857781"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261299-f8117380-7842-11eb-86c6-0425d1fea443.png" alt="image-20210225110007261"></li>
<li>공통 이웃 수 대신 자카드 유사도 혹은 Adamic Adar 점수를 사용할 수도 있습니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261303-f942a080-7842-11eb-873f-339cbce40391.png" alt="image-20210225110053574"></li>
<li>$N_u=N_v$일때 즉,두 정점의 이웃들의 집합이 같을 떄 자카드 유사도 1</li>
<li>W(u와v의 공통이웃)의 연결성이 클수록 가중치 낮다 why?<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261305-f942a080-7842-11eb-8965-6451efb3f9e7.png" alt="image-20210225110942133"></li>
<li>u와v가 트와이스를 팔로우한다고 서로 가까운 것은 아님-&gt;낮은 가중치</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="임의-보행-기반-접근법"><a href="#임의-보행-기반-접근법" class="headerlink" title="임의 보행 기반 접근법"></a>임의 보행 기반 접근법</h1><h2 id="임의보행-기반-접근법"><a href="#임의보행-기반-접근법" class="headerlink" title="임의보행 기반 접근법"></a>임의보행 기반 접근법</h2><ul>
<li>임의보행 기반 접근법에서는 한 정점에서 시작하여 임의보행을 할 때 다른 정점에 도달할 확률 을 유사도로 간주합니다</li>
<li>임의보행이란 현재 정점의 이웃 중 하나를 균일한 확률로 선택하는 이동하는 과정을 반복하는 것을 의미합니다</li>
<li>임의보행을 사용할 경우 시작 정점 주변의 지역적 정보와 그래프 전역 정보를 모두 고려한다는 장점이 있습니다<ul>
<li>기존의 거리,경로 기반 접근법은 거리를 k로 제한, 하지만 임의보행 접근법에서는 제한하지 않음, 그런 의미에서 그래프 전역정보 고려</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261306-f9db3700-7842-11eb-957e-2c9cf1650ba1.png" alt="image-20210225111859789"></li>
<li>어떻게 임베딩으로부터 도달 확률을 추정할까요?<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261307-f9db3700-7842-11eb-8d70-8f5cc259c39f.png" alt="image-20210225111943572"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261310-fa73cd80-7842-11eb-947f-f81348e1aa1d.png" alt="image-20210225112028514"></li>
</ul>
</li>
</ul>
<h2 id="DeepWalk-Node2Vec"><a href="#DeepWalk-Node2Vec" class="headerlink" title="DeepWalk, Node2Vec"></a>DeepWalk, Node2Vec</h2><ul>
<li>임의보행의 방법에 따라 DeepWalk와 Node2Vec이 구분됩니다</li>
<li>DeepWalk는 앞서 설명한 기본적인 임의보행을 사용합니다 즉, 현재 정점의 이웃 중 하나를 균일한 확률로 선택하는 이동하는 과정을 반복합니다</li>
<li>Node2Vec은 2차 치우친 임의보행(Second-order Biased Random Walk)을 사용합니다<ul>
<li>현재 정점(예시에서 𝑣)과 직전에 머물렀던 정점(예시에서 𝑢)을 모두 고려하여 다음 정점을 선택합니다</li>
<li>직전 정점의 거리를 기준으로 경우를 구분하여 차등적인 확률을 부여합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261311-fb0c6400-7842-11eb-9a3b-aa04d9868e65.png" alt="image-20210225112308400"></li>
<li>Node2Vec에서는 부여하는 확률에 따라서 다른 종류의 임베딩을 얻습니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261312-fba4fa80-7842-11eb-8916-38506aa334e0.png" alt="image-20210225112417345"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261315-fba4fa80-7842-11eb-95f3-08bd135ecd2d.png" alt="image-20210225112449054"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261316-fc3d9100-7842-11eb-82d6-e8a065224624.png" alt="image-20210225112506606"><br>-</li>
</ul>
</li>
</ul>
<h2 id="손실-함수-근사"><a href="#손실-함수-근사" class="headerlink" title="손실 함수 근사"></a>손실 함수 근사</h2><ul>
<li>임의보행 기법의 손실함수는 계산에 정점의 수의 제곱에 비례하는 시간이 소요됩니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261318-fc3d9100-7842-11eb-884f-33114e80f3b6.png" alt="image-20210225112816322"></li>
<li>따라서 많은 경우 근사식을 사용합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261320-fcd62780-7842-11eb-8dd7-7bcea7e986d4.png" alt="image-20210225112844742"></li>
<li>연결성에 비례하는 확률로 네거티브 샘플을 뽑으며, 네거티브 샘플이 많을 수록 학습이 더욱 안정적입니다</li>
<li>네거티브 샘플을 많이 뽑을 수록 학습이 안정적임</li>
</ul>
<h1 id="변환식-정점-표현-학습의-한계"><a href="#변환식-정점-표현-학습의-한계" class="headerlink" title="변환식 정점 표현 학습의 한계"></a>변환식 정점 표현 학습의 한계</h1><h2 id="변환식-정점-표현-학습과-귀납식-정점-표현-학습"><a href="#변환식-정점-표현-학습과-귀납식-정점-표현-학습" class="headerlink" title="변환식 정점 표현 학습과 귀납식 정점 표현 학습"></a>변환식 정점 표현 학습과 귀납식 정점 표현 학습</h2><ul>
<li><p>지금까지 소개한 정점 임베딩 방법들을 변환식(Transductive) 방법입니다</p>
</li>
<li><p>변환식(Transdctive) 방법은 학습의 결과로 정점의 임베딩 자체를 얻는다는 특성이 있습니다 정점을 임베딩으로 변화시키는 함수, 즉 인코더를 얻는 귀납식(Inductive) 방법과 대조됩 니다</p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/109261322-fcd62780-7842-11eb-8d2f-599a90078e89.png" alt="image-20210225113320988"></p>
</li>
<li><p>변환식 임베딩 방법은 여러 한계를 갖습니다</p>
<ol>
<li>학습이 진행된 이후에 추가된 정점에 대해서는 임베딩을 얻을 수 없습니다</li>
</ol>
<p>​ 입력그래프에 변화가 있는 경우 임베딩을 다시 수행</p>
<ol>
<li><p>모든 정점에 대한 임베딩을 미리 계산하여 저장해두어야 합니다</p>
</li>
<li><p>정점이 속성(Attribute) 정보를 가진 경우에 이를 활용할 수 없습니다</p>
</li>
</ol>
</li>
<li><p>귀납식 임베딩 방법-&gt; GNN</p>
</li>
</ul>
<h1 id="넷플릭스-챌린지"><a href="#넷플릭스-챌린지" class="headerlink" title="넷플릭스 챌린지"></a>넷플릭스 챌린지</h1><ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261323-fd6ebe00-7842-11eb-854b-5174c3769b79.png" alt="image-20210225170001631"></li>
<li>넷플릭스 챌린지의 목표는 추천시스템의 성능을 10%이상 향상시키는 것이었습니다</li>
<li>평균 제곱근 오차 0.9514을 0.8563까지 낮출 경우 100만불의 상금을 받는 조건이었습니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261326-fe075480-7842-11eb-9fab-50b952254207.png" alt="image-20210225170127758"></li>
</ul>
<h1 id="잠재-인수-모형"><a href="#잠재-인수-모형" class="headerlink" title="잠재 인수 모형"></a>잠재 인수 모형</h1><h2 id="잠재-인수-모형-개요"><a href="#잠재-인수-모형-개요" class="headerlink" title="잠재 인수 모형 개요"></a>잠재 인수 모형 개요</h2><ul>
<li>잠재 인수 모형(Latent Factor Model)의 핵심은 사용자와 상품을 벡터로 표현하는 것입니다<ul>
<li>uv decomposition</li>
<li>SVD</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261328-fe9feb00-7842-11eb-9060-9130a6d9bc22.png" alt="image-20210225170314752"></li>
<li>수치적으로 표현하는 것은 쉬운 일이 아님</li>
<li>잠재 인수 모형에서는 고정된 인수 대신 효과적인 인수를 학습하는 것을 목표로 합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261330-fe9feb00-7842-11eb-8918-0e9ec3b96a45.png" alt="image-20210225170458921"></li>
</ul>
</li>
</ul>
<h2 id="손실-함수"><a href="#손실-함수" class="headerlink" title="손실 함수"></a>손실 함수</h2><ul>
<li>사용자와 상품을 임베딩하는 기준은 무엇인가요?<ul>
<li>사용자와 상품의 임베딩의 내적(Inner Product)이 평점과 최대한 유사하도록 하는 것입니다</li>
<li>사용자 𝑥의 임베딩을 𝑝𝑥, 상품 𝑖의 임베딩을 𝑞𝑖라고 합시다 사용자 𝑥의 상품 𝑖에 대한 평점을 𝑟𝑥𝑖라고 합시다 임베딩의 목표는 𝑝𝑥 ⊺ 𝑞𝑖이 𝑟𝑥𝑖와 유사하도록 하는 것입니다</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261333-ff388180-7842-11eb-879d-44fe5ba83e88.png" alt="image-20210225170833623"></li>
<li>과적합을 방지하기 위하여 정규화 항을 손실 함수에 더해줍니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261336-ff388180-7842-11eb-8623-8dc93925f533.png" alt="image-20210225170850192"></li>
<li>임베딩이 너무 크면 훈련 데이터에 있는 잡음들까지 배울 수 있다</li>
<li>정규화의 세기가 클수록 모형 복잡도에 집중하여 최소화</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261337-ffd11800-7842-11eb-9e6b-f4695b005f09.png" alt="image-20210225171218512"></li>
</ul>
</li>
</ul>
<h2 id="최적화"><a href="#최적화" class="headerlink" title="최적화"></a>최적화</h2><ul>
<li>손실함수를 최소화하는 𝑃와 𝑄를 찾기 위해서는 (확률적) 경사하강법을 사용합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261338-ffd11800-7842-11eb-86ea-07f32a25f700.png" alt="image-20210225171324056"></li>
</ul>
<h1 id="고급-잠재-인수-모형"><a href="#고급-잠재-인수-모형" class="headerlink" title="고급 잠재 인수 모형"></a>고급 잠재 인수 모형</h1><h2 id="사용자와-상품의-편향을-고려한-잠재-인수-모형"><a href="#사용자와-상품의-편향을-고려한-잠재-인수-모형" class="headerlink" title="사용자와 상품의 편향을 고려한 잠재 인수 모형"></a>사용자와 상품의 편향을 고려한 잠재 인수 모형</h2><ul>
<li>각 사용자의 편향은 해당 사용자의 평점 평균과 전체 평점 평균의 차입니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261339-0069ae80-7843-11eb-8b7b-821e813b22b8.png" alt="image-20210225171938430"></li>
</ul>
</li>
<li>각 상품의 편향은 해당 상품에 대한 평점 평균과 전체 평점 평균의 차입니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261342-0069ae80-7843-11eb-969d-2d549be1b0e0.png" alt="image-20210225172005439"></li>
</ul>
</li>
<li><p>개선된 잠재 인수 모형에서는 평점을 전체 평균, 사용자 편향, 상품 편향, 상호작용으로 분리합니다</p>
<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261347-01024500-7843-11eb-974d-c181004112ec.png" alt="image-20210225172108647"></li>
</ul>
</li>
<li><p>개선된 잠재 인수 모형의 손실 함수는 아래와 같습니다</p>
<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261350-019adb80-7843-11eb-8d47-9f52c5c1e149.png" alt="image-20210225172248712"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261351-02337200-7843-11eb-8445-ae6ae5810cc7.png" alt="image-20210225172404000"></li>
</ul>
</li>
</ul>
<h2 id="시간적-편향을-고려한-잠재-인수-모형"><a href="#시간적-편향을-고려한-잠재-인수-모형" class="headerlink" title="시간적 편향을 고려한 잠재 인수 모형"></a>시간적 편향을 고려한 잠재 인수 모형</h2><ul>
<li>넷플릭스 시스템의 변화로 평균 평점이 크게 상승하는 사건이 있었습니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261354-02337200-7843-11eb-99f1-e4a5292feb9c.png" alt="image-20210225172446600"></li>
</ul>
</li>
<li>영화의 평점은 출시일 이후 시간이 지남에 따라 상승하는 경향을 갖습니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261359-02cc0880-7843-11eb-9a58-88d3d146166d.png" alt="image-20210225172529255"></li>
</ul>
</li>
<li>개선된 잠재 인수 모형에서는 이러한 시간적 편향을 고려합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109261363-03649f00-7843-11eb-94db-6e1e5ce0e04c.png" alt="image-20210225172647321"></li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109261366-03649f00-7843-11eb-9edf-0329b91a5e2a.png" alt="image-20210225172711517"></li>
</ul>
<h1 id="넷플릭스-챌린지의-결과"><a href="#넷플릭스-챌린지의-결과" class="headerlink" title="넷플릭스 챌린지의 결과"></a>넷플릭스 챌린지의 결과</h1><h2 id="앙상블-학습"><a href="#앙상블-학습" class="headerlink" title="앙상블 학습"></a>앙상블 학습</h2><ul>
<li>BellKor 팀은 앙상블 학습을 사용하여 처음으로 목표 성능에 도달하였습니다</li>
<li>BellKor 팀의 독주에 위기감을 느낀 다른 팀들은 연합팀 Ensemble을 만들었습니다</li>
<li>넷플릭스 챌린지 종료 시점에 BellKor 팀 Ensemble 팀의 오차는 정확히 동일했습니다 하지만 BellKor 팀의 제출이 20분 빨랐습니다.</li>
</ul>
<p>​</p>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/25/BoostCamp/Day23/"><img class="fill" src="/img/boostcamp.png" alt="Day23"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-25T03:28:58.000Z" title="2021-2-25 12:28:58 ├F10: PM┤">2021-02-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:31:55.399Z" title="2021-3-22 6:31:55 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">21 minutes read (About 3091 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/25/BoostCamp/Day23/">Day23</a></h1><div class="content"><h1 id="군집-구조와-군집-탐색-문제"><a href="#군집-구조와-군집-탐색-문제" class="headerlink" title="군집 구조와 군집 탐색 문제"></a>군집 구조와 군집 탐색 문제</h1><ul>
<li>군집(Community)이란 다음 조건들을 만족하는 정점들의 집합<ol>
<li>집합에 속하는 정점 사이에는 많은 간선이 존재</li>
<li>집합에 속하는 정점과 그렇지 않은 정점 사이에는 적은 수의 간선이 존재</li>
</ol>
</li>
<li>실제 그래프에서의 군집들<ul>
<li>온라인 소셜 네트워크의 군집들은 사회적 무리(Social Circle)을 의미하는 경우가 많다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109098575-f5d8e780-7764-11eb-919a-f5bbfc2e7654.png" alt="image-20210224093907324"></li>
</ul>
</li>
<li>온라인 소셜 네트워크의 군집들이 부정 행위와 관련된 경우도 많다.</li>
<li>조직 내의 분란이 소셜 네트워크 상의 군집으로 표현된 경우도 있다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109098576-f6717e00-7764-11eb-8003-52cbd83c9256.png" alt="image-20210224094033233"></li>
</ul>
</li>
<li>키워드 – 광고주 그래프에서는 동일한 주제의 키워드들이 군집을 형성합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109098580-f70a1480-7764-11eb-8362-5d27c8d8681b.png" alt="image-20210224094118211"></li>
</ul>
</li>
<li>뉴런간 연결 그래프에서는 군집들이 뇌의 기능적 구성 단위를 의미합니다</li>
</ul>
</li>
<li>군집 탐색 문제<ul>
<li>그래프를 여러 군집으로 ‘잘’ 나누는 문제를 군집 탐색(Community Detection) 문제라고 합니다<ul>
<li>보통은 각 정점이 한 개의 군집에 속하도록 군집을 나눕니다</li>
<li>비지도 기계학습 문제인 클러스터링(Clustering)과 상당히 유사합니다<ul>
<li>클러스터링 : 피쳐들의 벡터형태로 표현된 인스턴스들을 그룹으로 묶음</li>
<li>군집탐색문제 : 정점들을 그룹으로 묶음</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="군집-구조의-통계적-유의성과-군집성"><a href="#군집-구조의-통계적-유의성과-군집성" class="headerlink" title="군집 구조의 통계적 유의성과 군집성"></a>군집 구조의 통계적 유의성과 군집성</h1><ul>
<li>비교 대상: 배치 모형<ul>
<li>성공적인 군집탐색은 비교를 통해 정의 , 그 비교의 대상이 되는 것이 배치모형(Configuration Model)이다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109098581-f7a2ab00-7764-11eb-9967-4baa9c8a099d.png" alt="image-20210224094631721"></li>
</ul>
</li>
<li>군집성의 정의<ul>
<li>군집 탐색의 성공 여부를 판단 하기 위해서, 군집성(Modularity)가 사용됩니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109098582-f83b4180-7764-11eb-8f62-d13f07344040.png" alt="image-20210224094817164"></li>
<li>기댓값을 사용하는 이유는 배치모형이 무작위성을 포함하고 있기 때문</li>
<li>차이가 클수록 그래프에서 군집s내부 간선의 수가 많음을 의미-&gt;군집의 성질을 잘 만족함</li>
<li>-1&lt;=군집성&lt;=1</li>
</ul>
</li>
<li>즉, 군집성은 무작위로 연결된 배치 모형과의 비교를 통해 통계적 유의성을 판단합니다</li>
<li>군집성은 항상 –1과 +1 사이의 값을 갖습니다</li>
<li>보통 군집성이 0.3 ~ 0.7 정도의 값을 가질 때, 그래프에 존재하는 통계적으로 유의미한 군집들을 찾아냈다고 할 수 있습니다</li>
</ul>
<h1 id="군집-탐색-알고리즘"><a href="#군집-탐색-알고리즘" class="headerlink" title="군집 탐색 알고리즘"></a>군집 탐색 알고리즘</h1><ul>
<li><p>Girvan-Newman 알고리즘</p>
<ul>
<li><p>하향식(Top-Down) 군집 탐색 알고리즘입니다</p>
</li>
<li><p>전체 그래프에서 탐색을 시작합니다 군집들이 서로 분리되록, 간선을 순차적으로 제거합니다</p>
</li>
<li><p>어떤 간선을 제거해야 군집들이 분리될까요?</p>
<ul>
<li>바로 서로 다른 군집을 연결하는 다리(Bridge) 역할의 간선입니다</li>
</ul>
</li>
<li><p>서로 다른 군집을 연결하는 다리 역할의 간선을 어떻게 찾아낼 수 있을까요?</p>
<ul>
<li>간선의 매개 중심성(Betweenness Centrality)을 사용합니다 이는 해당 간선이 정점 간의 최단 경로에 놓이는 횟수를 의미합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109098585-f83b4180-7764-11eb-9318-1b8f60869b8a.png" alt="image-20210224095424640"></li>
<li>매개 중심성을 통해 서로 다른 군집을 연결하는 다리 역할의 간선을 찾아낼 수 있습니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109098587-f8d3d800-7764-11eb-9d4b-68fe22374e88.png" alt="image-20210224095455618"></li>
</ul>
</li>
<li><p>Girvan-Newman 알고리즘은 매개 중심성이 높은 간선을 순차적으로 제거합니다</p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/109098590-f8d3d800-7764-11eb-8f49-17dd49321729.png" alt="image-20210224095609411"></p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/109098592-f96c6e80-7764-11eb-98c3-d5cb18346c4a.png" alt="image-20210224095623587"></p>
</li>
<li><p>간선이 모두 제거될 때까지 반복합니다</p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/109098594-fa050500-7764-11eb-9eb7-bb62c8cf9fdd.png" alt="image-20210224095709009"></p>
</li>
<li><p>간선을 어느 정도 제거하는 것이 가장 적합할까요?</p>
<ul>
<li>앞서 정의한 군집성을 그 기준으로 삼습니다 즉, 군집성이 최대가 되는 지점까지 간선을 제거합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109098596-fa050500-7764-11eb-9820-6766f6e3b60c.png" alt="image-20210224095854257"></li>
</ul>
</li>
<li><p>정리</p>
<ol>
<li>전체 그래프에서 시작합니다</li>
<li>매개 중심성이 높은 순서로 간선을 제거하면서, 군집성을 변화를 기록합니다</li>
<li>군집성이 가장 커지는 상황을 복원합니다</li>
<li>이 때, 서로 연결된 정점들, 즉 연결 요소를 하나의 군집으로 간주합니다</li>
</ol>
<p>즉, 전체 그래프에서 시작해서 점점 작은 단위를 검색하는 하향식(Top-Down) 방법입니다</p>
</li>
</ul>
</li>
<li><p>Louvain 알고리즘</p>
<ul>
<li>상향식(Bottom-Up) 군집 탐색 알고리즘입니다</li>
<li>각 정점이 하나의 군집을 형성한다고 가정한 상태에서 시작</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109098598-fa9d9b80-7764-11eb-9bb3-341486cef08d.png" alt="image-20210224100142281"></li>
<li>그러면 어떤 기준으로 군집을 합쳐야 할까요?<ul>
<li>군집성</li>
</ul>
</li>
<li>과정<ol>
<li>Louvain 알고리즘은 개별 정점으로 구성된 크기 1의 군집들로부터 시작합니다</li>
<li>각 정점 𝑢를 기존 혹은 새로운 군집으로 이동합니다 이 때, 군집성이 최대화되도록 군집을 결정합니다</li>
<li>더 이상 군집성이 증가하지 않을 때까지 2)를 반복합니다</li>
<li>각 군집을 하나의 정점으로하는 군집 레벨의 그래프를 얻은 뒤 3)을 수행합니다</li>
<li>한 개의 정점이 남을 때까지 4)를 반복합니다</li>
</ol>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109098601-fb363200-7764-11eb-9469-361dbb6c0fa9.png" alt="image-20210224100401905"></li>
</ul>
</li>
</ul>
<h1 id="중첩이-있는-군집-탐색"><a href="#중첩이-있는-군집-탐색" class="headerlink" title="중첩이 있는 군집 탐색"></a>중첩이 있는 군집 탐색</h1><ul>
<li>중첩이 있는 군집 구조<ul>
<li>실제 그래프의 군집들을 중첩되어 있는 경우가 많습니다</li>
<li>예를 들어 소셜 네트워크에서의 개인은 여러 사회적 역할을 수행합니다 그 결과 여러 군집에 속하게 됩니다</li>
<li>앞서 배운 Girvan-Newman 알고리즘, Louvain 알고리즘은 군집 간의 중첩이 없다고 가정합니다 그러면 중첩이 있는 군집은 어떻게 찾아낼 수 있을까요?<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109098602-fb363200-7764-11eb-9e2a-6b6addaf5251.png" alt="image-20210224100542795"></li>
</ul>
</li>
<li>이를 위해 아래와 같은 중첩 군집 모형을 가정합니다<ol>
<li>각 정점은 여러 개의 군집에 속할 수 있습니다</li>
<li>각 군집 𝐴에 대하여, 같은 군집에 속하는 두 정점은 𝑃𝐴 확률로 간선으로 직접 연결됩니다</li>
<li>두 정점이 여러 군집에 동시에 속할 경우 간선 연결 확률은 독립적입니다 예를 들어, 두 정점이 군집 𝐴와 𝐵에 동시에 속할 경우 두 정점이 간선으로 직접 연결될 확률은 1 − (1 − 𝑃𝐴)(1 − 𝑃𝐵)입니다</li>
<li>어느 군집에도 함께 속하지 않는 두 정점은 낮은 확률 𝜖으로 직접 연결됩니다</li>
</ol>
</li>
<li>중첩 군집 모형이 주어지면, 주어진 그래프의 확률을 계산할 수 있습니다</li>
<li>그래프의 확률은 다음 확률들의 곱입니다<ul>
<li>그래프의 각 간선의 두 정점이 (모형에 의해) 직접 연결될 확률</li>
<li>그래프에서 직접 연결되지 않은 각 정점 쌍이 (모형에 의해) 직접 연결되지 않을 확률</li>
</ul>
</li>
<li>현실의 많은 경우 그래프는 주어져 있지만 중첩군집모형은 주어지지 않는 경우가 많음</li>
<li>따라서 중첩 군집 탐색은 주어진 그래프의 확률을 최대화하는 중첩 군집 모형을 찾는 과정입니다 -&gt;최대우도추정치<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109098605-fbcec880-7764-11eb-89f7-ecb5e4e0346a.png" alt="image-20210224101151987"></li>
</ul>
</li>
<li>중첩 군집 탐색을 용이하게 하기 위하여 완화된 중첩 군집 모형을 사용합니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109098606-fc675f00-7764-11eb-9715-903f3f4b8dc7.png" alt="image-20210224101212737"></li>
<li>완화된 중첩 군집 모형에서는 각 정점이 각 군집에 속해 있는 정도를 실숫값으로 표현합니다</li>
<li>즉, 기존 모형에서는 각 정점이 각 군집에 속하거나 속하지 않거나 둘 중 하나였는데, 중간 상태를 표현할 수 있게 된 것입니다</li>
<li>최적화 관점에서는, 모형의 매개변수들이 실수 값을 가지기 때문에 익숙한 최적화 도구 (경사하강법 등)을 사용하여 모형을 탐색할 수 있다는 장점이 있습니다</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="우리-주변의-추천-시스템"><a href="#우리-주변의-추천-시스템" class="headerlink" title="우리 주변의 추천 시스템"></a>우리 주변의 추천 시스템</h1><ul>
<li>추천 시스템과 그래프<ul>
<li>사용자 각각이 구매할 만한 혹은 선호할 만한 상품을 추천합니다</li>
<li>구매 기록이라는 암시적(Implicit)인 선호만 있는 경우도 있고, 평점이라는 명시적(Explicit)인 선호가 있는 경우도 있습니다</li>
<li>그래프 관점에서 추천 시스템은 “<code>미래의 간선을 예측하는 문제</code>” 혹은 “<code>누락된 간선의 가중치를 추정하는 문제</code>”로 해석할 수 있습니다</li>
</ul>
</li>
</ul>
<h1 id="내용-기반-추천시스템"><a href="#내용-기반-추천시스템" class="headerlink" title="내용 기반 추천시스템"></a>내용 기반 추천시스템</h1><ul>
<li><p>내용 기반 추천시스템의 원리</p>
<ul>
<li>내용 기반(Content-based) 추천은 각 사용자가 구매/만족했던 상품(부가정보)과 유사한 것을 추천하는 방법입니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109098609-fcfff580-7764-11eb-9bba-78b2f2406d22.png" alt="image-20210224105759072"><ol>
<li><img src="https://user-images.githubusercontent.com/46857207/109098610-fcfff580-7764-11eb-852c-ef0d8cb72984.png" alt="image-20210224105841531"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109098614-fd988c00-7764-11eb-91d8-203969bb5806.png" alt="image-20210224105904795"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109098615-fe312280-7764-11eb-8cd5-49e8ef7550e1.png" alt="image-20210224110310572"></li>
<li>마지막 단계는 사용자에게 상품을 추천하는 단계입니다 코사인 유사도가 높은 상품들을 추천합니다</li>
</ol>
</li>
<li>내용 기반 추천시스템은 다음 장점을 갖습니다<ul>
<li>다른 사용자의 구매 기록이 필요하지 않습니다-&gt; 본인의 기록만</li>
<li>독특한 취향의 사용자에게도 추천이 가능합니다</li>
<li>새 상품에 대해서도 추천이 가능합니다-&gt;상품 프로필</li>
<li>추천의 이유를 제공할 수 있습니다</li>
</ul>
</li>
<li>내용 기반 추천시스템은 다음 단점을 갖습니다<ul>
<li>상품에 대한 부가 정보가 없는 경우에는 사용할 수 없습니다</li>
<li>구매 기록이 없는 사용자에게는 사용할 수 없습니다-&gt;사용자 프로필x</li>
<li>과적합(Overfitting)으로 지나치게 협소한 추천을 할 위험이 있습니다</li>
</ul>
</li>
</ul>
<h1 id="협업-필터링-추천시스템"><a href="#협업-필터링-추천시스템" class="headerlink" title="협업 필터링 추천시스템"></a>협업 필터링 추천시스템</h1><p>​</p>
</li>
<li><p>​ 협업 필터링의 원리</p>
<ul>
<li>사용자-사용자 협업 필터링은 다음 세 단계로 이루어집니다<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109098616-fe312280-7764-11eb-9e1d-7b62419521fd.png" alt="image-20210224110937832"></li>
</ul>
</li>
<li>사용자-사용자 협업 필터링의 핵심은 유사한 취향의 사용자를 찾는 것입니다 그런데 취향의 유사도는 어떻게 계산할까요?<ul>
<li>취향의 유사성은 상관 계수(Correlation Coefficient)를 통해 측정합니다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/109098618-fec9b900-7764-11eb-89db-32df27a69a47.png" alt="image-20210224111923584"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109098620-fec9b900-7764-11eb-9208-2102bf0add60.png" alt="image-20210224112801261"></li>
<li>마지막 단계는 추정한 평점이 가장 높은 상품을 추천하는 단계입니다</li>
<li>추천의 대상 사용자를 𝑥라고 합시다 앞서 설명한 방법을 통해, 𝑥가 아직 구매하지 않은 상품 각각에 대해 평점을 추정합니다 추정한 평점이 가장 높은 상품들을 𝑥에게 추천합니다</li>
<li>협업 필터링은 다음 장점과 단점 갖습니다<ul>
<li>(+) 상품에 대한 부가 정보가 없는 경우에도 사용할 수 있습니다</li>
<li>(−) 충분한 수의 평점 데이터가 누적되어야 효과적입니다</li>
<li>(−) 새 상품, 새로운 사용자에 대한 추천이 불가능합니다</li>
<li>(−) 독특한 취향의 사용자에게 추천이 어렵습니다</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="추천-시스템의-평가"><a href="#추천-시스템의-평가" class="headerlink" title="추천 시스템의 평가"></a>추천 시스템의 평가</h1><ul>
<li>데이터 분리<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/109098621-ff624f80-7764-11eb-9c29-bd7d7b76bdcf.png" alt="image-20210224113213272"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/109098622-fffae600-7764-11eb-86c8-c8d88394fcb4.png" alt="image-20210224113230529"></li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2021/02/24/BoostCamp/Day22/"><img class="fill" src="/img/boostcamp.png" alt="Day22"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-24T05:58:22.000Z" title="2021-2-24 2:58:22 ├F10: PM┤">2021-02-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-22T09:31:43.487Z" title="2021-3-22 6:31:43 ├F10: PM┤">2021-03-22</time></span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/BoostCamp/">BoostCamp</a></span><span class="level-item">14 minutes read (About 2054 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/24/BoostCamp/Day22/">Day22</a></h1><div class="content"><ul>
<li>웹과 그래프<ul>
<li>웹은 웹페이지와 하이퍼링크로 구성된 거대한 방향성 있는 그래프</li>
<li>정점: 웹페이지, 간선: 하이퍼링크</li>
</ul>
</li>
<li>검색 엔진<ul>
<li>웹을 거대한 디렉토리로 정리 -&gt; 카테고리의 수와 깊이도 무한정 커지는 문제</li>
</ul>
</li>
<li>키워드에 의존한 검색 엔진<ul>
<li>악의적인 웹페이지에 취약</li>
</ul>
</li>
<li>Q 사용자 키워드와 관련성이 높고 신뢰할 수 있는 웹페이지를 어떻게 찾을 수 있을까?</li>
<li>A. 페이지랭크</li>
</ul>
<h2 id="페이지랭크"><a href="#페이지랭크" class="headerlink" title="페이지랭크"></a>페이지랭크</h2><ul>
<li><p>페이지랭크의 핵심 아이디어는 투표(하이퍼링크)</p>
</li>
<li><p>들어노는 간선이 많을 수록 신뢰할 수 있다는 뜻</p>
</li>
<li><p>들어오는 간선의 수를 세는 것만으로 충분할까?</p>
<ul>
<li>악용될 소지가 있다. 웹페이지를 여러 개 만들어서 간선의 수를 부풀릴 수 있다</li>
<li>돈을 주고 트위터의 팔로어를 늘리는 것</li>
<li>이런 악용에 의한 효과를 줄이기 위해 가중 투표를한다. 관련성이 높고 신뢰할 수 있는 웹사이트의 투표를 더 중요하게 간주한다.</li>
<li>관련성과 신뢰성을 출력과 입력으로 사용한다-&gt; 재귀,연립방정식을 통해 가능</li>
</ul>
</li>
<li><p>페이지랭크 점수 <strong>_자신의 페이지랭크 점수/나가는 이웃의 수_</strong> 만큼의 가중치로 투표한다.</p>
</li>
<li><p>각 웹페이지의 페이지랭크 점수는 받은 투표의 가중치 합으로 정의</p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/108954757-a5a04d80-76b0-11eb-998b-0dab48cf192a.png" alt="image-20210223095716783"></p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/108954762-a6d17a80-76b0-11eb-8889-a3497c4ec1d4.png" alt="image-20210223095736643"></p>
</li>
<li><p>투표의 관점이 아닌 임의 보행 관점</p>
<ul>
<li>웹퍼서는 하이퍼링크 중 하나를 균일한 확률로 클릭</li>
<li>웹서퍼가 t번째 방문한 웹페이지가 웹페이지 i일 확률을 $p_i(t)$</li>
<li>$p(t)$는 길이가 웹페이지 수와 같은 확률분포 벡터<ul>
<li>모든 페이지에서 웹페이지 <em>i</em>를 클릭할 확률 $p_i(t)$를 모두 모아놓은 벡터이다. 당연히 길이가 웹페이지 수와 같아진다.</li>
</ul>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954765-a6d17a80-76b0-11eb-8237-dc3921394071.png" alt="image-20210223100240027"></li>
<li>웹서퍼가 이 과정을 무한히 반복하고 나면, 즉 t가 무한히 커지먼 확률본포 p(t)는 수렴</li>
<li>p(t)=p(t+1)=p</li>
<li>수렴한 확률분포 p는 정상분포라고 부른다</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954767-a76a1100-76b0-11eb-82cb-7f7e13475aa1.png" alt="image-20210223100523413"></li>
<li>투표 관점에서 정의한 페이지랭크점수와 동일하다</li>
</ul>
</li>
<li><p>페이지랭크의 계산</p>
<ul>
<li><p>반복곱(power iteration)</p>
<ul>
<li><ol>
<li>각 웹페이지의 i의 페이지랭크 점수$r_i^{(0)}$를 <strong>_1/웹페이지의 수_</strong>로 초기화</li>
</ol>
</li>
<li><ol>
<li>페이지랭크 점수를 갱신, 각 정점이 받은 투표의 가중치 합산<img src="https://user-images.githubusercontent.com/46857207/108954768-a76a1100-76b0-11eb-9d28-0de413e583e5.png" alt="image-20210223101026085"></li>
<li>페이지랭크 점수가 수렴하였으면 종료, 아닌 경우 2로</li>
</ol>
</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954770-a802a780-76b0-11eb-9a3f-bd92ee8a1ab9.png" alt="image-20210223101441439"></li>
</ul>
</li>
<li><p>Q1. 반복곱이 한상 수렴하는 것을 보장할 수 있나?</p>
<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108954775-a89b3e00-76b0-11eb-8f7e-efcc8d017b85.png" alt="image-20210223101724884"></li>
</ul>
</li>
<li><p>Q2. 반복곱이 합리적인 점수로 수렴하는 것을 보장할 수 있나?</p>
<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108954776-a933d480-76b0-11eb-8752-7a36ee4ab336.png" alt="image-20210223101811983"></li>
</ul>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/108954779-a933d480-76b0-11eb-9657-31b514835e42.png" alt="image-20210223101851709"></p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/108954782-a9cc6b00-76b0-11eb-8ad9-32345025c06d.png" alt="image-20210223102032533"></p>
</li>
<li><p><img src="https://user-images.githubusercontent.com/46857207/108954783-a9cc6b00-76b0-11eb-922b-340fab7f62cd.png" alt="image-20210223102140989"></p>
<ul>
<li>B가 점수가 높은 이유는 많은 정점으로부터 투표를 받고 있기 때문</li>
<li>투표를 받지 않아도 순간이동으로 페이지랭크 점수가 0이 아니다</li>
<li>c의 점수가 높은 이유는 b로부터 들어오기 때문 (소중한 한표)</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="그래프를-바이럴-마케팅에-어떻게-활용할까"><a href="#그래프를-바이럴-마케팅에-어떻게-활용할까" class="headerlink" title="그래프를 바이럴 마케팅에 어떻게 활용할까?"></a>그래프를 바이럴 마케팅에 어떻게 활용할까?</h2><ul>
<li>그래프를 통한 전파의 예시, 정보 행동 고장 질병<ul>
<li>SNS을 통해 정보 전파</li>
<li>아이스버킷 챌린지, 펭권문제등의 행동 전파</li>
<li>컴퓨터 네트워크에서 일부장비의 고장이 다른 장비의 과부하로 이어져 전체 네트워크를 마비시킬 수 있다</li>
<li>코로나 메르스등의 질병 전파</li>
</ul>
</li>
<li>전파과정을 치계적으로 이해하고 대처하기 위해서는 수학적 모형화가 필요</li>
<li>의사결정 기반의 전파 모형</li>
<li>언제 사용하는가<ul>
<li>주변 사람의 의사결정이 본인의 의사결정에 영향을 미친다. 주변사람들의 의사결정을 고려하여 각자 의사결정을 내리는 경우 <strong><code>의사결정 기반의 전파 모형</code></strong>을 사용한다.</li>
</ul>
</li>
<li><ul>
<li>카카오 vs 라인</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954785-aa650180-76b0-11eb-8169-92e13639eb70.png" alt="image-20210223103904118"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954788-aafd9800-76b0-11eb-97b0-82f811f17880.png" alt="image-20210223103948116"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954790-aafd9800-76b0-11eb-85d4-fc1ecd0a4de2.png" alt="image-20210223104018597"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954791-ab962e80-76b0-11eb-8bd7-bfd52b9d7960.png" alt="image-20210223104111058"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954792-ab962e80-76b0-11eb-9ac1-4d09d3bf946d.png" alt="image-20210223104253539"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954793-ac2ec500-76b0-11eb-8f10-7aa077745ab9.png" alt="image-20210223104329710"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954794-ac2ec500-76b0-11eb-935d-f5deb8e2792f.png" alt="image-20210223104435407"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954795-acc75b80-76b0-11eb-8186-0d76710ed31c.png" alt="image-20210223104501214"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954797-acc75b80-76b0-11eb-95c7-0bc604306a4e.png" alt="image-20210223104635824"></li>
</ul>
</li>
<li>확률적 전파 모형(독립적 전파 모형)<ul>
<li>의사결정 기반의 전파 모형은 전파 과정을 간단하게 표현할 수 있지만, ‘의지’나 ‘결정’이 들어가지 않은 전파에 대해서는 적합하지 않다.</li>
<li>코로나의 전파 과정은 확률적 과정이기 떄문에 확률적 전파 모형을 고려해야 한다.</li>
<li>가장 간단한 형태의 확률적 전파 모형인 독립 전파 모형</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954799-ad5ff200-76b0-11eb-8168-557b36d93478.png" alt="image-20210223104912798"></li>
<li>서로 다른 이웃이 전염되는 확률은 독립적이므로, 최초 감염자들로부터 전파가 늘어남에 따라 전파확률이 기하급수적으로 늘어나게 된다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954800-ad5ff200-76b0-11eb-928b-6b7747a8be0c.png" alt="image-20210223105036897"></li>
<li>한번 감염자는 계속 감염자</li>
<li>회복을 가정하는 SIS, SIR등의 다른 전파 모형도 있다.</li>
</ul>
</li>
<li>전파 최대화 문제<ul>
<li>바이럴 마케팅이란<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108954803-adf88880-76b0-11eb-8b02-91c6cefb6087.png" alt="image-20210223105222893"></li>
</ul>
</li>
<li>시드 집합의 중요성<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108954808-ae911f00-76b0-11eb-8a8e-7adbaaae265a.png" alt="image-20210223105316358"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954813-af29b580-76b0-11eb-9e14-3dde9f68ec91.png" alt="image-20210223105439115"></li>
</ul>
</li>
<li>전파 최대화 문제<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108954815-af29b580-76b0-11eb-815d-7222f00703f0.png" alt="image-20210223105734089"></li>
<li>대신에, 최고의 시드 집합에 근사하는 <strong><code>휴리스틱(heuristics)</code></strong>을 사용해 볼 수 있다.</li>
<li>휴리스틱이란 실험적으로 잘 동작하지만 이론적으로는 보장할 수 없는 알고리즘<ul>
<li><img src="https://user-images.githubusercontent.com/46857207/108964909-72b18600-76bf-11eb-9a66-2c5210b174fa.png" alt="image-20210223105936790"></li>
<li>연결 중심성 : 연결성이 높은 정점들이 높은 중심성을 갖는다</li>
<li>근접 중심성 : 다른 정점들과의 평균 거리를 측정한 뒤 평균 거리가 낮은 정점들이 높은 근접 중심성을 갖는다</li>
<li>매개 중심성 : 정점 간 최단 경로를 고려하여 최단 경로에 많이 놓인 정점일수록 매개 중심성이 높다</li>
</ul>
</li>
<li>탐욕 알고리즘<ul>
<li>탐욕 알고리즘 역시 많이 사용된다. 시드 집합의 원소, 즉 최초 전파자를 한번에 한명씩 선택하며, 매 순간 시뮬레이션 하여 더 많은 전파를 일으킬 수 있는 시드를 찾아 다음 타겟으로 지목한다.</li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954819-afc24c00-76b0-11eb-9b3c-5e994d244a46.png" alt="image-20210223110327774"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954820-b05ae280-76b0-11eb-848f-adfc9a9c48ae.png" alt="image-20210223110546908"></li>
<li><img src="https://user-images.githubusercontent.com/46857207/108954821-b05ae280-76b0-11eb-98f6-9b2a66fc1588.png" alt="image-20210223110633961"></li>
<li>탐욕 알고리즘으로 찾은 시드 집합에 의한 평균 전파 크기가, 최고(이상적) 시드집합에 의한 평균 전파크기의 최소 0.632배 이상은 된다는 것이 증명되어있다. 즉, <strong>최저성능이 보장</strong>되어있다.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/">Previous</a></div><div class="pagination-next"><a href="/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link is-current" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li><li><a class="pagination-link" href="/page/5/">5</a></li></ul></nav></div><div class="column column-left is-3-tablet is-3-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/./img/avatar.jpg" alt="Keonwoo Choi"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Keonwoo Choi</p><p class="is-size-6 is-block">blog</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Korea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">42</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/KeonwooChoi" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/KeonwooChoi"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">42</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI/BoostCamp/"><span class="level-start"><span class="level-item">BoostCamp</span></span><span class="level-end"><span class="level-item tag">41</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI/BoostCamp/Project-Stage/"><span class="level-start"><span class="level-item">Project Stage</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/AI/Pytorch/"><span class="level-start"><span class="level-item">Pytorch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-01T15:10:20.000Z">2021-04-02</time></p><p class="title"><a href="/2021/04/02/BoostCamp/Project%20Stage/Day44/">Day44</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a> / <a href="/categories/AI/BoostCamp/Project-Stage/">Project Stage</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-01T15:10:08.000Z">2021-04-02</time></p><p class="title"><a href="/2021/04/02/BoostCamp/Project%20Stage/Day43/">Day43</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a> / <a href="/categories/AI/BoostCamp/Project-Stage/">Project Stage</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-30T16:32:26.000Z">2021-03-31</time></p><p class="title"><a href="/2021/03/31/BoostCamp/Project%20Stage/Day42/">Day42-Augmentation</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a> / <a href="/categories/AI/BoostCamp/Project-Stage/">Project Stage</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-29T16:00:24.000Z">2021-03-30</time></p><p class="title"><a href="/2021/03/30/BoostCamp/Project%20Stage/Day41/">Day41-EDA</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a> / <a href="/categories/AI/BoostCamp/Project-Stage/">Project Stage</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-22T06:59:30.000Z">2021-03-22</time></p><p class="title"><a href="/2021/03/22/BoostCamp/Day40/">Day40</a></p><p class="categories"><a href="/categories/AI/">AI</a> / <a href="/categories/AI/BoostCamp/">BoostCamp</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">April 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/03/"><span class="level-start"><span class="level-item">March 2021</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/02/"><span class="level-start"><span class="level-item">February 2021</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">January 2021</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></div></div></div><!--!--></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">blog</a><p class="is-size-7"><span>&copy; 2021 Keonwoo Choi</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>