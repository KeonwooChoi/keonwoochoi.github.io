{"pages":[{"title":"about","text":"","link":"/about/index.html"}],"posts":[{"title":"BoostCamp Day1","text":"File System &amp; Terminal BasicOS 프로그램은 OS에 의존적 파일시스템 트리구조 저장 파일 VS 디렉토리 경로: 트리구조상 노드의 연결 절대 경로- 루트 디렉토리부터 상대 경로- 현재 디렉토리부터 터미널 Console = Terminal = CMD Command Line Interface (cmder for window) shell cd mkdir dir (ls) copy (cp) del (rm) 파이썬[참고] 컴파일러 VS 인터프리터 컴파일러: 소스코드를 기계어로 먼저 번역 인터프리터: 소스코드를 실행시점에 번역 객체 지향 동적 타이핑 언어 객체 지향: 실행 순서가 아닌 단위 모듈 중심으로 프로그램 작성 (하나의 객체는 method 와 attribute로 구성) 동적 타이핑: 실행 시점에 데이터의 타입 결정 Jupyter Interactive Shell IPython 커널 기반 단축키 툴팁: Shift + Tab 들여쓰기: ctrl + ] or ctrl + [ 아래셀이랑합치기: shift + M 셀지우기: d, d Markdown 변환: m,m Code로변환: y, y Colab 구글 드라이브 저장 피어 세션그라운드룰 오늘 공부한 내용 중 따로 공부하면 좋은 자료나 팁이 있으면 공유하기. 궁금했던 부분 서로 물어보는 시간 가지기 모르는 질문을 부끄러워하지말고 물어보기. 지각 하지 않기(2시 5분까지는 인정?) 코드 과제리뷰시 칭찬 곁들이기 피어세션외 개인시간 존중하기 과제를 다 마치지 못한 사람들을 위해 적절한 힌트로 도와주기 피어세션 동안엔 피어세션에만 집중하고, 다 함께정한 약속들은 최선을 다해 지키기 캠프 진행하면서 플랜 추가/ 수정하기 피어세션 플랜 강의, 과제 중 막힌거 Q&amp;A 공부한 자료 공유 코드 리뷰 모더레이터 내 차례는 4주!","link":"/2021/01/18/BoostCamp/BoostCamp-Day1/"},{"title":"BoostCamp Day3","text":"Python data structurestack LIFO 입력을 Push, 출력을 Pop 리스트를 사용하여, push를 append(), pop을 pop() queue FIFO put를 append(), get을 pop(0)를 사용 deque-&gt;popleft() tuple 값의 변경이 불가능한 리스트 선언 시 “[ ]” 가 아닌 “( )”를 사용 왜 쓸까? 프로그램을 작동하는 동안 변경되지 않은 데이터의 저장 함수의 반환 값등 사용자의 실수에 의한 에러를 사전에 방지 >&gt;&gt; t = (1) # 일반정수로 인식 >&gt;&gt; t = (1, ) # 값이 하나인 Tuple은 반드시 “,” 를 붙여야 함 set 값을 순서없이 저장, 중복 불허 하는 자료형 add, remove, update, discard, clear remove VS discard remove :해당 값이 없으면 에러 discard: 해당 값이 없어도 에러X 집합 연산 합집합: union, | 교집합: intersection, &amp; 차집합: difference, - dictionary Key 값을 활용하여, 데이터 값(Value)를 관리함 items() # Dict 데이터 출력 -&gt;tuple형태로 출력 -&gt; 언패킹 keys() # Dict 키 값만 출력 values() # Dict Value만 출력 Collectionsdeque Stack과 Queue 를 지원하는 모듈 List에 비해 효율적인=빠른 자료 저장 방식을 지원함 rotate, reverse등 Linked List의 특성을 지원함 OrderedDict dict도 python 3.6 부터 입력한 순서를 보장하여 출력함 defaultdict d = defaultdict(lambda: 0) # Default 값을 0으로 설정함 Counter Sequence type의 data element들의 갯수를 dict 형태로 반환 namedtuple Tuple 형태로 Data 구조체를 저장하는 방법 Pythonic codesplit &amp; joinlist comprehension 일반적으로 for + append 보다 속도가 빠름 result = [i for i in range(10)] result = [i+j for i in word_1 for j in word_2] Nested For loop ,이중 for문이 된다. [i+j for i in case_1 for j in case_2 if not(i==j)] [i+j if not(i==j) else i for i in case_1 for j in case_2] [ [i+j for i in case_1] for j in case_2] j가 먼저 도는 loop enumerate index, value zip 두 개 이상의 list의 값을 병렬적으로 추출함 enumerate &amp; zip lambda lambda problmes 테스트의 어려움 문서화 docstring 지원 미비 코드 해석의 어려움 map 두 개 이상의 list에도 적용 가능함, if filter도 사용가능 python3 는 iteration을 생성  list을 붙여줘야 list 사용가능 실행시점의 값을 생성, 메모리 효율적 reduce Legacy library나 다양한 머신러닝 코드에서 여전히 사용중-&gt; 대용량 데이터 그러나 코드의 직관성이 떨어져서 lambda나 reduce는 python3에서 사용을 권장하지 않음 iterable object 내부적 구현으로 iter 와 next 가 사용됨 generator iterable object를 특수한 형태로 사용해주는 함수 element가 사용되는 시점에 값을 메모리에 반환 1234def geneartor_list(value): result = [] for i in range(value): yield i yield를 사용해 한번에 하나의 element만 반환함 메모리 절약 generator comprehension list comprehension과 유사한 형태로 generator형태의 list 생성 [ ] 대신 ( ) 를 사용하여 표현 gen_ex = (n*n for n in range(500)) When generator list 타입의 데이터를 반환해주는 함수는 generator로 만들어라! 큰 데이터를 처리할 때는 generator expression을 고려하라 파일 데이터를 처리할 때도 generator를 쓰자 function passing arguments Keyword arguments 함수에 입력되는 parameter의 변수명을 사용, arguments를 넘김 12345def print_somthing(my_name, your_name): print(&quot;Hello {0}, My name is {1}&quot;.format(your_name, my_name))print_somthing(&quot;Sungchul&quot;, &quot;TEAMLAB&quot;)print_somthing(your_name=&quot;TEAMLAB&quot;, my_name=&quot;Sungchul&quot;) Default arguments parameter의 기본 값을 사용, 입력하지 않을 경우 기본값 출력 12345def print_somthing_2(my_name, your_name=&quot;TEAMLAB&quot;): print(&quot;Hello {0}, My name is {1}&quot;.format(your_name, my_name))print_somthing_2(&quot;Sungchul&quot;, &quot;TEAMLAB&quot;)print_somthing_2(&quot;Sungchul&quot;) variable-length-asterisk variable-length Asterisk(*) 기호를 사용하여 함수의 parameter를 표시함 개수가 정해지지 않은 변수를 함수의 parameter로 사용하는 법 입력된 값은 tuple type으로 사용할 수 있음 1234def asterisk_test(a, b,*args): return a+b+sum(args)print(asterisk_test(1, 2, 3, 4, 5)) args에는 (3,4,5)가 tuple타입으로 들어감 Keyword variable-length Parameter 이름을 따로 지정하지 않고 입력하는 방법 asterisk(*) 두개를 사용하여 함수의 parameter를 표시함 입력된 값은 dict type으로 사용할 수 있음 가변인자는 오직 한 개만 기존 가변인자 다음에 사용 12345678def kwargs_test_1(**kwargs): print(kwargs)def kwargs_test_2(**kwargs): print(kwargs) print(&quot;First value is {first}&quot;.format(**kwargs)) print(&quot;Second value is {second}&quot;.format(**kwargs)) print(&quot;Third value is {third}&quot;.format(**kwargs)) 123456789def kwargs_test_3(one,two=3,*args,**kwargs): print(one+two+sum(args)) print(kwargs)kwargs_test_3(3,4,5,6,7,8,9, first=3, second=4, third=5)kwargs_test_3(one=3,two=4,5,6,7,8,9, first=3, second=4, third=5) #에러kwargs_test_3(one=3,two=4,first=3, second=4, third=5) #에러 안남 (args=())kwargs_test_3(3,4,first=3, second=4, third=5) #에러 안남#키워드 형태로 다 쓰던지 뒤에만 쓰던지 하자 asterisk 단순 곱셈, 제곱연산, 가변 인자 활용 등 다양하게 사용됨 unpacking a container tuple, dict 등 자료형에 들어가 있는 값을 unpacking 함수의 입력값, zip 등에 유용하게 사용가능 12345def asterisk_test(a, *args): #여기 *와 unpacking *는 의미가 다름 print(a, args) print(type(args))asterisk_test(1, *(2,3,4,5,6)) #unpacking 12345def asterisk_test(a, b, c, d,): print(a, b, c, d)data = {&quot;b&quot;:1 , &quot;c&quot;:2, &quot;d&quot;:3}asterisk_test(10, **data) ##keyword unpacking -&gt; b=1,c=2,d=3 12for data in zip(*([1, 2], [3, 4], [5, 6])): # unpacking [1,2],[3,4],[5,6] print(data) 피어세션 파이토치 관련 스터디를 진행하기로 함 PyTorchZeroToAll (in English) 월 &amp; 수 14:00 → 파이토치 화 &amp; 목 17:30 → 과제 코드 리뷰","link":"/2021/01/20/BoostCamp/BoostCamp-Day3/"},{"title":"BoosCamp Day4","text":"Python Object-Oriented ProgrammingOOP Python naming rule CamelCase: 띄워쓰기 부분에 대문자 낙타의 등 모양, 파이썬 Class명에 사용 snakecase : 띄워쓰기 부분에 “” 를 추가 뱀 처럼 늘여쓰기, 파이썬 함수/변수명에 사용 Attribute 추가하기 Attribute 추가는 __init___ , self와 함께! __init__은 객체 초기화 예약 함수 (namedtuple과 비슷) 파이썬에서 __ 의미 - __는 특수한 예약 함수나 변수 그리고 함수명 변경(맨글링)으로 사용 1234567class SoccerPlayer(object): def __str__(self): return &quot;Hello, My name is %s. I play in %s in center &quot; %(self.name, self.position)jinhyun = SoccerPlayer(&quot;Jinhyun&quot;, &quot;MF&quot;, 10)print(jinhyun) self : 생성된 인스턴스를 가리킴 Implementations1234567891011121314151617181920212223242526272829303132333435363738394041class Note(object): def __init__(self, content = None): self.content = content def write_content(self, content): self.content = content def remove_all(self): self.content = &quot;&quot; def __add__(self, other): return self.content + other.content def __str__(self): return self.contentclass NoteBook(object): def __init__(self, title): self.title = title self.page_number = 1 self.notes = {} def add_note(self, note, page = 0): if self.page_number &lt; 300: if page == 0: self.notes[self.page_number] = note self.page_number += 1 else: self.notes[page]=note self.page_number += 1 else: print(&quot;Page가 모두 채워졌습니다.&quot;) def remove_note(self, page_number): if page_number in self.notes.keys(): return self.notes.pop(page_number) else: print(&quot;해당 페이지는 존재하지 않습니다&quot;) def get_number_of_pages(self): return len(self.notes.keys()) Inheritance 부모클래스로 부터 속성과 Method를 물려받은 자식 클래스를 생성 하는 것 Polymorphism 같은 이름 메소드의 내부 로직을 다르게 작성 Dynamic Typing 특성으로 인해 파이썬에서는 같은 부모클래스의 상속에서 주로 발생함 Visibility 객체의 정보를 볼 수 있는 레벨을 조절하는 것 누구나 객체 안에 모든 변수를 볼 필요가 없음 Encapsulation 123456789101112131415class Product(object): passclass Inventory(object): def __init__(self): self.__items = [] #Private 변수로 선언하여 타객체가 접근X def add_new_item(self, product): if type(product) == Product: self.__items.append(product) print(&quot;new item added&quot;) else: raise ValueError(&quot;Invalid Item&quot;) def get_number_of_items(self): return len(self.__items) 12345678910111213141516class Inventory(object): def __init__(self): self.__items = [] @property #property decorator def items(self): return self.__itemsmy_inventory = Inventory()my_inventory.add_new_item(Product())my_inventory.add_new_item(Product())print(my_inventory.get_number_of_items())items = my_inventory.itemsitems.append(Product())print(my_inventory.get_number_of_items()) Decorate First-class objects 변수나 데이터 구조에 할당이 가능한 객체 파이썬의 모든 함수는 일급함수 ex) map Inner function 함수 내에 또 다른 함수가 존재 closures : inner function을 return값으로 반환 1234567def print_msg(msg): def printer(): print(msg) return printeranother = print_msg(&quot;Hello, Python&quot;)another() 가능한 이유: 일급객체-&gt; 함수 리턴 가능, 클로저 closure example 12345678910111213141516171819def star(func): def inner(*args, **kwargs): print(&quot;*&quot; * 30) func(*args, **kwargs) print(&quot;*&quot; * 30) return innerdef percent(func): def inner(*args, **kwargs): print(&quot;%&quot; * 30) func(*args, **kwargs) print(&quot;%&quot; * 30) return inner@star@percentdef printer(msg): print(msg)printer(&quot;Hello&quot;) 12345678910111213def generate_power(exponent): def wrapper(f): def inner(*args): result = f(*args) return exponent**result return inner return wrapper@generate_power(2)def raise_two(n): return n**2print(raise_two(7)) #562949953421312 Module and Project모듈 import 모듈을 호출할 때 범위 정하는 방법 Alias 설정 -&gt; 선호 모듈에서 특정 함수 또는 클래스만 호출하기 -&gt; from 모듈에서 모든 함수 또는 클래스를 호출하기 -&gt; * Built-in Modules random time urllib 패키지 하나의대형프로젝트를만드는코드의묶음 init , main 등키워드파일명이사용됨 폴더별로init.py 구성하기 1234__all__= ['image', 'stage', 'sound']from . import imagefrom . import stagefrom . import sound __main__.py 파일만들기 12345678910from stage.main import game_startfrom stage.sub import set_stage_levelfrom image.character import show_characterfrom sound.bgm import bgm_playif __name__ == '__main__': game_start() set_stage_level(5) bgm_play(10) show_character() Package 내에서 다른 폴더의 모듈을 부를 때 상대 참조로 호출하는 방법 오픈 소스 라이브러리가상환경 설치 virtualenv와 conda가 virtualenv + pip 레퍼런스+패키지 개수 conda Windows에서 장점 conda create -n my_project python=3.9 conda activate my_project 피어 세션 morsecode 리뷰 dict(), split(), join() 활용 정규식 배우기 함수 반복 호출 시 효율성 생각해보기 알고리즘 스터디 검토","link":"/2021/01/21/BoostCamp/BoostCamp-Day4/"},{"title":"BoostCamp Day2","text":"Variable &amp; memory변수 professor = “Sungchul Choi” 의의미는” ④Professor에Sungchul Choi를넣어라 정확히는Professor라는변수에 “Sungchul Choi“ 라는값을넣으라는의미 [참고] 컴퓨터의 구조 – 폰 노이만(John von Neumann) 아키텍처 알파벳, 숫자, 언더스코어(_) 로 선언 가능 변수명은 의미 있는 단어로 표기하는 것이 좋다 변수명은 대소문자가 구분된다. 예약어는 쓰지 않는다 Dynamic Typing 실수형에서 정수형으로 형변환 시 소수점 이하 내림 [참고] 컴퓨터는 왜 이진수를 쓰나? 전류가 흐를 때 1, 흐르지 않을 때 0으로만 숫자를 표현할 수 있음 리스트 인덱싱 (Indexing) - list에 있는 값들은 주소(offset)를 가짐 슬라이싱 (Slicing) a[-9:] -9부터 끝까지(-10,-30… 모두 가능) concatenation, is_in, 연산 함수들 append, extend, insert, remove, del 등 활용 color.remove(“white”) del color[0] 다양한 Data Type이 하나에 List에 들어감 파이썬은 해당 리스트 변수에는 리스트 주소값이 저장됨 패킹과 언패킹 행렬(Matrix) 생성 import copy -&gt;copy.deepcopy Function and Console I/O함수 코드를논리적인단위로분리, 코드=보고서 함수이름, parameter, indentation,return value(optional) 함수 수행 순서 함수 부분을 제외한 메인프로그램부터 시작 함수 호출시 함수부분을 수행 후 되돌아옴 parameter vs argument parameter : 함수의 입력 값 인터페이스 argument: 실제 Parameter에 대입된 값 sorted VS sort Console I/O input() print 콤마(,) 사용할경우print 문이연결됨 숫자입력받기(형변환) print formatting % string “%datatype” % (variable) 형태로출력양식을표현 “8.2f” -&gt; 8칸 확보, 소숫점 2째자리까지만 format 함수 print( “Product: {0}, Price per unit: {1:.3f}.”.format( “Apple”, 5.243)) padding: ex) {0:&lt;10s} 왼쪽정렬 fstring (기본 왼쪽정렬(&lt;)) print(f”Hello, {name}. You are {age}.”) print(f’{name:&lt;20}’) 나머지는 로 채움 Fahrenheit Converter123456789print(&quot;본 프로그램은 섭씨를 화씨로 변환해주는 프로그램입니다.&quot;)print(&quot;변환하고 싶은 섭씨 온도를 입력해 주세요:&quot;)cell_value=float(input())fah_value=((9/5)*cel_value)+32print(f&quot;섭씨온도 : {cel_value:.2f}&quot;)print(f&quot;화씨온도 : {fah_value:.2f}&quot;)Conditionif-else, elif 조건 판단 방법 is 연산은 메모리의 주소를 비교 -5 ~256까지는 정적 메모리 and, or, not ,all , any 삼항 연산자 loof for loop 반복문 변수명 임시적인 반복 변수는 대부분 i, j, k로 정함 이것은 수학에서 변수를 x, y, z로 정하는 것과 유사한 관례 0부터 시작하는 반복문 반복문은 대부분 0부터 반복을 시작 2진수가 0부터 시작하기 때문에 0부터 시작하는 걸 권장 while문 반복의 제어 – break, continue [연습] 구구단 계산기 1234567print(&quot;구구단 몇단을 계산할까요?&quot;)dan=int(input())print(f&quot;구구단 {dan}단을 계산합니다.&quot;)구구단 5단을 계산합니다.for i in range(1,10): print(f&quot;{dan}X{i}={dan*i}&quot;) loof review print 활용 loop &amp; control lab [연습] 숫자 찾기 게임 12345678910111213import randomguess_number = random.randint(1, 100)print(&quot;숫자를 맞춰보세요 (1 ~ 100)&quot;)users_input = int(input())while (users_input is not guess_number): if users_input &gt; guess_number: print(&quot;숫자가 너무 큽니다&quot;) else: print(&quot;숫자가 너무 작습니다&quot;) users_input = int(input())else: print(&quot;정답입니다. &quot;, &quot;입력한 숫자는 &quot;, users_input, &quot;입니다&quot;) [연습] 연속적인 구구단 입력 12345678910111213141516print(&quot;구구단 몇 단을 계산할까요(1~9)?&quot;)x = 1while (x is not 0): x = int(input()) if x == 0: break if not(1 &lt;= x &lt;= 9): print(&quot;잘못 입력하셨습니다&quot;, &quot;1부터 9사이 숫자를 입력해주세요&quot;) continue else: print(&quot;구구단 &quot; + str(x) + &quot;단을 계산합니다.&quot;) for i in range(1, 10): print(str(x) + &quot; X &quot; + str(i) + &quot; = &quot; + str(x*i)) print(&quot;구구단 몇 단을 계산할까요(1~9)?&quot;) print(&quot;구구단 게임을 종료합니다&quot;) debugging 문법적 에러 들여쓰기 오탈자 대소문자 구분 안함 논리적 에러 중간 중간 픤터 문을 찍어서 확인 loop review String and advanced function conceptstring string은1byte 크기로 한 글자씩 메모리 공간이 할당됨 인덱싱 문자열의 각 문자는 개별주소(offset)를 가짐 List와 같은 형태로 데이터를 처리함 함수 a.capitalize(첫 문자 대문자) 큰따옴표 작은 따옴표 ① a = ‘It\\’ ok.’ ② a = “It’s ok.” # raw string Yesterday 노래엔 Yesterday 라는 말이 몇 번 나올까? 12345678910f = open(&quot;yesterday.txt&quot;, 'r')yesterday_lyric =&quot;&quot;while True: line = f.readline() if not line: break yesterday_lyric = yesterday_lyric + line.strip() + &quot;\\n&quot;f.close()n _of_yesterday = yesterday_lyric.upper().count(&quot;YESTERDAY&quot;) # 대소문자 구분 제거print (&quot;Number of a Word 'Yesterday'&quot; , n_of_yesterday) Call by object reference 파이썬은 객체의 주소가 함수로 전달되는 방식 전달된 객체를 참조하여 변경 시 호출자에게 영향을 주나, 새로운 객체를 만들 경우 호출자에게 영향을 주지 않음 swap Scoping Rule 변수의 범위 1234567def test(t): print(x) t = 20 #x의 값은 영향을 주지 않는다. 관계가 끊어졌기 떄문 print (&quot;In Function :&quot;, t)x = 10test(x)print(t) recursive function function type hints 12def type_hint_example(name: str) -&gt; str: return f&quot;Hello, {name}&quot; docstring 세계의 따옴표 함수 가이드 라인 함수 작성 가이드 라인 함수 이름에 함수의 역할, 의도가 명확히 들어낼 것 하나의 함수에는 유사한 역할을 하는 코드만 포함 피어 세션과제 리뷰 과제 풀이 후 코드 리뷰 strip() vs split() string.title() baseball 시간 좀 걸림 함수 단위로 작성시 복잡해 보였지만 코드 보기가 편해짐","link":"/2021/01/19/BoostCamp/BoostCamp-Day2/"},{"title":"Day10","text":"Data Visualizationmatplotlib pyplot객체를 사용 단점 : argument를 kwargs받음 set linestyle https://matplotlib.org/examples/lines_bars_and_markers/linestyles.html title xlabel, ylabel legen 범례 scatter bar seaborn hue : 카테고리 데이터 scatterplot : 퍼짐 regplot : regression line countplot ==value_counts() 통계학모수 통계적 모델링은 적절한 가정 위에서 확률분포를 추정하는 것이 목표 유한한 개수의 데이터를 관찰해서 모집단의 분포를 정확하게 알아내는 것은 불가능, 근사적으로 확률분포를 추정할 수 밖에 없다. 예측모형의 목적은 분포를 정확하게 맞추는 것보다 데이터와 추정 방법의 불확식성을 고려해서 위험을 최소화하는 것이다. 데이터가 특정 확률분포를 따른다고 선험적으로(a priori) 가정한 후 그 분포를 결정하는 모수(parameter)를 추정하는 방법을 모수적방법론 (평균과 분산을 추정하는 방법을 통해서 데이터를 학습하는 방법을 모수적 방법론) 특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌면 비모수방법론이라 부른다. 비모수 방법론은 모수가 없는 것이 아니라 무한히 많거나 모수의 개수가 데이터에 따라서 바뀌는 경우이다. 둘의 차이는 어떤 가정을 미리 부여하는지 아닌지에 따라서 구별된다. 예제 표본분포(sample distribution)과 표집분포는 다르다 표집분포 : 표본평균과 표본분산의 확률분포 모집단의 분포가 정규분포를 따르지 않으면 표본분포는 데이터를 많이 모아도 정규분포가 될 수 없다. 모집단의 분포가 정규분포를 따르지 않아도 표본평균의 표집분포는 정규분포를 따른다 표본평균의 분산$\\sigma^2\\over n$는 데이터의 개수(n)이 늘어나면 0으로 수렴 원래 확률분포는 이항분포이고 이항분포의 표본분포는 데이터를 모아도 정규분포가 되지 않지만 이항분포에서 추출한 통계량, 즉 표본평균의 확률분포는 정규분포로 가고 이를 중심극한 정리라고 한다. 표본평균과 표본분산만으로 확률분포를 추정하는 것은 위험하고 최대가능도 추정법을 활용 확률밀도함수, 확률질량함수와 같다. 단지 관점의 차이 확률밀도함수는 모수($\\theta$)가 주어져 있을 때 x에 대한 함수로 해석 가능도함수는 주어진 데이터($x$)에 대해서 모수($\\theta$)를 변수로둔 함수로 해석-&gt; 데이터가 주어진 상황에서 ($\\theta$)를 변형시킴에 따라 값이 바뀌는 함수 ($\\theta$)에 대한 확률로 해석하면 안되고 가능도는 오로지 ($\\theta$)에 대해서 크고 작음에 따른 대소비교가 가능한 함수로 이해하자 이산확률변수 카테고리 예제 원핫벡터 $x_(i,k)$는 0,1만 가진다 - further question 확률 VS 가능도","link":"/2021/01/29/BoostCamp/Day10/"},{"title":"BoostCamp Day5","text":"ExceptionException Handling try ~ except 문법 1234567for i in range(10): try: print(10 / i) except ZeroDivisionError as e: print(&quot;Not divided by 0&quot;) except Exception as e: #전체 exception은 비추 print(e) if문 만으로 가능 IndexError NameError : 존재하지 않은 변수를 호출 할 때 ZeroDivisionError ValueError : 변환할 수 없는 문자/숫자를 변환할 때 FileNotFoundError try ~ except ~ else (예외 발생하지 않을 때 else문) try ~ except ~ finally raise 구문 필요에 따라 강제로 Exception을 발생 assert 구문 True or False File Handling Text vs Binary text : 문자열, 메모장 확인 binary : 메모장 깨짐, app종속, ex) 엑셀, 워드, 한글 read write open with문과 사용 readlines() : 파일 전체를 list로 반환 readline() : 한 줄씩 write encoding : utf8 mode a : 덮어씀 directory import os os.mkdir os.path.isdir or exists import pathlib pathlib.Path.cwd() import pickle -&gt;객체 영속화 pickle.dump pickle.load Logging Handling Console 화면에 출력, 파일에 남기기, DB에 남기기 등등 기록된 로그를 분석하여 의미있는 결과를 도출 할 수 있음 실행시점에서 남겨야 하는 기록, 개발시점에서 남겨야하는 기록 print로 남기는 것도 가능 그러나 Console 창에만 남기는 기록은 분석시 사용불가 때로는 레벨별(개발, 운영)로 기록을 남길 필요도 있음 logging 모듈 1234567import logginglogger = logging.getLogger(&quot;main&quot;)logging.basicConfig(level=logging.DEBUG)logger.setLevel(logging.INFO) 설정 configparser 프로그램의 실행 설정을 file에 저장함 Section, Key, Value 값의 형태로 설정된 설정 파일을 사용 dict config.sections() : 섹션 리스트 호출 argparser Console 창에서 프로그램 실행시 Setting 정보를 저장함 Logging formatter Log의 결과값의 format을 지정해줄 수 있음 formatter = logging.Formatter(‘%(asctime)s %(levelname)s %(process)d %(message)s’) Data HandlingComma separate Values (CSV) 엑셀 양식의 데이터를 프로그램에 상관없이 쓰기 위한 데이터 형식이라고 생각하면 쉬움 Text 파일 형태로 데이터 처리시 문장 내에 들어 가있는“,” 등에 대해 전처리 과정이필요 import cs Web 정규식 XML 데이터의 구조와 의미를 설명하는 TAG(MarkUp)를 사용하여 표시하는 언어 가장 많이 쓰이는 parser인 beautifulsoup으로 파싱 JSON loads, dump 마스터 클래스 ai 종류 classification clustering 추천 RL(강화학습) 생성 수학 선형대수 미적분 통계학 수리통계 해석학 ML/DL : 논문 -&gt; 파이프라인 ,리소스 관리(경량화) DS : 넓은 개념 기술 스택 스파크 하둡 에어플로우 피어세션 파이토치 순서 정함 정규식 연습 cs","link":"/2021/01/22/BoostCamp/BoostCamp-Day5/"},{"title":"Day12","text":"OptimizationGeneralization 일반화 성능을 높이는 것이 목적 Cross-validation(k fold) 하이퍼 파라미터가 많이 존재하기 때문에(lr) cross-validation을 통해 최적의 하이퍼파라미터를 찾고 이를 고정시킨 상태에서 학습시킬 때는 모든 데이터를 사용 Bias and variance 학습데이터에 노이즈가 있을 경우 bias와 variance를 둘 다 줄이기는 힘들다 Boostrapping Bagging vs Boosting Gradient Descent Methods Batch-size Matters 배치 너무 크면 sharp minimizers 너무 작으면 flat minimizers Momentum Nesterov Accelerated Gradient Adagrad Adadelta RMSporp Adam Regularization학습데이터뿐만 아니라 테스트 데이터에도 잘 작동하도록 규제하는 것 Early stopping parameter norm penalty 파라미터가 너무 크지 않게 하는 것 Data augmentation Noise robustness Label smoothing Dropout Batch normalization Internal Covariate(feature) Shift를 줄인다 성능은 올라간다 CNN","link":"/2021/02/02/BoostCamp/Day12/"},{"title":"Day13","text":"CNN fully connected 없어지는 추세이다 parameter의 숫자를 줄이기 위해 Stride Padding dense layer의 parameter가 많은 이유는 각각의 커널이 모두 적용되기 때문이다. parameter를 줄이는 것이 중요-&gt;1x1 convolution 11x11 커널은 좋은것은 아니다 3x3만 사용 3x3과 5x5는 receptive field 차원에서는 똑같지만 parameter의 수는 다르다 인셉션 블록 여러개의 response를 concatenate하는 효과도 있지만 1x1을 사용함으로써 param수를 줄일 수 있게 된다. 3x3전에 input채널을 줄이고 3x3후에 output채널을 늘린다. resnet의 더하기 대신 concat 채널이 점점 커진다 -&gt; param수도 늘어남 1x1을 사용해 transition block에서 줄인다 Computer Visionsemantic segmentation pixel마다 분류 param수는 같다 엄밀히 말하면 복원할 수는 없다. Detection R-CNN 바운딩 박스를 뽑는 것도 네트워크로 학습 RPN : 이미지로 특정 위치가 바운딩 박스로써 의미가 있을지 없을지 판단 물체가 무엇인지는 판단x anchor boxes: 미리 정해놓은 바운딩 박스의 크기 size 3개 ration 3개 -&gt;9 width,height,x,y-&gt;4 해당 바운딩 박스가 쓸모있는지 없는지 -&gt;2 YOLO 한번에 분류 바운딩 박스를 뽑는 region propoasl이 없다","link":"/2021/02/03/BoostCamp/Day13/"},{"title":"Day11","text":"베이즈 통계학 History Pytorchs Kaiming initialization https://towardsdatascience.com/understand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138","link":"/2021/02/01/BoostCamp/Day11/"},{"title":"Day16","text":"NLP Low level Tokenizaition, stemming(형태소 분석) Word and Phase level Named entity recognition(NER)-&gt;고유명사 ex)new york times part-of-speech(POS) tagging-&gt;성분 분석(명사,형용사) Sentence level Sentiment , machine translation Multi-sentence and paragraph level Entailment prediction(문장간 논리), question answering(where did napoleon die?), dialog system(chatbot), summarization Text mining 트렌드 분석 clustering (topic modeling) highly related to computational social science (SNS) KDD, The WebConf Information retreival(검색) highly related to computation social science recommendation system Trends of NLP each word can be represented as a vector (Word2Vec or GloVe) RNN (LSTM, GRUs) attention ,transformer in early days, customized models for different NLP tasks self-supervised-&gt;BERT, GPT-3 Bag-of-Words step1 중복단어 제거 step2 encodng unique words to one-hot vectors distance is $\\sqrt2$ cosine is 0 sentence can be represented as sum of one-hot vectors john really really loves this movie [1 2 1 1 1 0 0 0] NaiveBayes Classifier Word Embedding Express a word as a vector Same relationship is represented as the same vectors Word2Vec 인접한 단어들간의 의미가 비슷할 것이다-word간의 의미관계를 vector로 잘 표현 Intrusion Detection application translation sentiment analysis image captioning GloVe 중복되는 계산을 줄여 빠름 Word2Vec 2가지 CBOW vs skip-gramCBOW skip-gram","link":"/2021/02/16/BoostCamp/Day16/"},{"title":"Day18","text":"seq2seq Model many to many 인코더와 디코더로 구성 인코더의 마지막 hidden state vector는 디코더의 $h_0$로 사용 디코더에서 첫번쨰 단어로 를 넣어주고 나올떄까지 실행 With attention 정보의 유살때문 인코더의 마지막 hidden state vector하나만 사용하는 것이 아닌 각각 인코더의 hidden state vector 사용 $h^e_1, h^e_2…$ Attention output vector: 인코더의 hidden state vector의 가중평균 디코더의 hidden state vector의 2가지 역할 output layer(다음단어)의 입력 인코더의 hidden state vector중 어떤걸 중점적으로 할지 결정 디코더의 각 timestep에서의 입력은 Ground-truth 전 단계에서 잘못 예측하더라도 Ground-truth에서 올바른 입력을 넣어줌 Teacher forcing 실제 사용 환경에서 괴리가 있을 수 있다. 학습의 후반부에 예측한 값을 입력으로 줄 수 있다 Different Attention Mechanism디코더의 hidden state와 인코더의 hidden state와의 유사도를 구하는 다양한 방법 general concat Attention is Great 기계번역 성능 향상 information bottleneck problem 해결 Gradien vanishing 해결 많은 timestep을 거치지 않고 지름길이 만들어짐 backpropagation 해석가능성 제공 디코더가 인코더상의 어떤단어에 집중했는지 알 수 있다. Beam search Greedy decoding 근시안적인 문제점 잘못생성 시 돌아갈 수 없음 Exhaustive search joint probability $O(v^t)$ Greedy와 Exhaustive search의 중간 아이디어: 디코더의 timestemp마다 정해진 k개의 가능한 가지 수 고려, beam size Beam size=2 beam search의 디코딩 과정에서는 서로 다른 경로(hypotheses)가 존재하고 각각 다른 시점에서 생성 가 생성되면 그 경로는 종료 후 저장 Stop criterion time step T least n completed hypotheses 종료 후 완료된 hypotheses들 중 가장 높은 점수를 고른다 문제점 길이가 길수록 점수가 낮다 Fix: normalize by length BLEU score 문제점: 생성된 문장 전체를 비교하는 것이 아니라 고정된 위치의 단어 하나가 나와야 된다는 평가방식 precision and recall precision: 예측된 결과가 노출되었을 때 실질적으로 느끼는 정확도 ex) 검색결과 recall: 노출되어야 할 것들 중 실제 노출된 것 F-measure은 조화평균 순서가 맞지 않음에도 높은 값 따라서 BLUE score (BiLingual Evaluation Understudy) N-gram 연속된 n개의 단어로 봤을때 ground-truth와 얼마나 겹치는가 n: 1~4 recall 무시 어느정도 생략되어도 괜찮기 때문이다 recall이 높아도 명백한 오역이 될 수 있기 때문이다. 기하평균 조화평균은 크기가 작은 값에 지나치게 큰 가중치를 준다 예측값이 아무리 길어도 1-&gt; recall도 고려 Further Question BLEU score가 번역 문장 평가에 있어서 갖는 단점은 무엇이 있을까요?","link":"/2021/02/18/BoostCamp/Day18/"},{"title":"Day15","text":"Generative ModelsWhat does it mean to learn a generative model? Generation-&gt;sampling Densitiy estimation :$p(x)$ should be high if x looks like dog-&gt;explicit models unsuperviesd representation learning-&gt; feature learning How can we represent $p(x)$ Auto-regressive Model Latent Variable Models posterior distribution을 근사할 수 있는 variational distribution을 찾는 것 explicit하지 않다 reconstruction을 무엇을 해도 되지만 kl-divergence는 가우시안을 사용 isotropic gaussian 단점 : encoder를 활용할 떄 prior fitting term이 kl-divergence를 활용한다는 것 GAN 장점 : discriminator가 점차 좋아진다","link":"/2021/02/05/BoostCamp/Day15/"},{"title":"Day17","text":"RNN ​ rolled unrolled $y_t$는 매 타임스텝마다 계산할 수도 있도 마지막 타임스텝에만 계산할 수도 있다. 품사 분석 -&gt; 매 타임스텝 감정 분석-&gt; 마지막 타임스텝만 parameter $W$ 를 공유 RNN은 왜 tanh를 사용할까? RNN의 Vanishing gradient 문제를 예방하기 위해서 gradient가 최대한 오래 유지될 수 있도록 해주는 역할로 tanh가 적합하기 때문입니다. Types of RNNs one to one standard neural networdk one to many image captionning 추가적인 입력이 없는 경우 같은 사이즈의 텐서가 들어가되 모두 0으로 채워짐 many to one sentiment classification 입력의 길이에 따라 RNN cell 확장 many to many 입력과 출력 모두 sequence machine translation video classification on frame level, pos태깅 Character level Language Model 다음 단어를 예측해야함 $h_0$는 0으로 초기화된 값 output layer에 softmax적용 예측값을 다음 타임스텝의 입력으로 넣어줌 ex) 주식가격 셰익스피어의 희곡 학습 초반에는 의미없는 값 생성 논문 작성 Latex사용 코드 작성 Character level Language Model의 학습 과정 Backpropagation throgh time sequence를 잘라서 학습(truncation) RNN에서 필요한 정보를 저장하는 공간은 hidden state vector hidden state vector 각각의 차원 한개를 고정하고 그 값이 진행됨에 따라서 어떻게 변하는지 분석한다 특정 dimension(cell)의 역활(따옴표) if조건문 Vanilla RNN에서는 Vanishing/Exploding Gradient problem 발생 LSTM Vanishing/Exploding Gradient 해결 타임스텝이 멀어져도 효과적 Forget gate Gate gate $i_t$를 곱해주는 것은 $C_{t-1}$에 더해줄 정보에서 값을 덜어내는것 $h_t$ $C_t$: 기억해야할 모든 정보 $h_t$: output layer의 입력으로 사용, $C_t$에서 당장 필요한 정보만 필터링 GRU cell state와 hidden state 합침 계산량, 메모리 요구량 줄임 input gate가 커질수록 forget gate 작아짐 LSTM,GRU backpropagation 곱해주는 것이 아닌 필요한 정보를 더하여 vanishing 해결 멀리있는 타임스텝까지 gradient 변형없이 전달 Further Question BPTT 이외에 RNN/LSTM/GRU의 구조를 유지하면서 gradient vanishing/exploding 문제를 완화할 수 있는 방법이 있을까요? RNN/LSTM/GRU 기반의 Language Model에서 초반 time step의 정보를 전달하기 어려운 점을 완화할 수 있는 방법이 있을까요?","link":"/2021/02/17/BoostCamp/Day17/"},{"title":"Day14","text":"RNN 시계열, sequence 데이터 독립동등분포를 잘 위배한다. ex) 개가사람을 문다. 사람이 개를 문다. 앞뒤 문맥없이 예측하는 것은 힘들다. 데이터의 위치를 함부로 바꾸면 안됨 모든 데이터가 필요한건 아니다. 위 MLP는 과거의 정보를 다룰 수 없다. 가중치 3개 wx1 wh1 w2 ,이것은 t에 따라 변하지 않는다. ex) 내읠 시험 전수는 전날에만 의존한다. 중간 hidden state-&gt; 과거의 정보를 요약 과거의 정보가 미래까지 살아남기 힘듦 한참 전의 step은 소실 문장이 길어져도 이전의 정보를 고려해야 하는데 그러지 못한다. activation $\\phi$가 sigmoid라면 $h_0$는 의미가 없어지게 된다. Relu를 써도 마찬가지 forget gate: $f_t$는 0~1값 -&gt;이전 cell state에서 어떤걸 버리고 살릴지 결정 input gate: 어떤 정보를 올릴지 결정 Transformer n개의 단어가 어떻게 한번에 처리되는지 인코더와 디코더 사이의 어떤 정보를 주고 받는지 디코더가 어떻게 generation하는지 bias","link":"/2021/02/04/BoostCamp/Day14/"},{"title":"Day19","text":"TransformerAttention만을 사용해 RNN대체 기존 RNN 모델의 한계 long-term dependecy problem Bi-Directional RNNs 왼쪽, 오른쪽 정보 같이 포함할 수 있도록 forward, backward RNN 두 개의 모듈을 병렬적으로 만듦 Transformer 인코더 input vector는 각각 query벡터로 변환 query vector 와 key vector 내적을 통해 새로운 vector 생성 key vector: query vector와 내적, 여러개의 key vector들 중 어느것이 query와 연관있는 지 value: 가중평균 구하는데 쓰이는 재료 vector value 벡터에 대한 가중편균-&gt; 모든 단어의 정보 고려 seq 길이가 길어도 동일한 key value들로 변환되고 query와 유사도만 높다면 멀리있는 정보도 쉽게 가져올 수 있다. input을그대로 사용하면 자기 자신과의 내적이 가장 커지는 문제 input q (k,v) q,k의 차원은 같지만 v의 차원은 달라도 됨 query가 여러개 병렬적인 행렬 연산을 통해 학습이 빠름 Scaled dot product 분산이 작을수록 표준편차가 작고 확률분포가 uniform distribution(30~50%)에 가깝게 나타난다 어느 한 key에만 극단적으로 몰리는것을 방지 분산이 1인 형태로 유지 한쪽으로 몰리는 경우 gradient vanishing 발생 가능 Multi Head Attention여러개의 attention을 사용하여 여러 문장이 있을 때 다양한 관점에서 정보를 뽑는다. Multi-head attention을 사용하는 이유는 같은 문장에서도 중점을 두어야 할 단어들이 다를 수 있기 때문 복잡도 self-attention의 메모리 사용은 seq에 따라 커질 수 있지만 병렬적으로 수행 사능 RNN은 dimension으로 조절할 수 있지만 병렬 수행 불가 Block-Based Model 2개의 sub layers multi-head attention feed-forward NN with ReLU (Fully connected) 각각 2개의 step residual conneciton and layer normalization LayerNorm(x+sublayer(x)) Layer Normalization 평균0 분산1으로 만듦 step1: 각 단어 vector를 평균0 분산1이되도록 normalization step2: Affine transformation? Positional Encoding 순서를 무시 따라서 순서 정보를 포함 시킴 상수vector를 입력vector에 더해줌(주기함수 사용) Learning Rate Scheduling Learning Rate를 학습하면서 변화 Decoder 디코더에서 만든 hidden state vector가 query로 사용 Masked Self attention Further Question Attention은 이름 그대로 어떤 단어의 정보를 얼마나 가져올 지 알려주는 직관적인 방법처럼 보입니다. Attention을 모델의 Output을 설명하는 데에 활용할 수 있을까요?","link":"/2021/02/19/BoostCamp/Day19/"},{"title":"Day21","text":"그래프 그래프는 정점(Vertex) 집합과, 간선(Edge) 집합으로 이루어진 수학적 구조이다. 네트워크로도 불리며, 정점은 노드(Node)로, 간선은 엣지(Edge) 혹은 링크(Link)로도 불린다. 우리 주변의 많은 복잡계(Complex System)는 구성 요소 간의 복잡한 상호작용을 하는 특성이 있다 그래프는 이복잡계의 상호작용을 효과적으로 표현하고, 복잡계를 분석하기 위한 언어이다. 정점 분류(Node Classification) 문제 트위터에서의 공유(Retweet) 관계를 분석하여, 각 사용자의 정치적 성향을 파악 백질의 상호작용을 분석 연결 예측(Link Prediction) 문제 거시적 - 페이스북 소셜네트워크는 진화 방향 예측 미시적 : 추천시스템 군집 분석(Community Detection) 문제 연결 관계로부터 사회적 무리(Social Circle)을 찾아내기 랭킹(Ranking) 및 정보 검색(Information Retrieval) 문제 웹(Web)이라는 거대한 그래프로부터 중요한 웹페이지 찾아내기 정보 전파(Information Cascading) 및 바이럴 마케팅(Viral Marketing) 문제 정보 전달을 최대화 그래프의 유형 및 분류 표현 방식 일반적으로 정점들의 집합을 _V_, 간선들의 집합을 _E_, 그래프를 _G_=(_V_,_E_)로 적는다. 방향성이 있는 그래프에서는 나가는 이웃들의 집합을 $N_{out}{(v)}$ 들어오는 이웃들의 집합을 $N_{in}{(v)}$으로 표시 간선 리스트(Edge List) - 그래프를 간선들의 리스트로 저장한다 간선이 연결하는 두 정점들의 순서쌍(Pair)로 저장된다. 방향성이 있는 간선의 경우 (출발점, 도착점) 순서로 저장 인접 리스트(Adjacent List) - 각 정점들의 이웃들을 리스트로 저장한다. 방향성이 없는 경우 방향성이 있는 경우 인접 행렬(Adjacent Matrix) 방향성이 없는 경우 방향성이 있는 경우 행렬의 원소가 대부분 0이 아닌 경우에 일반행렬이 더 빠르다 실제 그래프와 랜덤 그래프 실제 그래프(RealGraph)란 다양한 복잡계로 부터 얻어진 그래프 MSN 랜덤 그래프(RandomGraph)는 확률적 과정을 통해 생성한 그래프 에르되스(Erdős)와 레니(Rényi)가 제안한 랜덤 그래프 모델 임의의 두 정점 사이에 간선이 존재하는지 여부는 동일한 확률 분포에 의해 결정됩니다 에르되스-레니 랜덤그래프 $G(n,p)$는 n개의 정점을 가지고 임의의 두 개의 정점 사이에 간선이 존재할 확률은 p 정점 간의 연결은 서로 독립적 Q. G(3,0.3) 에 의해 생성될 수 있는 그래프와 각각의 확률은? 작은 세상 효과 경로와 거리 정점 u와 _v_ 사이의 경로(Path)는 아래 조건을 만족하는 정점들의 순열(Sequence)이다 u에서 시작하여 v에서 끝난다. 순열에서 연속된 정점은 간선으로 연결되어 있어야 한다. 경로의 길이는 해당 경로 상에 놓이는 간선의 수로 정의된다. 경로의 길이= 순열에 존재하는 정점들의 수-1 정점 u와 v 사이의 거리(Distance)는 u와 v* 사이 최단경로의 길이이다. 지름(Diameter)은 정점 간 거리의 최댓값이다 작은 세상 효과 임의의 두 사람을 골랐을 때, 몇 단계의 지인을 거쳐 연결되어 있을까? 평균적으로 6단계만을 거쳤습니다 MSN메신저 그래프에서는 어떨까요? 정점 간의 평균 거리는 7 정도 밖에 되지 않습니다 작은 세상 효과는 높은 확률로 랜덤 그래프에도 존재 모든 사람이 100명의 지인이 있다고 가정해봅시다 다섯 단계를 거치면 최대 100억(= $100^5$)명의 사람과 연결될 수 있습니다 하지만 모든 그래프에서 작은 세상 효과가 존재하는 것은 아닙니다 연결성의 두터운 꼬리 분포 연결성 정점의 연결성(Degree)은 그 정점과 연결된 간선의 수를 의미합니다 정점 V의 연결성은 해당 정점의 이웃들의 수와 같습니다 보통 정점 V의 연결성은 $d(v)$, $d_v$혹은 $|N(v)|$ 로 적습니다 두터운 꼬리 분포 실제 그래프의 연결성 분포는 두터운 꼬리(HeavyTail)를 갖습니다 즉,연결성이 매우 높은 허브(Hub) 정점이 존재함을 의미합니다 랜덤 그래프의 연결성 분포는 높은 확률로 정규 분포와 유사합니다 연결성이 매우 높은 허브(Hub) 정점이 존재할 가능성은 0 정규 분포와 유사한 예시로는 키의 분포가 있습니다 거대 연결 요소 연결 요소 연결 요소(ConnectedComponent)는 다음 조건들을 만족하는 정점들의 집합을 의미합니다 연결 요소에 속하는 정점들은 경로로 연결될 수 있습니다 1의 조건을 만족하면서 정점을 추가할 수 없습니다 거대 연결 요소 실제 그래프에는 거대 연결 요소(GiantConnectedComponent)가 존재합니다 거대 연결 요소는 대다수의 정점을 포함합니다 MSN메신저 그래프에는 99.9%의 정점이 하나의 거대 연결 요소에 포함됩니다 랜덤 그래프에도 높은 확률로 거대 연결 요소(GiantConnectedComponent)가 존재합니다 단,정점들의 평균 연결성이 1보다 충분히 커야 합니다 는 RandomGraphTheory 군집 계수 군집 군집(Community)이란 다음 조건들을 만족하는 정점들의 집합입니다 집합에 속하는 정점 사이에는 많은 간선이 존재합니다 집합에 속하는 정점과 그렇지 않은 정점 사이에는 적은 수의 간선이 존재합니다 수학적으로 엄밀한 정의는 아니다. 지역적 군집 계수 지역적 군집 계수(LocalClusteringCoefficient)는 한 정점에서 군집의 형성 정도를 측정합니다 지역적 군집 계수(LocalClusteringCoefficient)는 한 정점에서 군집의 형성 정도를 측정합니다 연결성이 0인 정점에서는 지역적 군집 계수가 정의되지 않습니다 지역적 군집 계수가 군집이랑 어떻게 연결되는 것이죠? 정점 i의 지역적 군집 계수가 매우 높다고 합시다 즉,정점 i의 이웃들도 높은 확률로 서로 간선으로 연결되어 있습니다 정점 i와 그 이웃들은 높은 확률로 군집을 형성합니다 전역 군집 계수 전역 군집 계수(GlobalClusteringCoefficient)는 전체 그래프에서 군집의 형성 정도를 측정합니다 그래프 G의 전역 군집 계수는 각 정점에서의 지역적 군집 계수의 평균입니다 단,지역적 군집 계수가 정의되지 않는 정점은 제외합니다 높은 군집 계수 실제 그래프에서는 군집 계수가 높다. 즉, 많은 군집이 존재한다. 이유에는 여러가지가 있다. 동질성(Homophily) : 서로 유사한 정점끼리 간선으로 연결될 가능성이 높다. 같은 동네에 사는 같은 나이의 아이들이 친구가 되는 경우가 그 예시입니다 전이성(Transitivity) : 공통 이웃이 있는 경우, 공통 이웃이 매개 역할을 해줄 수 있다. 친구를 서로에게 소개해주는 경우가 그 예시입니다 반면 랜덤 그래프에서는 지역적 혹은 전역 군집 계수가 높지 않습니다 구체적으로 랜덤 그래프 G(n,p)에서의 군집 계수는 p입니다 랜덤 그래프에서의 간선 연결이 독립적인 것을 고려하면 당연한 결과입니다","link":"/2021/02/23/BoostCamp/Day21/"},{"title":"Day22","text":"웹과 그래프 웹은 웹페이지와 하이퍼링크로 구성된 거대한 방향성 있는 그래프 정점: 웹페이지, 간선: 하이퍼링크 검색 엔진 웹을 거대한 디렉토리로 정리 -&gt; 카테고리의 수와 깊이도 무한정 커지는 문제 키워드에 의존한 검색 엔진 악의적인 웹페이지에 취약 Q 사용자 키워드와 관련성이 높고 신뢰할 수 있는 웹페이지를 어떻게 찾을 수 있을까? A. 페이지랭크 페이지랭크 페이지랭크의 핵심 아이디어는 투표(하이퍼링크) 들어노는 간선이 많을 수록 신뢰할 수 있다는 뜻 들어오는 간선의 수를 세는 것만으로 충분할까? 악용될 소지가 있다. 웹페이지를 여러 개 만들어서 간선의 수를 부풀릴 수 있다 돈을 주고 트위터의 팔로어를 늘리는 것 이런 악용에 의한 효과를 줄이기 위해 가중 투표를한다. 관련성이 높고 신뢰할 수 있는 웹사이트의 투표를 더 중요하게 간주한다. 관련성과 신뢰성을 출력과 입력으로 사용한다-&gt; 재귀,연립방정식을 통해 가능 페이지랭크 점수 _자신의 페이지랭크 점수/나가는 이웃의 수_ 만큼의 가중치로 투표한다. 각 웹페이지의 페이지랭크 점수는 받은 투표의 가중치 합으로 정의 투표의 관점이 아닌 임의 보행 관점 웹퍼서는 하이퍼링크 중 하나를 균일한 확률로 클릭 웹서퍼가 t번째 방문한 웹페이지가 웹페이지 i일 확률을 $p_i(t)$ $p(t)$는 길이가 웹페이지 수와 같은 확률분포 벡터 모든 페이지에서 웹페이지 i를 클릭할 확률 $p_i(t)$를 모두 모아놓은 벡터이다. 당연히 길이가 웹페이지 수와 같아진다. 웹서퍼가 이 과정을 무한히 반복하고 나면, 즉 t가 무한히 커지먼 확률본포 p(t)는 수렴 p(t)=p(t+1)=p 수렴한 확률분포 p는 정상분포라고 부른다 투표 관점에서 정의한 페이지랭크점수와 동일하다 페이지랭크의 계산 반복곱(power iteration) 각 웹페이지의 i의 페이지랭크 점수$r_i^{(0)}$를 _1/웹페이지의 수_로 초기화 페이지랭크 점수를 갱신, 각 정점이 받은 투표의 가중치 합산 페이지랭크 점수가 수렴하였으면 종료, 아닌 경우 2로 Q1. 반복곱이 한상 수렴하는 것을 보장할 수 있나? Q2. 반복곱이 합리적인 점수로 수렴하는 것을 보장할 수 있나? B가 점수가 높은 이유는 많은 정점으로부터 투표를 받고 있기 때문 투표를 받지 않아도 순간이동으로 페이지랭크 점수가 0이 아니다 c의 점수가 높은 이유는 b로부터 들어오기 때문 (소중한 한표) 그래프를 바이럴 마케팅에 어떻게 활용할까? 그래프를 통한 전파의 예시, 정보 행동 고장 질병 SNS을 통해 정보 전파 아이스버킷 챌린지, 펭권문제등의 행동 전파 컴퓨터 네트워크에서 일부장비의 고장이 다른 장비의 과부하로 이어져 전체 네트워크를 마비시킬 수 있다 코로나 메르스등의 질병 전파 전파과정을 치계적으로 이해하고 대처하기 위해서는 수학적 모형화가 필요 의사결정 기반의 전파 모형 언제 사용하는가 주변 사람의 의사결정이 본인의 의사결정에 영향을 미친다. 주변사람들의 의사결정을 고려하여 각자 의사결정을 내리는 경우 의사결정 기반의 전파 모형을 사용한다. 카카오 vs 라인 확률적 전파 모형(독립적 전파 모형) 의사결정 기반의 전파 모형은 전파 과정을 간단하게 표현할 수 있지만, ‘의지’나 ‘결정’이 들어가지 않은 전파에 대해서는 적합하지 않다. 코로나의 전파 과정은 확률적 과정이기 떄문에 확률적 전파 모형을 고려해야 한다. 가장 간단한 형태의 확률적 전파 모형인 독립 전파 모형 서로 다른 이웃이 전염되는 확률은 독립적이므로, 최초 감염자들로부터 전파가 늘어남에 따라 전파확률이 기하급수적으로 늘어나게 된다. 한번 감염자는 계속 감염자 회복을 가정하는 SIS, SIR등의 다른 전파 모형도 있다. 전파 최대화 문제 바이럴 마케팅이란 시드 집합의 중요성 전파 최대화 문제 대신에, 최고의 시드 집합에 근사하는 휴리스틱(heuristics)을 사용해 볼 수 있다. 휴리스틱이란 실험적으로 잘 동작하지만 이론적으로는 보장할 수 없는 알고리즘 연결 중심성 : 연결성이 높은 정점들이 높은 중심성을 갖는다 근접 중심성 : 다른 정점들과의 평균 거리를 측정한 뒤 평균 거리가 낮은 정점들이 높은 근접 중심성을 갖는다 매개 중심성 : 정점 간 최단 경로를 고려하여 최단 경로에 많이 놓인 정점일수록 매개 중심성이 높다 탐욕 알고리즘 탐욕 알고리즘 역시 많이 사용된다. 시드 집합의 원소, 즉 최초 전파자를 한번에 한명씩 선택하며, 매 순간 시뮬레이션 하여 더 많은 전파를 일으킬 수 있는 시드를 찾아 다음 타겟으로 지목한다. 탐욕 알고리즘으로 찾은 시드 집합에 의한 평균 전파 크기가, 최고(이상적) 시드집합에 의한 평균 전파크기의 최소 0.632배 이상은 된다는 것이 증명되어있다. 즉, 최저성능이 보장되어있다.","link":"/2021/02/24/BoostCamp/Day22/"},{"title":"Day20","text":"Recent Trends self-attention block을 많이 쌓는다 self-supervised learning framework 추천시스템 신약개발 영상처리 자연어 생성 task에서 여전히 greedy decoding 벗어나지 못함 GPT-1 special token을 제안해서 다양한 자연어 처리 task를 가능하게 함 12개의 self-attention block text prediction: 다음단어 예측하는 language modelling 입력과 출력이 따로 있지 않음 sentiment analysis, classification과 같은 label된 데이터가 있을때 multi-task learning에 의해서 학습 토큰과 다른 extract토큰으로 바꾼 후 인코딩 extract토큰만을 선형변환을 통해 긍부정에 대한 output 예측 entailment task 두 개의 문장을 하나의 sequence로 만들되 중간에 Delim토큰 extract토큰을 output layer에 통과시켜 분류 시행 extract토큰이 query로 사용되어서 task에 필요한 여러 정보들을 input으로부터 정보를 추출할 수 있어야함 학습된 GPT-1모델을 transfer learning형태로 활용할 때 가령 긍부정 분류를 하다가 주제분류를 하게되면 downstream task로써 learning rate BERT 다음단어를 예측하는 language modelling방식으로 학습시킨 모델 Pre-training Task in BERT Masked Language Model 얼마나 가릴지 hyperparameter 15% 너무 높거나 낮으면 문제 15% 다 MASK로 바꾸는 것이 아닌 80(MASK) 10(random word) 10(keep same) Next Sentence Prediction 문장레벨에서의 task에 대응하기 위한 기법 두 문장이 인접한 문장인지 구별하는 binary classification [CLS] : GPT의 extract, 문장의 앞 [SEP] : 문장 사이, 끝날 때 Summary self-attention block arichitecture base: L=12 H(인코딩vector의 차원 수 )=768 A(attention-block)=12 large: L=24 H=1024 A=16 input representation word별 embedding vector가 아닌 좀 더 잘게 쪼갠 subword단위 wordPiece embedding(30000) learned positional embedding -&gt; 단어의 위치 정보 [CLS] [SEP] segment embedding ‘he’는 6번쨰 단어이지만 ,2번째 문장의 첫번째 단어 GPT vs BERT GPT : Masked( 다음 단어를 예측하는것이 task이기 때문에 다음단어 접근 불가) ,BERT: Masked단어를 포함하여 모든 단어 접근 가능 GPT; 800M words, batch size-32000 learning-rate동일 BERT: 2500M words, [CLS] [SEP], segment embedding, batch-size-128000 , learning-rate-optimization FIne tunning process Machine Reading Comprehension, Question Answering 기계 독해 기반 질의응답 SQuAD1.1 정답 문구의 위치 SQuAD2.0 답이 없는 경우 [CLS] 을 활용해서 binary classification -&gt; no answer(cross entropy loss) On Swag 다수 문장을 다룰 때 다음에 나타날법한 적절한 문장 매번 서로 다른 문장을 concat해서 [CLS]토큰을 output layer를 통과하여 각기 얻은 scalar값을 softmax 모델이 끊임 없이 좋아짐 layer를 깊게 쌓고 parameter를 늘릴 수록 계속 좋아짐 not asymptoted (점근적이지 않다) Advance Self-superviesd pre-training modelsGPT-2 pre-training-task: language modelling 40GB dataset is good quality Language model can perform down-stream tasks in zero-shot setting- without any parameter or architecture modification motivation multitasking learning as question answering 모든 자연어처리 task가 질의응답으로 바뀔 수 있다. Dataset Reddit- 외부 링크도 포함(좋아요3개이상) preprocess bpe model layer normalization layer가 위로 갈수록 선형변환 값들이 0에 수렴 위쪽 layer의 역할이 줄어듬 Question Answering conversation question answering dataset (CoQA) 55 F1 score Fine tuned bert achieved 89 F1 Summarization fine tune없이 zero shot으로 inference TL;RT Too long didnt read Translation GPT-3 parameter수를 많이, 큰 batch-size, 많은 data ALBERT 장애물 memory limitation training speed A Lite BERT Factorized Embedding parameterization 기존의 BERT에서 Embedding vector 사이즈는 hidden vector size 와 같아야 했다 Cross-layer Parameter Sharing Shared-FFN Shared-attention- $W_q ,W_k, W_v$ All-shared 성능 차이 별로 없다 Sentence Order Prediction Next sentence Prediction -&gt;BERT에서 실효성이 없음-&gt;masked language modelling만 연속적인 두 문장의 순서를 예측 두 독립적인 문장을 가져와 선후관계를 파악하는 것이 아니라, 항상 연속적인 두 문장을 가져온다. 정오더 or 역오더 이를 negative sample이라고 하는데, 인접 문장이므로 순서와 관계없이 비슷한 단어가 당연히 많이 등장한다. ELECTRAefficiently learning an encoder that classifies token replacements accurately 마스킹된 단어를 복원해주는 모델-Generator를 하나 두고, 또 Generator가 복원한 단어들을 받아 이 단어가 원본인지 또는 generator에 의해 복원된 단어인지를 예측하는 모델-Discriminator를 둔다. Generator ,Discriminator (GAN아이디어) pre-trained Discriminator을 사용 Light-weight Models DistillBERT teacher model , student model TinyBERT Teacher model의 parameter, 중간결과물까지 닮도록 학습 MSE Loss teacher model과 student model의 차원이 다르면 적용하기 어려울 수 있음 FCN을 하나 더 둔다 Fusing Knowledge Graph into language Model 주어진 문장에서 문맥, 단어들간 유사도는 잘 파악하나 문장에 포함되지 않은 추가적인 정보는 활용 못함 ex) 꽃을 심기 위해 땅을 판다. 집을 짓기 위해 땅을 판다. 땅을 파기 위한 도구는 문장에 나타나지 않음 외부지식(Knowledge graph)을 통해 학습 땅-파다-도구 ex)삽, 포크레인 Further Question BERT의 Masked Language Model의 단점은 무엇이 있을까요? 사람이 실제로 언어를 배우는 방식과의 차이를 생각해보며 떠올려봅시다","link":"/2021/02/22/BoostCamp/Day20/"},{"title":"Day23","text":"군집 구조와 군집 탐색 문제 군집(Community)이란 다음 조건들을 만족하는 정점들의 집합 집합에 속하는 정점 사이에는 많은 간선이 존재 집합에 속하는 정점과 그렇지 않은 정점 사이에는 적은 수의 간선이 존재 실제 그래프에서의 군집들 온라인 소셜 네트워크의 군집들은 사회적 무리(Social Circle)을 의미하는 경우가 많다 온라인 소셜 네트워크의 군집들이 부정 행위와 관련된 경우도 많다. 조직 내의 분란이 소셜 네트워크 상의 군집으로 표현된 경우도 있다 키워드 – 광고주 그래프에서는 동일한 주제의 키워드들이 군집을 형성합니다 뉴런간 연결 그래프에서는 군집들이 뇌의 기능적 구성 단위를 의미합니다 군집 탐색 문제 그래프를 여러 군집으로 ‘잘’ 나누는 문제를 군집 탐색(Community Detection) 문제라고 합니다 보통은 각 정점이 한 개의 군집에 속하도록 군집을 나눕니다 비지도 기계학습 문제인 클러스터링(Clustering)과 상당히 유사합니다 클러스터링 : 피쳐들의 벡터형태로 표현된 인스턴스들을 그룹으로 묶음 군집탐색문제 : 정점들을 그룹으로 묶음 군집 구조의 통계적 유의성과 군집성 비교 대상: 배치 모형 성공적인 군집탐색은 비교를 통해 정의 , 그 비교의 대상이 되는 것이 배치모형(Configuration Model)이다. 군집성의 정의 군집 탐색의 성공 여부를 판단 하기 위해서, 군집성(Modularity)가 사용됩니다 기댓값을 사용하는 이유는 배치모형이 무작위성을 포함하고 있기 때문 차이가 클수록 그래프에서 군집s내부 간선의 수가 많음을 의미-&gt;군집의 성질을 잘 만족함 -1&lt;=군집성&lt;=1 즉, 군집성은 무작위로 연결된 배치 모형과의 비교를 통해 통계적 유의성을 판단합니다 군집성은 항상 –1과 +1 사이의 값을 갖습니다 보통 군집성이 0.3 ~ 0.7 정도의 값을 가질 때, 그래프에 존재하는 통계적으로 유의미한 군집들을 찾아냈다고 할 수 있습니다 군집 탐색 알고리즘 Girvan-Newman 알고리즘 하향식(Top-Down) 군집 탐색 알고리즘입니다 전체 그래프에서 탐색을 시작합니다 군집들이 서로 분리되록, 간선을 순차적으로 제거합니다 어떤 간선을 제거해야 군집들이 분리될까요? 바로 서로 다른 군집을 연결하는 다리(Bridge) 역할의 간선입니다 서로 다른 군집을 연결하는 다리 역할의 간선을 어떻게 찾아낼 수 있을까요? 간선의 매개 중심성(Betweenness Centrality)을 사용합니다 이는 해당 간선이 정점 간의 최단 경로에 놓이는 횟수를 의미합니다 매개 중심성을 통해 서로 다른 군집을 연결하는 다리 역할의 간선을 찾아낼 수 있습니다 Girvan-Newman 알고리즘은 매개 중심성이 높은 간선을 순차적으로 제거합니다 간선이 모두 제거될 때까지 반복합니다 간선을 어느 정도 제거하는 것이 가장 적합할까요? 앞서 정의한 군집성을 그 기준으로 삼습니다 즉, 군집성이 최대가 되는 지점까지 간선을 제거합니다 정리 전체 그래프에서 시작합니다 매개 중심성이 높은 순서로 간선을 제거하면서, 군집성을 변화를 기록합니다 군집성이 가장 커지는 상황을 복원합니다 이 때, 서로 연결된 정점들, 즉 연결 요소를 하나의 군집으로 간주합니다 즉, 전체 그래프에서 시작해서 점점 작은 단위를 검색하는 하향식(Top-Down) 방법입니다 Louvain 알고리즘 상향식(Bottom-Up) 군집 탐색 알고리즘입니다 각 정점이 하나의 군집을 형성한다고 가정한 상태에서 시작 그러면 어떤 기준으로 군집을 합쳐야 할까요? 군집성 과정 Louvain 알고리즘은 개별 정점으로 구성된 크기 1의 군집들로부터 시작합니다 각 정점 𝑢를 기존 혹은 새로운 군집으로 이동합니다 이 때, 군집성이 최대화되도록 군집을 결정합니다 더 이상 군집성이 증가하지 않을 때까지 2)를 반복합니다 각 군집을 하나의 정점으로하는 군집 레벨의 그래프를 얻은 뒤 3)을 수행합니다 한 개의 정점이 남을 때까지 4)를 반복합니다 중첩이 있는 군집 탐색 중첩이 있는 군집 구조 실제 그래프의 군집들을 중첩되어 있는 경우가 많습니다 예를 들어 소셜 네트워크에서의 개인은 여러 사회적 역할을 수행합니다 그 결과 여러 군집에 속하게 됩니다 앞서 배운 Girvan-Newman 알고리즘, Louvain 알고리즘은 군집 간의 중첩이 없다고 가정합니다 그러면 중첩이 있는 군집은 어떻게 찾아낼 수 있을까요? 이를 위해 아래와 같은 중첩 군집 모형을 가정합니다 각 정점은 여러 개의 군집에 속할 수 있습니다 각 군집 𝐴에 대하여, 같은 군집에 속하는 두 정점은 𝑃𝐴 확률로 간선으로 직접 연결됩니다 두 정점이 여러 군집에 동시에 속할 경우 간선 연결 확률은 독립적입니다 예를 들어, 두 정점이 군집 𝐴와 𝐵에 동시에 속할 경우 두 정점이 간선으로 직접 연결될 확률은 1 − (1 − 𝑃𝐴)(1 − 𝑃𝐵)입니다 어느 군집에도 함께 속하지 않는 두 정점은 낮은 확률 𝜖으로 직접 연결됩니다 중첩 군집 모형이 주어지면, 주어진 그래프의 확률을 계산할 수 있습니다 그래프의 확률은 다음 확률들의 곱입니다 그래프의 각 간선의 두 정점이 (모형에 의해) 직접 연결될 확률 그래프에서 직접 연결되지 않은 각 정점 쌍이 (모형에 의해) 직접 연결되지 않을 확률 현실의 많은 경우 그래프는 주어져 있지만 중첩군집모형은 주어지지 않는 경우가 많음 따라서 중첩 군집 탐색은 주어진 그래프의 확률을 최대화하는 중첩 군집 모형을 찾는 과정입니다 -&gt;최대우도추정치 중첩 군집 탐색을 용이하게 하기 위하여 완화된 중첩 군집 모형을 사용합니다 완화된 중첩 군집 모형에서는 각 정점이 각 군집에 속해 있는 정도를 실숫값으로 표현합니다 즉, 기존 모형에서는 각 정점이 각 군집에 속하거나 속하지 않거나 둘 중 하나였는데, 중간 상태를 표현할 수 있게 된 것입니다 최적화 관점에서는, 모형의 매개변수들이 실수 값을 가지기 때문에 익숙한 최적화 도구 (경사하강법 등)을 사용하여 모형을 탐색할 수 있다는 장점이 있습니다 우리 주변의 추천 시스템 추천 시스템과 그래프 사용자 각각이 구매할 만한 혹은 선호할 만한 상품을 추천합니다 구매 기록이라는 암시적(Implicit)인 선호만 있는 경우도 있고, 평점이라는 명시적(Explicit)인 선호가 있는 경우도 있습니다 그래프 관점에서 추천 시스템은 “미래의 간선을 예측하는 문제” 혹은 “누락된 간선의 가중치를 추정하는 문제”로 해석할 수 있습니다 내용 기반 추천시스템 내용 기반 추천시스템의 원리 내용 기반(Content-based) 추천은 각 사용자가 구매/만족했던 상품(부가정보)과 유사한 것을 추천하는 방법입니다 마지막 단계는 사용자에게 상품을 추천하는 단계입니다 코사인 유사도가 높은 상품들을 추천합니다 내용 기반 추천시스템은 다음 장점을 갖습니다 다른 사용자의 구매 기록이 필요하지 않습니다-&gt; 본인의 기록만 독특한 취향의 사용자에게도 추천이 가능합니다 새 상품에 대해서도 추천이 가능합니다-&gt;상품 프로필 추천의 이유를 제공할 수 있습니다 내용 기반 추천시스템은 다음 단점을 갖습니다 상품에 대한 부가 정보가 없는 경우에는 사용할 수 없습니다 구매 기록이 없는 사용자에게는 사용할 수 없습니다-&gt;사용자 프로필x 과적합(Overfitting)으로 지나치게 협소한 추천을 할 위험이 있습니다 협업 필터링 추천시스템​ ​ 협업 필터링의 원리 사용자-사용자 협업 필터링은 다음 세 단계로 이루어집니다 사용자-사용자 협업 필터링의 핵심은 유사한 취향의 사용자를 찾는 것입니다 그런데 취향의 유사도는 어떻게 계산할까요? 취향의 유사성은 상관 계수(Correlation Coefficient)를 통해 측정합니다 마지막 단계는 추정한 평점이 가장 높은 상품을 추천하는 단계입니다 추천의 대상 사용자를 𝑥라고 합시다 앞서 설명한 방법을 통해, 𝑥가 아직 구매하지 않은 상품 각각에 대해 평점을 추정합니다 추정한 평점이 가장 높은 상품들을 𝑥에게 추천합니다 협업 필터링은 다음 장점과 단점 갖습니다 (+) 상품에 대한 부가 정보가 없는 경우에도 사용할 수 있습니다 (−) 충분한 수의 평점 데이터가 누적되어야 효과적입니다 (−) 새 상품, 새로운 사용자에 대한 추천이 불가능합니다 (−) 독특한 취향의 사용자에게 추천이 어렵습니다 추천 시스템의 평가 데이터 분리","link":"/2021/02/25/BoostCamp/Day23/"},{"title":"Day25","text":"정점 표현 학습 복습 정점 표현 학습이란 그래프의 정점들을 벡터의 형태로 표현하는 것 정점 임베딩(Node Embedding) 그래프에서의 정점간 유사도를 임베딩 공간에서도 “보존”하는 것 그래프에서 두 정점의 유사도는 어떻게 정의할까 지금까지 소개한 정점 임베딩 방법들을 변환식(Transductive) 방법 출력으로 임베딩 자체를 얻는 변환식 임베딩 방법은 여러 한계를 갖습니다 학습이 진행된 이후에 추가된 정점에 대해서는 임베딩을 얻을 수 없습니다 모든 정점에 대한 임베딩을 미리 계산하여 저장해두어야 합니다 정점이 속성(Attribute) 정보를 가진 경우에 이를 활용할 수 없습니다 출력으로 인코더를 얻는 귀납식 임베딩 방법은 여러 장점을 갖습니다 학습이 진행된 이후에 추가된 정점에 대해서도 임베딩을 얻을 수 있습니다 모든 정점에 대한 임베딩을 미리 계산하여 저장해둘 필요가 없습니다 정점이 속성(Attribute) 정보를 가진 경우에 이를 활용할 수 있습니다 그래프 신경망 기본그래프 신경망 구조 그래프 신경망은 그래프와 정점의 속성 정보를 입력으로 받습니다 정점의 속성의 예시는 다음과 같습니다 온라인 소셜 네트워크에서 사용자의 지역, 성별, 연령, 프로필 사진 등 논문 인용 그래프에서 논문에 사용된 키워드에 대한 원-핫 벡터 PageRank 등의 정점 중심성, 군집 계수(Clustering Coefficient) 등 그래프 신경망은 이웃 정점들의 정보를 집계하는 과정을 반복하여 임베딩을 얻습니다 각 집계 단계를 층(Layer)이라고 부르고, 각 층마다 임베딩을 얻습니다 그래프 신경망 구조 대상 정점 마다 집계되는 정보가 상이합니다 대상 정점 별 집계되는 구조를 계산 그래프(Computation Graph)라고 부릅니다 서로 다른 대상 정점간에도 층 별 집계 함수는 공유합니다 서로 다른 구조의 계산 그래프를 처리하기 위해서는 어떤 형태의 집계 함수가 필요할까요? 집계 함수는 (1) 이웃들 정보의 평균을 계산하고 (2) 신경망에 적용하는 단계를 거칩니다 마지막 층에서의 정점 별 임베딩이 해당 정점의 출력 임베딩입니다 그래프 신경망의 학습 그래프 신경망의 학습 변수(Trainable Parameter)는 층 별 신경망의 가중치입니다 먼저 손실함수를 결정합니다. 정점간 거리를 “보존”하는 것을 목표로 할 수 있습니다 (그래프 신경망은 비지도 학습, 지도 학습이 모두 가능합니다) 비지도 학습에서는 정점간 거리를 “보존”하는 것을 목표로 합니다 지도 학습에서는 후속 과제의 손실함수를 이용해 종단종 학습을 합니다 후속 과제(Downstream Task)의 손실함수를 이용한 종단종(End-to-End) 학습도 가능합니다 임베딩이 그래프의 유사도를 보존하는지 여부는 관심이 아니고 분류기의 정확도를 높이는 것이 목표 그래프 신경망과 변환적 정점 임베딩을 이용한 정점 분류 손실함수를 정의한 후 학습에 사용할 대상 정점을 결정하여 학습 데이터를 구성합니다 마지막으로 오차역전파(Backpropagation)을 통해 손실함수를 최소화합니다 그래프 신경망의 활용 학습된 신경망을 적용하여, 학습에 사용되지 않은 정점의 임베딩을 얻을 수 있습니다 마찬가지로, 학습 이후에 추가된 정점의 임베딩도 얻을 수 있습니다 학습된 그래프 신경망을, 새로운 그래프에 적용할 수도 있습니다 그래프 신경망 변형그래프 합성곱 신경망 소개한 것 이외에도 다양한 형태의 집계 함수를 사용할 수 있습니다 GraphSAGE GraphSAGE의 집계 함수입니다 합성곱 신경망과의 비교합성곱 신경망과 그래프 신경망의 유사성 합성곱 신경망과 그래프 신경망은 모두 이웃의 정보를 집계하는 과정을 반복합니다 합성곱 신경망에서는 이웃의 수가 균일하지만, 그래프 신경망에서는 아닙니다 그래프의 인접 행렬에 합성곱 신경망을 적용하면 효과적일까요? 그래프에는 합성곱 신경망이 아닌 그래프 신경망을 적용하여야 합니다! 많은 분들이 흔히 범하는 실수입니다 합성곱 신경망이 주로 쓰이는 이미지에서는 인접 픽셀이 유용한 정보를 담고 있을 가능성이 높습니다 하지만, 그래프의 인접 행렬에서의 인접 원소는 제한된 정보를 가집니다 특히나, 인접 행렬의 행과 열의 순서는 임의로 결정되는 경우가 많습니다 그래프 신경망에서의 어텐션기본 그래프 신경망의 한계 기본 그래프 신경망에서는 이웃들의 정보를 동일한 가중치로 평균을 냅니다 그래프 합성곱 신경망에서 역시 단순히 연결성을 고려한 가중치로 평균을 냅니다 그래프 어텐션 신경망(Graph Attention Network, GAT)에서는 가중치 자체도 학습합니다 각 층에서 정점 𝑖로부터 이웃 𝑗로의 가중치 𝜶𝒊𝒋는 세 단계를 통해 계산합니다 여러 개의 어텐션을 동시에 학습한 뒤, 결과를 연결하여 사용할 수 있다 그래프 표현 학습과 그래프 풀링그래프 표현 학습 그래프 표현 학습, 혹은 그래프 임베딩이란 정점이 아닌 그래프 전체를 벡터의 형태로 표현하는 것입니다 개별 정점을 벡터의 형태로 표현하는 정점 표현 학습과 구분됩니다 그래프 임베딩은 벡터의 형태로 표현된 그래프 자체를 의미하기도 합니다 그래프 임베딩은 그래프 분류 등에 활용됩니다 그래프 형태로 표현된 화합물의 분자 구조로부터 특성을 예측하는 것이 한가지 예시입니다 그래프 풀링 그래프 풀링(Graph Pooling)이란 정점 임베딩들로부터 그래프 임베딩(그래프 전체를 표현하는 벡터)을 얻는 과정입니다 평균 등 단순한 방법보다 그래프의 구조를 고려한 방법을 사용할 경우 그래프 분류 등의 후속 과제에서 더 높은 성능을 얻는 것으로 알려져 있습니다 미분 가능한 풀링은 그래프 신경망의 여러곳에서 사용 가능 개별정점의 임베딩을 얻는데 군집을 찾는데 군집을 합산하는데 지나친 획일화 문제지나친 획일화 문제 지나친 획일화(Over-smoothing) 문제란 그래프 신경망의 층의 수가 증가하면서 정점의 임베딩이 서로 유사해지는 현상을 의미합니다 수 많은 정점들로부터 정보를 합산하기 떄문에 그래프의 전반을 집계하는 효과가 있다 지나친 획일화의 결과로 그래프 신경망의 층의 수를 늘렸을 때, 후속 과제에서의 정확도가 감소하는 현상이 발견되었습니다 지나친 획일화 문제에 대한 대응 획일화 문제에 대한 대응으로 JK 네트워크(Jumping Knowledge Network)는 마지막 층의 임베딩 뿐 아니라, 모든 층의 임베딩을 함께 사용합니다 그래프 데이터의 증강그래프 데이터 증강 데이터 증강(Data Augmentation)은 다양한 기계학습 문제에서 효과적입니다 그래프 데이터 증강의 결과 정점 분류의 정확도가 개선되는 것을 확인했습니다","link":"/2021/03/02/BoostCamp/Day25/"},{"title":"Day28","text":"캐글 경진대회 노하우 자신만의 파이프라인 구축 notebooks탭 참고 stratified k fold Full stack ML Engineer","link":"/2021/03/03/BoostCamp/Day28/"},{"title":"Day31","text":"Course overviewWhat is computer vision? 시각적 데이터에서 representation을 추출하는 일을 Inverse Rendering이라고 한다 representation을 통해 장면에 해당하는 이미지나 3D 모델을 재구현하는것을 Computer Graphics, 또는 렌더링(Rendering)이라고 한다. How to implement? 머신러닝: feature를 사용자가 직접 지정해주는 작업 필요 =&gt; 딥러닝의 경사하강법을 통한 feature extraction과 대조 딥러닝: 이미지를 입력받아 내부적으로 추상적인 변수를 추출(feature extraction) 정답을 예측하는 과정에서 feature를 update What you will learn in this course Image classificationWhat is classification An ideal approach for image recognition 가장 이상적인 classifier는 세상에 존재하는 모든 이미지 데이터를 “유사한” 이미지끼리 모아서KNN(K-Nearest Neighbors) 을 적용하는 것이다. 영상간 유사도를 정의하는 것도 쉬운일이 아님 NN vs CNN NN의 가장 큰 문제점은 이미지 전체의 패턴에 대해 학습했기 때문에, 가령 반쯤 잘리거나 학습된 이미지의 패턴과는 전혀 다른 이미지가 주어진다면 올바른 결과를 내지 못하는 것에 있다. 또한 이미지의 크기가 커진다면 학습해야할 파라미터의 수가 증가한다 CNN 은 Fully-connected layer가 아닌 Locally-connected layer 를 통해 local feature들을 학습하게 하고, 파라미터를 공유(shared parameter) 함으로써 학습해야 할 파라미터의 수를 줄일수 있도록 디자인 하였다. CNN architectures for image classification1AlexNet 2012년 ILSVRC에서 1위를 차지한 모델 합성곱 연산과 풀링 연산이 반복되는 구조 합성곱 필터 크기/stride: 11×11, 5×5, 3×3 / 1 이전의 LeNet보다 크기가 큰 이미지를 입력받아, 더 큰 필터를 사용 풀링 필터 크기/stride: 2 × 2 / 2 7개의 레이어, 605K개의 노드, 60M개의 파라미터 1.2M개의 학습 데이터를 활용 ReLU, Dropout 활용 명암을 normalization 지금은 사용 안함 대신 batch normalization 사용 Receptive field 입력된 이미지 일부가 합성곱/풀링 과정을 거쳐 한 픽셀로 맵핑되었을 떄, 일부 입력의 크기를 의미 즉, 각 필터가 입력 이미지의 어느 부분만큼 인식하는 지를 의미 VGG 깊은 레이어 no local response normalization only 3x3 filter, 2x2 max pool 커널 사이즈가 커지면 receptive field 가 커지고, 그만큼 많은 영역의 정보를 파악할 수 있다. 반면 학습해야하는 parameter의 수가 커지는 문제점이 있다 5x5 receptive field 는 두개의 3x3 커널을 이용하는 것 과 같으면서 parameter의 수는 줄어든다 better performance better generalization 다른 task적용 작은 커널 사이즈로도 깊게 쌓으면 큰 receptive field를 얻을 수 있다-&gt; 이미지 많은 부븐을 고려 할 수 있다 Data augmentationLearning representation of dataset Dataset is (almost) always biased Images taken by camera(trainingdata)≠ realdata 양질의 이미지를 얻기는 어렵고 고비용 =&gt; 기존의 이미지를 변형하여 학습 데이터로 활용 Augmenting data to fill more space and to close the gap 어떤 aug사용? 많은 augmentation 기법이 존재하지만 최적의 기법을 찾는것은 어렵다. 또한 한번의 augmentation이 아닌 일련의 augmentation(Policy) 을 수행할 필요도 있다. RandAugment는 자동으로 최적의 policy를 찾아 어느정도의 강도로 적용할지 찾는 것을 목표로 한다. Leveraging pre-trained informationTransfer learning The high-quality dataset is expensive and hard to obtain Knowledge learned from one dataset can be applied to other datasets! Pre-trained model에서 기존의 FC layer를 target task에 맞는 FC layer를 적용하여 pretrained model의 convolution layer 들의 가중치는 freeze 하고 FC layer의 가중치만 학습을 하는 방법이다. 따라서 학습데이터셋이 적더라도 적은 파라미터만 학습 시키기 때문에 효율적으로 학습시킬 수 있다. pretrained model 의 convolution layer도 같이 학습하게 하는데, convolution layer 의 learning rate 는 낮게 / target task를 위한 FC layer 는 높게 학습 하도록 하여 target task 에 빠르게 적응하도록 한다. 따라서 위의 방법보단 더 많은 파라미터를 학습시키기 때문에 조금 더 많은 데이터셋이 필요할 수 있다. Knowledge distillation pretrained model(Teacher Model) 의 학습된 지식을 더 작은 model(Student Model)로 지식을 전달하여 모델을 압축하는 방법이다.KL-divergence loss 를 통해 teacher model의 output distribution과 student model 의 output distribution 이 유사해지도록 학습을 한다. 이때, student model의 데이터셋이 없다면 unsupervised-learning 으로 진행되어 student model 만을 업데이트하게 된다 teacher model의 출력 label(예측)을 ground truth 레이블인 것 처럼 소형 모델에게 학습시키는 pseudo-labeling 방식으로도 사용되고 있다. 레이블을 활용하지 않는 경우 Student 모델이 Teacher 모델의 Inference와 가까워지도록 학습 KL-div 레이블을 활용할 경우 Teacher 모델의 Inference와 Ground Truth를 모두 참고하여 학습. 즉, Teacher 모델을 모사함과 동시에 정확성을 높이는 셈 Teacher 모델의 Inference와의 괴리와 Ground Truth와의 괴리를 가중합한 Loss를 바탕으로 역전파, Student 모델을 업데이트 softmax with temperature T(Soft Prediction)의 경우 출력의 값을 smooth 하게 만들어주는 기능 을 한다 Leveraging unlabeled dataset for training일반적으로 많은 데이터들은 unlabeled data 이며 labeled data 는 극히 일부분이다. 그렇다면 unlabeled data를 활용하여 학습할 수 있는 방법은 없을까? Semi-supervised learning labeled data를 활용하여 학습된 pretrained model 로 unlabeled data를 예측하여 pseudo-labeled data를 생성하고 labeled data 와 pseudo-labeled data를 활용하여 pretrained model 또는 새로운 model을 재학습한다. Self-training Augmentation + Teacher-Student Network + Semi-supervised Learning 사전학습된 Teacher Model을 통해 Pseudo Labeling을 진행, 사용 가능한 모든 데이터를 통해 Student Model을 학습 Knowledge Distillation의 학습 방식과 같이, Ground Truth와 Teacher Model의 Inference를 모두 고려하여 학습 Student 모델이 Teacher Model의 성능을 넘을 경우, 해당 모델을 Teacher Model로 대체. 다시 위 과정을 반복 student model이 계속 커짐","link":"/2021/03/09/BoostCamp/Day31/"},{"title":"Day24","text":"정점 표현 학습정점 표현 학습이란 정점 표현 학습이란 그래프의 정점들을 벡터의 형태로 표현하는 것입니다 정점 표현 학습은 간단히 정점 임베딩(Node Embedding)이라고도 부릅니다 정점 임베딩은 벡터 형태의 표현 그 자체를 의미하기도 합니다 정점이 표현되는 벡터 공간을 임베딩 공간이라고 부릅시다 정점 표현 학습의 이유 정점 임베딩의 결과로, 벡터 형태의 데이터를 위한 도구들을 그래프에도 적용할 수 있습니다 분류기(로지스틱 회귀분석, 다층 퍼셉트론 등) 그리고 군집 분석 알고리즘(K-Means, DBSCAN 등)은 벡터 형태로 표현된 사례(Instance)들을 입력으로 받습니다 정점 분류(Node Classification), 군집 분석(Community Detection) 등에 활용 정점 표현 학습의 목표 어떤 기준으로 정점을 벡터로 변환해야할까요? 그래프에서의 정점간 유사도를 임베딩 공간에서도 “보존”하는 것을 목표로 합니다 임베딩 공간에서의 유사도로는 내적(Inner Product)를 사용합니다 먼저 인접성을 바탕으로 한 접근법 인접성 기반 접근법인접성 기반 접근법 인접성(Adjacency) 기반 접근법에서는 두 정점이 인접할 때 유사하다고 간주합니다 두 정점 𝑢와 𝑣가 인접하다는 것은 둘을 직접 연결하는 간선 (𝑢, 𝑣)가 있음을 의미합니다 인접성 기반 접근법의 손실 함수 인접성만으로 유사도를 판단하는 것은 한계가 있습니다 빨간색 정점과 파란색 정점은 거리가 3인 반면 초록색 정점과 파란색 정점은 거리가 2입니다 인접성만을 고려할 경우 이러한 사실에 대한 고려 없이, 두 경우의 유사도는 0으로 같습니다 군집 관점에서는 빨간색 정점과 파란색 정점은 다른 군집에 속하는 반면 초록색 정점과 파란색 정점은 같은 군집에 속합니다 거리/경로/중첩 기반 접근법거리 기반 접근법 거리 기반 접근법에서는 두 정점 사이의 거리가 충분히 가까운 경우 유사하다고 간주합니다 경로 기반 접근법 경로 기반 접근법에서는 두 정점 사이의 경로가 많을 수록 유사하다고 간주합니다 복습 1 4 6 8 중첩 기반 접근법 중첩 기반 접근법에서는 두 정점이 많은 이웃을 공유할 수록 유사하다고 간주합니다 공통 이웃 수 대신 자카드 유사도 혹은 Adamic Adar 점수를 사용할 수도 있습니다 $N_u=N_v$일때 즉,두 정점의 이웃들의 집합이 같을 떄 자카드 유사도 1 W(u와v의 공통이웃)의 연결성이 클수록 가중치 낮다 why? u와v가 트와이스를 팔로우한다고 서로 가까운 것은 아님-&gt;낮은 가중치 임의 보행 기반 접근법임의보행 기반 접근법 임의보행 기반 접근법에서는 한 정점에서 시작하여 임의보행을 할 때 다른 정점에 도달할 확률 을 유사도로 간주합니다 임의보행이란 현재 정점의 이웃 중 하나를 균일한 확률로 선택하는 이동하는 과정을 반복하는 것을 의미합니다 임의보행을 사용할 경우 시작 정점 주변의 지역적 정보와 그래프 전역 정보를 모두 고려한다는 장점이 있습니다 기존의 거리,경로 기반 접근법은 거리를 k로 제한, 하지만 임의보행 접근법에서는 제한하지 않음, 그런 의미에서 그래프 전역정보 고려 어떻게 임베딩으로부터 도달 확률을 추정할까요? DeepWalk, Node2Vec 임의보행의 방법에 따라 DeepWalk와 Node2Vec이 구분됩니다 DeepWalk는 앞서 설명한 기본적인 임의보행을 사용합니다 즉, 현재 정점의 이웃 중 하나를 균일한 확률로 선택하는 이동하는 과정을 반복합니다 Node2Vec은 2차 치우친 임의보행(Second-order Biased Random Walk)을 사용합니다 현재 정점(예시에서 𝑣)과 직전에 머물렀던 정점(예시에서 𝑢)을 모두 고려하여 다음 정점을 선택합니다 직전 정점의 거리를 기준으로 경우를 구분하여 차등적인 확률을 부여합니다 Node2Vec에서는 부여하는 확률에 따라서 다른 종류의 임베딩을 얻습니다 - 손실 함수 근사 임의보행 기법의 손실함수는 계산에 정점의 수의 제곱에 비례하는 시간이 소요됩니다 따라서 많은 경우 근사식을 사용합니다 연결성에 비례하는 확률로 네거티브 샘플을 뽑으며, 네거티브 샘플이 많을 수록 학습이 더욱 안정적입니다 네거티브 샘플을 많이 뽑을 수록 학습이 안정적임 변환식 정점 표현 학습의 한계변환식 정점 표현 학습과 귀납식 정점 표현 학습 지금까지 소개한 정점 임베딩 방법들을 변환식(Transductive) 방법입니다 변환식(Transdctive) 방법은 학습의 결과로 정점의 임베딩 자체를 얻는다는 특성이 있습니다 정점을 임베딩으로 변화시키는 함수, 즉 인코더를 얻는 귀납식(Inductive) 방법과 대조됩 니다 변환식 임베딩 방법은 여러 한계를 갖습니다 학습이 진행된 이후에 추가된 정점에 대해서는 임베딩을 얻을 수 없습니다 ​ 입력그래프에 변화가 있는 경우 임베딩을 다시 수행 모든 정점에 대한 임베딩을 미리 계산하여 저장해두어야 합니다 정점이 속성(Attribute) 정보를 가진 경우에 이를 활용할 수 없습니다 귀납식 임베딩 방법-&gt; GNN 넷플릭스 챌린지 넷플릭스 챌린지의 목표는 추천시스템의 성능을 10%이상 향상시키는 것이었습니다 평균 제곱근 오차 0.9514을 0.8563까지 낮출 경우 100만불의 상금을 받는 조건이었습니다 잠재 인수 모형잠재 인수 모형 개요 잠재 인수 모형(Latent Factor Model)의 핵심은 사용자와 상품을 벡터로 표현하는 것입니다 uv decomposition SVD 수치적으로 표현하는 것은 쉬운 일이 아님 잠재 인수 모형에서는 고정된 인수 대신 효과적인 인수를 학습하는 것을 목표로 합니다 손실 함수 사용자와 상품을 임베딩하는 기준은 무엇인가요? 사용자와 상품의 임베딩의 내적(Inner Product)이 평점과 최대한 유사하도록 하는 것입니다 사용자 𝑥의 임베딩을 𝑝𝑥, 상품 𝑖의 임베딩을 𝑞𝑖라고 합시다 사용자 𝑥의 상품 𝑖에 대한 평점을 𝑟𝑥𝑖라고 합시다 임베딩의 목표는 𝑝𝑥 ⊺ 𝑞𝑖이 𝑟𝑥𝑖와 유사하도록 하는 것입니다 과적합을 방지하기 위하여 정규화 항을 손실 함수에 더해줍니다 임베딩이 너무 크면 훈련 데이터에 있는 잡음들까지 배울 수 있다 정규화의 세기가 클수록 모형 복잡도에 집중하여 최소화 최적화 손실함수를 최소화하는 𝑃와 𝑄를 찾기 위해서는 (확률적) 경사하강법을 사용합니다 고급 잠재 인수 모형사용자와 상품의 편향을 고려한 잠재 인수 모형 각 사용자의 편향은 해당 사용자의 평점 평균과 전체 평점 평균의 차입니다 각 상품의 편향은 해당 상품에 대한 평점 평균과 전체 평점 평균의 차입니다 개선된 잠재 인수 모형에서는 평점을 전체 평균, 사용자 편향, 상품 편향, 상호작용으로 분리합니다 개선된 잠재 인수 모형의 손실 함수는 아래와 같습니다 시간적 편향을 고려한 잠재 인수 모형 넷플릭스 시스템의 변화로 평균 평점이 크게 상승하는 사건이 있었습니다 영화의 평점은 출시일 이후 시간이 지남에 따라 상승하는 경향을 갖습니다 개선된 잠재 인수 모형에서는 이러한 시간적 편향을 고려합니다 넷플릭스 챌린지의 결과앙상블 학습 BellKor 팀은 앙상블 학습을 사용하여 처음으로 목표 성능에 도달하였습니다 BellKor 팀의 독주에 위기감을 느낀 다른 팀들은 연합팀 Ensemble을 만들었습니다 넷플릭스 챌린지 종료 시점에 BellKor 팀 Ensemble 팀의 오차는 정확히 동일했습니다 하지만 BellKor 팀의 제출이 20분 빨랐습니다. ​","link":"/2021/02/26/BoostCamp/Day24/"},{"title":"Day29","text":"언어 모델링내가 만든 AI 모델은 합법일까, 불법일까","link":"/2021/03/05/BoostCamp/Day29/"},{"title":"Day27","text":"서비스 향 AI 모델 개발 VS 수업/학교/연구 AI 모델 개발연구 관점에서 AI 개발이란? 보통 수업/학교/연구에서는 정해진 데이터셋/평가 방식에서 더 좋은 모델을 찾는 일을 한다 서비스 관점에서 AI 개발이란? 서비스 개발 시에는 학습 데이터셋도 없고, 테스트 데이터셋과 테스트 방법도 없다. 서비스 개발 시에는 서비스 요구 사항만이 있다. 그래서, 첫 번째로 해야 할 일은 학습 데이터셋을 준비하는 것이다. 정확히는 서비스 요구사항으로 부터 학습 데이터셋의 종류/수량/정답을 정해야 한다. 지금까지의 이야기를 종합하면, 다음과 같은 입출력을 갖는 기술 모듈을 개발해 달라는 요청 결국 학습 데이터 준비를 하려면 모델 파이프 라인 설계가 되어 있어야 한다! 그런데, 모델 파이프 라인 설계 하려면 어느 정도 데이터가 있어야 한다! 자! 본인이 학습 데이터셋 준비 담당자라고 해보고, 어떤 일을 겪게 되는지 살펴보자. 다시 한 번 정리해 보면… 테스트 데이터셋은 학습 데이터셋에서 일부 사용한다고 하고, (사실은 이것도 할 얘기가 많지만..) 서비스 요구사항으로부터 테스트 방법을 도출해야 한다. 테스트 방법에 대해 다음처럼 정리할 수 있다. 추가로, 모델에 관련한 요구사항을 도출해야 합니다. 서비스 향 AI 모델 개발 기술팀의 조직 구성 AI 기술팀에게는 서비스 요구사항이 오고, 이에 맞는 AI 모델을 개발해야 한다. 그런데, 기술팀에 AI 모델 Serving까지 요구되면 필요한 인력은 늘어난다. 마지막으로 모델을 실제 서빙하기 위한 추가 작업들이 end device에 맞춰 더 있다. AI쪽으로 커리어를 쌓고자 하시는 분들에게 드리고 싶은 말씀 개발자 ⇒ AI 관련 전환 AI 시대의 커리어 빌딩Careers in AI 학교를 가야하나요? 회사를 가야하나요? AI를 다루는 회사의 종류 AI를 다루는 팀의 구성 AI 팀에서 엔지니어가 되면 어떤 일을 할까요? 보통 논문 읽고 모델 학습하는 일을 떠올리는 분들이 많습니다만… 현실에서는 정말 다양한 역할이 있고 100% 하나의 포지션의 역할을 수행하는 경우는 드묾 How to start my AI engineering career Understand yourself","link":"/2021/03/03/BoostCamp/Day27/"},{"title":"Day30","text":"AI/ML 퀀트AI Ethics","link":"/2021/03/05/BoostCamp/Day30/"},{"title":"Day36","text":"연역적 (deductive) 결정 가설 증명을 통해 현상을 추론 “전제가 참이면, 결론도 참”이라는 논리로 결정 전제에 따라 결과가 바뀜 귀납적 (inductive) 결정 가설을 경험적 자료와 비교해 추론 높은 확률로 참, 낮은 확률로 거짓 머신러닝(결정기)도 이에 해당 결정기 결정기는 어떤 데이터를 가지고 최종 판단을 내리는 것을 말한다. 추천시스템과 같은 가벼운 의사결정부터 암 진단과 같은 무거운 결정까지 다양 딥러닝이 발전하기 전에는 모델의 성능이 좋지 않았기 때문에 가벼운 결정만 가능하였지만 발전 이후 정확도가 거의 100%에 가까워지면서 무거운 의사결정가지 가능 가벼운 결정기머신러닝(결정기)은 인간의 결정을 대신 해줌 서비스하기 위해 큰 데이터로 학습한 모델을 경량화해서 edge device에 탑재. 경량화: 필요한 것만 갖고 불필요한 것을 제거하여 규모를 줄이거나 가볍게 만드는 것 소형화: 필요/불필요한 것을 구분하지 않고 규모를 줄이거나 가볍게 만드는 것 무엇을 경량화? 모델이 가진 무의미한 정보량을 줄여서 경량화를 달성하는 것이 목표 무의미한 정보가 줄어들면, 정보의 밀도가 올라간다 모델 압축(Compression)과도 같다 어떻게 경량화? Pruning Quantization Knowledge Distillation Filter Decomposition 모델 경량화 과정 Edge device cloud service나 on-premise(자체 서버)를 했을 때에 엄청난 비용이 발생 사생활 문제와 항상 네트워크에 연결되어 있어야 한다는 문제 Low cost No privacy concerns Stand-alone Cloud intelligence, edge intelligence Edge intellignece는 Centralized intelligence와 비교 좌측은 중앙 서버의 과중이 심한 반면 우측의 Edge intelligence의 경우 비교적 중앙 서버가 과중이 심하지 않음 Edge intelligence에는 Edge Training, Edge Offloading, Edge Caching, Edge Inference 등이 있다. 우리가 많이 다루게 될 내용은 Edge Inference Edge Inference를 적용하기 위해서는 Pytorch로 모델을 만든 뒤 Edge device에서 사용할 수 있다 Edge Inferenced의 depth High level에서 사용하는 PyTorch나 Tensorflow 등으로 Model을 대부분 만들고 이것들이 Edge devices로 내려가기 위해서는 Low level IR로 Graph lowering OptimizerComputer Optimization 컴퓨터가 문제를 푸는 과정 모든 combination을 고려하기 전까지 최적해를 알 수 없음. 반대로, 유한한 모든 combination을 고려하면 무조건 최적해 보장 ML Optimazation 머신러닝이 문제를 푸는 과정 모든 상태를 고려하지 않고 현재 상태보다 낫게 업데이트해 최적화 Decision problem vs optimization problemDecision problem 조건을 만족한다면 문제를 푼 것. 하나의 결정. 무한한 자원으로 최고 성능을 내는 것. Decision Spanning Tree (DST) upper bound가 정해져 있고, 그 upper bound만 만족하면 풀리는 문제 Optimazation problem 더이상 못찾을 때까지 decision을 연쇄적으로 반복. 제약 조건을 만족하면서 최고의 성능을 내는 것 Minimum Spanning Tree(MST) Dicision problem을 연쇄적으로 반복했을 때 해결 Constraints무엇을 원하느냐에 따라 굉장히 달라짐(시간,돈…) Decision problem에서 무한한 자원 (infinite amount of resoources)을 사용한다고 가정 Optimization problem에서는 각각의 Decision problem에서 지불했던 Cost를 더해서 Constraints를 계산합니다. 이때, 모든 Cost를 더했을 때 Constraint를 넘으면 안된다","link":"/2021/03/16/BoostCamp/Day36/"},{"title":"Day37","text":"Space-Time Trade-off 공간(space)과 시간(time)은 서로 trade-off 관계에 있음. 압축되지 않은(uncompressed) 데이터를 저장한다면 더 많은 공간이 필요한 대신, 더 적은 시간이 걸림. 데이터를 압축(compressed)해 저장한다면 더 적은 공간이 필요한 대신, 더 많은 시간이 걸림. 공간(space)은 problem space(state space)와 search space(solution space)로 이루어져 있음. problem space는 문제를 해결하는 과정에 존재하는 모든 요소들의 공간이며, search space는 문제의 조건을 만족하는 요소들의 공간 search space: 모든 노드가 연결되어 있고, cycle이 존재하지 않은 그래프. 정답 후보. optimal solution: 그 중 1개(또는 일부)의 cost가 가장 작은 optimal solution. 정답. 시간과 공간의 제약 하에 주어진 문제(problem space)를 풀기 위해 제약 조건을 만족하는 집합(search space; feasible space) 중 가장 높은 performance를 내는 것을 찾음. Entropy 불확실성의 측정 정렬된 왼쪽 상태를 Low Entropy, 불규칙한 오른쪽 상태를 High Entropy 문제해결도 엔트로피(entropy) 관점에서 볼 수 있음. 문제를 푼다는 특정한 initial state에서 무질서한 problem solving 과정을 통해 엔트로피가 낮은 최적의 terminal state에 도달하는 것. Parameter search &amp; Hyper-parameter searchParameter Search 모델이 학습하며 가중치(weight)를 찾아감. class를 가장 잘 나누는 최적의 결정경계(decision boundary) 탐색. loss가 커지거나 작아지는 일종의 binary search 문제. 단, global minima 보장하지 않음. Hyperparameter Search 사람이 찾아주는 값. 한번의 hyperparameter 탐색에 cost가 너무 큼. 적은 cost를 보장하는 hyperparameter를 탐색 최적화 알고리즘 필요. Grid Search hyperparameter들의 후보를 골라 조합 탐색. 선택한 grid의 중간 단계는 탐색하지 않음. Random Search 범위 내의 랜덤한 값을 탐색. Bayesian Optimization Surrogate model(대리모델)을 만들어 학습해가며 최적의 hyperparameter 조합 탐색. Surrogate Model은 ML 모델을 정의하는 hyperparameter들을 위한 머신러닝 모델 반복연산으로 cost가 크고 모델의 hyperparameter도 찾아야 함. Surrogate의 대표적인 process가 Gaussian process 파란색 음영 ⇒ covariance 초록색 함수 ⇒ acquisition function 검정색 함숫값도 크고, 파란색 음영도 작은 부분을 찾겠다는 것. exploitation은 오른쪽 점 근처에 최적값이 존재할 것”이라고 예측 exploration은 표준편차가 가장 큰 점, 즉, 불확실성이 가장 높은 점 근처에 최적값이 존재하는 것이라고 예측 Mean과 Variance를 둘 다 고려해서 Acquisㅑtion max를 찾는다 Neural Architecture Search(NAS) 여러 모델들의 Architecture들을 알고리즘, 딥러닝 등의 모델에 넣어서 가장 좋은 성능의 Architecture를 찾아내는 방법 Search strategy 어디와 어디를 residual connection,fuse,depth-wise-seperate, 몇개의 layer.. grid search MnasNet PROXYLESSNAS ONCE-FOR-ALL 압축 (Compression) &amp; 압축률 (Compression rate) 압축은 손실 압축과 비손실 압축으로 나뉘는데, 손실 압축은 압축된 데이터를 복원할 때 손실이 일어나지만 더 높은 압축률을 가진다. Entropy 관점의 Encoding Cross-entropy 부분은 Q(i)라는 codebook의 입장에서 P(i)라는 message(정답 set)를 encoding 했을 때의 나오는 무질서도를 의미 Entropy 부분은 위에서 주황색 식 H(p)H(p), 즉, P(i)라는 message를 P(i)라는 codebook으로 encoding 했을 때를 무질서도를 의미 이때 entropy의 값은 0이 나오지는 않고, P(i) 분포가 기본적으로 가지고 있는 minimum entropy가 나옴 Cross-entropy에서 Entropy를 뺸다는 의미 압축 후의 모델 사이즈와 정확도 손실 측면에서 봤을 때, Pruning과 Quantization을 동시에 해주는 것이 좋은 결과를 낸다.","link":"/2021/03/18/BoostCamp/Day37/"},{"title":"Day38","text":"Acceleration 대기시간(Latency)은 요청한 데이터가 도달할 때까지 걸리는 시간이다. 대역폭(Bandwidth)은 단위시간 동안 전달할 수 있는 데이터의 최대치이다. 처리량(Throughput)은 단위시간 동안 실제로 전달되는 데이터의 양으로, 병렬 처리(Parallel processing)은 처리량을 늘리기 위한 것이다. GPU를 사용하는 이유, 병렬 처리가 가능한 라이브러리를 사용하는 이유, 모두 가속화와 밀접한 관련이 있다. Hardware acceleration SoC(System on Chip)는 CPU, GPU 등 다양한 시스템의 구성요소를 칩 하나에 집약한 것으로, 이를 사용하는 대표적인 제품에는 Apple의 M1이 있다. FPGA(Field-programmable gate array)는 사용자가 원하는 용도에 따라 내부 회로를 코딩해서 바꿔 사용할 수 있는 칩이다. 공간 복잡도와 관련있는 압축은 소프트웨어에서 해결하고, 시간 복잡도와 관련있는 가속은 하드웨어에서 해결Deep learning compiler 딥러닝 모델을 특정 디바이스에서 효율적으로 동작시키기 위해서는 해당 디바이스에 최적화된 코드가 필요하다. 이러한 작업을 자동으로 지원해주는 도구가 바로 DL compiler LLVM 원래는 ‘언어의 종류 x 아키텍처의 종류’만큼 복수의 컴파일러가 필요하다 LLVM IR을 사용하면 Frontend에서 어떤 언어가 들어오던 원하는 architecture로 변환해 MLIR MLIR은 LLVM의 Machine Learning 버전 MLIR에서는 중간에 있는 compiler들을 조립 후 통합해서 “통합 Framework”를 사용할 수 있게 만들었다. DL complier에 적용하는 Hardware-specific optimizations Hardware Intrinsic Mapping Memory Allocation &amp; Fetching Memory Latency Hiding Loop Oriented Optimization Techniques Parallelization Pruning Pruning이란 중요하지 않고 반복되는 부분을 잘라내는 것을 뜻한다. 이를 통해 정보의 손실은 일어나겠지만, 모델의 복잡도를 줄여 일반화 성능을 높이고 속도를 높이는 효과를 낸다. 딥러닝에서는 Pruning을 통해 중요하지 않은 것(weight이 0에 가까운 것)을 줄인다. Pruning과 Dropout은 비슷해보이지만, Pruning은 Dropout과 달리 버린 부분을 되살릴 수 없다. 또한 Dropout은 학습 시 사용하는 뉴런의 조합의 바꿔서 앙상블 효과를 낼 뿐 테스트를 할 때는 모든 뉴런을 전부 사용한다. L1, L2 regularization 모델 과적합을 방지하기 위한 방법 중 하나도 weight regularization이 있다. loss function 에 weight L1 norm, L2 norm 항을 추가한 것을 각각 L1, L2 regulation 이라 칭한다. pruning 비율에 따른 accuracy 감소 비율 pruning 후 retrain 할 때 weight regularization 항을 추가하여 과적합(파란점)을 방지(빨간점)한다. pruning 하면 parameter 수가 감소하고, accuracy도 낮아진다. 동일 accuracy를 보일 경우 속도는 느려진다. (tradeoff) Pruning category Unstructured Pruning : weight를 아무 규격 없이 잘라내는 pruning Structured Pruning : weight를 channel / layer 단위로 규격을 잡아 제거하는 pruning, 규격을 잡아 제거했기 때문에 hardward optimization이 잘 된다. Iterative pruning Pruning을 한 번에 많이 수행하게 되면, 많은 weight가 사라지게되어 pruning loss가 줄어든 후 Accuracy가 다시 올라가지 않아서 Iterative (반복적)으로 수행 pruning loss -&gt; retraining -&gt; pruning loss -&gt; retraining … Lottery ticket hypothesis pruning하기 전 얻었던 Accuracy (91%)를 pruning하고 나서도 얻을 수 있는 subnetwork가 원래 network 안에 존재할 것이다라는 가설 original network의 initialization된 parameter를 그대로 사용해야 Accuracy가 잘 나오는 subnetwork. 한계점은 subnetwork를 찾기 위해서는 어짜피 original network를 train해서 찾아야 한다는 것 한계점을 극복하기 위해 차후에 나온 방법(적은 cost) Iterative Magnitude pruning weight의 크기 기준으로 정렬해서 크기가 낮은 기준으로 잘라낸다는 의미 prune-&gt;mask를 씌우고 구조만 가지고 와서 다시 init Iterative Magnitude Pruning with Rewinding k번까지만 train 시킨 후, 이때의 네트워크를 저장 이후 수렴할 때 까지 훈련하고 pruning한 후 마스크를 적용해준다. Retrain 시, 마스크가 적용된 네트워크를 k번 학습하고 저장해놓은 네트워크를 이용하여 초기화해준다.","link":"/2021/03/18/BoostCamp/Day38/"},{"title":"Day32","text":"Problems with deeper layersGoing deeper with convolutions larger receptive fields more capacity and non linearity but gradient vanishing/exploding, computationally complex degradation problem, not overfitting CNN artchitectures for image classificationGoogLenet 여러 합성곱 및 풀링 레이어에 대한 병렬적 연산을 수행-&gt;concat The increased network size increases the use of computational resources -&gt; 1x1 conv 필터 수가 출력의 채널이 되어, 채널을 줄일 수 있게 됨 각 Inception 블록마다 단계별로 loss값을 구하는 경로를 마련 최종 Output에 대한 loss와 Auxiliary Classifier로부터 얻은 loss를 모두 종합하여 역전파 수행 ResNet depth가 성능에 중요 overfitting이 아니라 degradation problem Skip-Connection을 하나 추가할 때마다 Gradient 전파경로의 경우의 수가 2배 증가하여, Gradient 전파에 대한 시간 복잡도는 O(2^n) [참고]Residual Networks Behave Like Ensembles of Relatively Shallow Networks DenseNet 이전의 모든 레이어에 대한 정보들을 입력값으로 넣어줌-&gt; Concat하며 학습 채널이 늘어남으로 메모리도 늘어남 ,but feature 보존 SENet Squeeze &amp; Excitation Block EfficientNet 성능을 높이는 방법에 따라 Saturation Point가 다름 각각의 유용한 방법들을 적절한 비율로 동시 scaling 함 Deformable convolution 사람과 동물같은 deformable한 형태를 고려 리드를 활용하여 객체를 유연하게 파악 Semantic segmentation 이미지 분류를 영상 단위가 아니라 픽셀 별로 하는 것. 단, 같은 클래스(종류)이면서 서로 다른 물체(개체)를 구분하지는 않는다 ArchitectureFCN 입력부터 출력까지 모두 인공신경망으로만 구성된 end-to-end 구조 어떤 사이즈의 이미지도 입력할 수 있고, 입력 이미지와 동일한 크기의 Segmentation 결과를 얻을 수 있음 Fully Connected 구조를 사용하지 않고 업샘플링을 적용하여 저해상도 문제를 해결 1×1 Conv 레이어를 활용하여 Spatial Information을 유지-&gt;히트맵을 얻음 1×1 Conv 레이어를 활용하면 채널 간 압축 과정 일어남 이는 기존의 Feature Map을 채널을 주축으로 Flatten하여 FC 레이어를 적용하는 것과 같음 Upsampling 저해상도 문제를 회피하기 위한 방법 Conv, Pooling 레이어를 줄일수록 receptive field가 줄어들기 떄문에 일단은 작게 만들어서 receptive field 키워서 영상의 전반적인 context 파악할 수 있게 함 이후 upsampling을 통해 강제로 해상도 맞춰줌 Tranposed convolution 입력 이미지에 필터를 적용하여 사이즈를 크게 변환하는 방법 연산 과정에서 중첩 문제가 발생하는데 (checkboard artifact), 때문에 필터 사이즈와 Stride에 대한 튜닝이 필수적 overlap되는 구간은 다른 구간들보다 상대적으로 출력값이 높아 진해짐 upsample and convolution interpolution과 convolution을 분리 upsampling을 통해 중첩 문제가 없이 골고루 영향을 받게 함 low-level의 detail, local + high-leve의 global 높은 layer의 activation map을 upsampling하여 해상도를 크게 끌어올린다. 이에 맞추어 중간 layer의 activation map을 upsampling하여 가져오고, concat한다. Hypercolumns for object segmentation U-Net FCN기반 낮은 레이어와 높은 레이어에 있는 결과를 더 잘 결합하는 방법을 제시함 Contracting Path 풀링하면서 receptive field를 크게 확보하기 위해 해상도를 낮추고 채널수를 늘림 Expanding Path 채널 사이즈가 점점 줄어들지만 해상도는 늘어남 대칭되는 Contracting path의 layer에서 skip connection을 통해 대칭되는 feature map들을 가져와서 concat 한번에 Upsampling 하지 않고 차례대로 단계적으로 해상도를 올려줌 이미지 사이즈를 모두 짝수로 유지해야 함 DeepLab 후처리에 CRFs 사용 픽셀과 픽셀 사이의 관계 이어줌 regular한 pixel map을 그리드로 봄→ 최적화를 통해 경계 잘 찾을 수 있도록 모델링 Atrous convolution 컨볼루션 필터 사이에 Dilation factor 만큼 일정한 공간을 넣어줌 파라미터 수는 늘리지 않으면서 receptive field는 exponential하게 키울 수 있다 Depthwise separable convolution 기존의 convolution 연산은 하나의 필터를 모든 input 채널에 대입시켰다. 기본 convolution 연산을 둘로 나눠서 conv 의 표현력을 어느정도 유지하면서 계산량은 획기적으로 줄어듦 채널 별로 conv 해서 각각 값을 뽑음 + 1x1 conv 통해 하나의 값으로 출력되게 만듦","link":"/2021/03/10/BoostCamp/Day32/"},{"title":"Day40","text":"Map1 : Matrix (Tensor) is a data modeling tool 2 차원 행렬 Matrix 와 3 차원 이상 행렬 Tensor 는 data 를 나타내고 처리할 수 있는 도구이다. 위와 같이 다양한 분해가 가능하다. Map2 : Matrix (Tensor) is a linear transformation (map) Matrix (Tensor) 는 선형 변환이다. Map3 : Terminology Matrix (Tensor) 와 관련한 다양한 용어들 (기법들) 이 사용 가능하다. Filter decomposition 필터로 표현되는 데이터들의 분해 (e.g. 컨벌루션 레이어) Matrix factorization 2 차원으로 표현되는 데이터들의 분해 Tensor factorization 고차원으로 표현되는 데이터들의 분해 전부 어느 정도 겹치는 개념 Low-rank matrix approximation large-scale 로 학습하는 문제에서 Low-rank matrix approximation 는 kernel method 의 필수적인 도구이다. Kernel Method 2차원 데이터를 구분하고 싶을 때, 어떤 function을 통해 3차원 혹은 그 이상의 차원으로 보내면 저차원에서 구분이 안되는 것들이 구분되는 경우가 있다. 이를 고차원으로 보내기 위해서는 연산에서 큰 비용이 사용된다. 이를 다른 방법으로 고차원으로 보내기 위해 kernel method를 사용한다. Low-rank approximation in model compression Kernel method처럼 딥러닝에서 Filter를 decompostion 하는 방법 Depth-wise Seperable Convolution을 사용하면 훨씬 연산량이 적게 결과를 도출 커널 메소드를 통해 원래 값은 (근사하게) 나타내면서 파라미터 수는 줄일 수 있다. Matrix Decomposition Matrix decomposition은 행렬을 특정한 구조를 가진 다른 행렬의 곱으로 나타내는 것을 의미 이때, 나눠진 행렬의 곱은 원본 행렬에 근사 Eigenvalue Decomposition Matrix 는 선형 변환이다. 어떤 점 (벡터) 을 변환시켰을 때 길이만 바뀌는 벡터를 아이겐 벡터라고 한다. 그리고 변하는 길이를 아이겐 밸류라고 한다. Eigenvalue Decomposition 은 nxn 으로 이뤄진 행렬을 아이겐 벡터, 아이겐 밸류를 통해 분해하는 방법이다. Singular Value Decomposition (SVD) : A Generalization (nm case) of EVD Singular Value Decomposition은 eigenvalue(고윳값)을 decomposition 할 때 행과 열 크기가 같은 정방행렬(m x m 행렬)만 가능했지만 행과 열 크기가 다른 직각행렬에서의 분해가 가능 SVD 는 mxn 행렬을 EVD 처럼 분해하는 방법이다. M 은 다음과 같이 분해될 수 있다. SVD 는 EVD의 일반화된 방법임을 알 수 있다. PCA SVD에서 중요한 부분만 남기고 필요없는 부분은 잘라내는 것이 PCA이다. Tensor Decomposition CP (Canonical Polyadic) Decomposition 텐서에 SVD 를 적용한 것과 비슷한 방법이다. CP decomposition은 3차원 tensor을 3개의 rank1 tensor로 분해 Tucker decomposition은 3차원 tensor을 작아진 3차원 core tensor와 그의 3차원에 해당하는 정보를 가진 3개의 2차원 tensor로 분해 Tucker Decomposition Tucker Decomposition 은 CPD 를 일반화한 것에 가깝다. CP와 tucker은 매우 유사한 방법이나 표현이 다른 것이다. 임의의 tensor 를 여러개로의 행렬들이랑 곱한것으로 cp decomposition처럼","link":"/2021/03/22/BoostCamp/Day40/"},{"title":"Day7","text":"경사하강법 변수의 움직임에 따른 함수값의 변화를 측정하기 위한 도구 sympy.diff 접선의 기울기 함수를 증가시키고 싶다면 미분값을 더하고 감소시키고 싶으면 미분값을 뺀다. 변수가 벡터일 경우 편미분 각 변수별로 편미분을 계산한 그레디언트(gradient)벡터를 이용하 여 경사하강/경사상승법에 사용할 수 있다 -$\\nabla(f) $는 $ \\nabla(−f)$랑 같고 이는 각점에서 가장 빨리 감소하게 되는 방향과 같다 경사하강법 알고리즘은 그대로 적용된다. 그러나 벡터는 절대값 대신 노름(norm)을 계산해서 종료조건을 설정한다 경사하강법으로 선형회귀 계수 구하기 이론적으로 경사하강법은 미분가능하 고볼록(convex)한 함수에 대해선 적절한 학습률과 학습횟수를 선택했을 때 수렴이 보장되어있습니다 확률적경사하강법 모든 데이터를 사용해서 업데이트하는 대신 데이터 한개 또는 일부 활용하여 업데이트합니다 미니배치는 확률적으로 선택하므로 목적식 모양이 바뀌게 된다. exercise) RMSE의 미분","link":"/2021/01/26/BoostCamp/Day7/"},{"title":"Day6","text":"Numpy shape : dimension 반환 dtype : 데이터 type 반환 ndim : number of dimensions size : data 개수 reshape : shape 변경 , 개수 동일 -1 : size를 기반으로 row 개수 선정 flatten : 1차원으로 변환 slicing example[1] # 1dim example[1:2] # 2dim arange zeros ,ones, empty(초기화X), something_like identity (단위행렬) eye : 대각선 1 diag : 대각 출력 sum axis : 새로 만들어진 축이 0 mean , std vstac, hstack, concatenate Element-wise operations dot product transpose, T broadcasting comparisons logical_and logical_not logical_or where(condition,TRURE,FALSE) ,index반환 isnan isfinite argmax argmin argsort boolean index shape같아야됨 fancy index shape같지 않아도됨 npy : pickle 형태로 저장 Vector 차원 : 벡터의 개수 벡터의 노름(norm)은 원점에서부터의 거리 ∥ ⋅ ∥ L1노름 각 성분의 변화량의 절대값을 모두 더함 L2노름 피타고라스 정리를 이용해 유클리드 거리를 계산 노름의 종류에 따라 기하학적 성질이 달라지므로 둘 다 알자 두 벡터 사이의 거리를 계산할때는 벡터의 뺄셈을 이용합니다 두벡터사이의거리를이용하여각도도계산 L2를 이용 제2코사인 내적은 정사영(orthogonalprojection)된 벡터의 길이와 관련있다. Proj(x)의길이는코사인법칙에의해∥x∥ cos θ가된다 내적은정사영의길이를벡터 의길이 만큼조정한값이다 행렬 행렬(matrix)은 벡터(행벡터)를 원소로 가지는 2차원배열 행렬 곱셈 행렬곱셈은 i번째행벡터와 j번째열벡터사이의내적 행렬도내적이있을까 넘파이의np.inner는 번째행벡터와 번째행벡터사이의내적을 성분으로가지는행렬을계산합니다 행렬은 벡터공간에서 사용되는 연산자(operator)로 이해한다 다른 차원의 공간으로 보낼 수 있다 패턴을 추출 할 수도, 데이터를 압축할 수도 있다. 역행렬 행과 열 숫자가 같고 행렬식 (determinant)이 0이 아닌 경우에만 계산할 수 있다 numpy.linalg.inv 로 구할 수 있다 만일 역행렬을 계산할 수 없다면 유사역행렬(pseudo-inverse)또는 무어펜로즈(Moore-Penrose)$A^+$역행렬을 이용한다 numpy.linalg.pinv","link":"/2021/01/25/BoostCamp/Day6/"},{"title":"Day8","text":"Pandas pandel data tabular data values()-&gt;numpy type series series : DataFrame중 하나의 Column에 해당하는 데이터의 모음Object 1234list_data = [1, 2, 3, 4, 5]list_name = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;]example_obj = Series(data=list_data, index=list_name)example_obj a 1 b 2 c 3 d 4 e 5 dtype: int64 loc : index location, index이름 iloc : index position, index number 123# Example from - https://stackoverflow.com/questions/31593201/pandas-iloc-vs-ix-vs-loc-explanations = pd.Series(np.nan, index=[49, 48, 47, 46, 45, 1, 2, 3, 4, 5])s.loc[:3] 49 NaN 48 NaN 47 NaN 46 NaN 45 NaN 1 NaN 2 NaN 3 NaN dtype: float64 1s.iloc[:3] 49 NaN 48 NaN 47 NaN dtype: float64 drop(변화x) ,del(변화o) selectinon &amp; drop reset_index drop inplace dataframe operation series는 index 중복 가능 fill_value : nan채워줌 12df = DataFrame(np.arange(16).reshape(4, 4), columns=list(&quot;abcd&quot;))df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 12s = Series(np.arange(10, 14), index=list(&quot;abcd&quot;))s a 10 b 11 c 12 d 13 dtype: int32 1df + s .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d 0 10 12 14 16 1 14 16 18 20 2 18 20 22 24 3 22 24 26 28 12s2 = Series(np.arange(10, 14))s2 0 10 1 11 2 12 3 13 dtype: int32 1df + s2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d 0 1 2 3 0 NaN NaN NaN NaN NaN NaN NaN NaN 1 NaN NaN NaN NaN NaN NaN NaN NaN 2 NaN NaN NaN NaN NaN NaN NaN NaN 3 NaN NaN NaN NaN NaN NaN NaN NaN 1df.add(s2, axis=0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d 0 10 11 12 13 1 15 16 17 18 2 20 21 22 23 3 25 26 27 28 lambda map apply map, replace apply series전체(column) 에 적용 sum =apply(sum) applymap : 모든 element에 적용 built-in function describe 숫자만 가능 unique corr, cov, corrwith 상관관계 pd.options.display.maxrows 설정 sort_values() -&gt; index 섞임 value_counts() 딥러닝 학습방법 b : 절편, 각 행들이 같은 값 차원 d-&gt;p 소프트맥스연산 소프트맥스(softmax)함수는 모델의 출력을 확률로 해석할 수 있게 변환해 주는 연산 overflow를 방지하기 위해 max값을 뺴줌 학습의 경우 소프트맥스를 쓰지만 추론의 경우는 쓰지 않는다. 활성함수 실수값을 받아 실수값을 내는 비선형 함수 활성함수를 쓰지 않으면 딥러닝은 선형모형과 차이가 없다 시그모이도(sigmoid)함수나 tanh함수는 전통적으로 많이 쓰이던 활성함수지만 딥러닝에선 ReLU함수를 많이 쓰고 있다 신경망은 선형모델과 활성함수(activationfunction)를 합성한 함수 순차적인 신경망 계산을 순전파(forwardpropagation)라부른다 왜층을여러개를쌓나? 이론적으로는 2층신경망으로도 임의의 연속함수를 근사 할 수있다 층이 깊을수록 목적함수를 근사하는데 필요한 뉴런(노드)의 숫자가 훨씬 빨리 줄어들어 좀더 효율적으로 학습이 가능 역전파 알고리즘 각 노드의 텐서 값을 기억해야 하기 때문에 forward보다 메모리 많이 차지 Further question softmax 사용 이유 softmax연산의 경우 exp연산을 통해 크고 작음의 차이가 더 벌어지게된다. 값이 클수록 더 벌어진다는 말이다. 분류문제에서 더 올바른 분류결과를 빠르게 학습할 수 있기 위함이다.","link":"/2021/01/27/BoostCamp/Day8/"},{"title":"Day39","text":"fixed point &amp; floating point fixed-point : 정수 부분과 소수 부분을 그대로 구역을 나누눠 저장, 32bit Floating point방법에 비하여 메모리를 비 효율적으로 사용하는 형태 모두 실수를 표현하는 방법이며, 같은 bit를 사용할 때 표현할 수 있는 수의 갯수는 서로 같다. 다만 floating point는 fixed point에 비해 정밀도가 떨어지고, 대신 더 넓은 범위의 값들을 표현할 수 있다. floating point를 연산할 때는 FPU(Floating Point Unit)이 사용되는데, 회로의 크기도 크고 메모리도 많이 잡아먹는다. 따라서 정밀도를 포기하고 floating point 대신 int를 사용한다면 모델경량화에 도움이 될 것이다. Quantization 아날로그 데이터, 즉 연속적인 값을 디지털 데이터, 즉 띄엄띄엄한 값으로 바꾸어 근사하는 과정 FP number를 int8 등의 정수 보다 적은 bit의 자료형으로 mapping하여 정보를 잃는 대신 필요한 메모리를 줄이고 컴퓨팅 속도를 빠르게 하기 위한 compression 기법 float32는 크기에 비해 적은 범위를 사용하고 있고, 이 것을 int8에 mapping 시키면 모든 공간 사용이 가능하지만 정보 손실이 일난다 특징 model size 감소 memory bandwith requirements 감소 inference 에서 속도를 높이는 기초적인 방법이다. 연산 속도 가속화:이는 FPU(Floating Point Unit)가 하던 연산을 ALU(Arithmetic and Logic Unit)가 대체할 수 있게 되기 때문이다. Affine quantization Affine transform은 어떤 linear map에서 형태는 똑같지만(닮음은 유지하면서), 비율이나 크기만 작아지고 커지는 transform linear + activation Affine quantization은 이전 수식이나 형태를 유지하면서, 모델의 비율이나 크기만 작고 크게 quantization을 수행하는 것 Float -&gt; INT, INT -&gt; Float와 같은 quantization을 수행하고, 중간중간 Float, int형으로 variance의 scale만 바뀌었을뿐, 모델의 형태 자체가 변하지는 않는다 Quantizing activation and weights activation과 weight 모두 quantizing을 할 수 있다 ReLU activation function을 3-bit로 quantizatin Activation function에 quantization을 수행할 수 있고, weight 자체에다 quantization을 할 수 있다 Differentiating quantized values Quantization의 문제는 backpropagation을 할 때 미분이 안되는 문제점을 가지고 있다 Quantization을 하게 되면 계단 형태의 함수가 발생하게 되고, flat 한 부분은 미분을 할 수 없기 때문 backpropagation을 할 때 $∂y\\over∂x$를 Quantization 하기 전의 값으로 돌려놓고서 Loss를 계산합니다. 또는 smoothing 해서 계단형으로 사용하기도 한다. Quantization의 종류 어떤 것을 양자화할 것인지(weight, activaiton), 어떻게 할 건지(Dynamic, Static), 얼마나 할건지(mixed-precise, 16bit, 8bit, …), 언제 할 건지(Post-training, Quantization-aware training) 등 Dynamic quantization(DQ): training할 때에는 activation은 그대로 두고, weight만 quantization했다가 인퍼런스할 때에 activation도 quantization을 하는 방법, LSTM, Transformer 동적 양자화 기법은 보통 모델의 inference time 대부분을 메모리 로딩 시간이 잡아먹는 경우 많이 활용 Static quantization(PTQ): 정적 양자화는 Post Training Quantization 또는 PTQ라고 불린다 . inference 때weight과 activation을 모두 양자화하는 기법이다, CNN Quantization aware training(QAT): trainig 과정 중 quatization 될 것을 학습하도록 만드는 방법 fake node를 두어 추후 quantize 되었을 때의 영향을 미리 simulation Knowledge distillation Knowledge distillation은 teacher network와 student network의 output의 차이를 좁히는 방법으로 지식을 전수하는 효과를 내는 것이다. 크기가 작은 모델이 이를 통해 비슷한 성능을 낼 수 있게 되기 때문에 모델을 압축할 때 사용된다. transfer learning: 다른 도메인에 적용하는 것 distillation: 동일한 지식을 작은 모델에 전달 logit와 sigmoid는 서로 역함수 관계 위쪽에서는 soft prediction과 soft label에 대한 KL Divergence 아래 쪽에서는 hard prediction과 hard label에 대한 softmax를 적용 soft label은 hard prediction과는 다르게 확률값들로 표현, dog와 cat은 가까운 거리를 가지고 있고, dog와 car는 먼 거리를 가지고 있다 이 개념을 Teacher-Student model에 집어넣기 위해 Softmax에 Temperature (T) 값을 집어 넣게 됩니다. L(x;w) = \\alpha * KL(teacher, student) + (1-\\alpha)*Cross-Entropy(y,student) KD_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs/T, dim=1), F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T) + \\ F.cross_entropy(outputs, labels) * (1. - alpha) You can refer to the definition/document of PyTorch’s KL Divergence loss (KLDivLos). Here it requires inputs to be probability distributions and log-probability distributions, and that’s why we’re using softmax and log-softmax on teacher/student outputs nn.KLDivLoss 클래스의 기대 input은 student에 대한 log_softmax와 teacher에 대한 softmax Zero-mean assumption distillation은 model compression 측면에서 zero-mean을 만족해야 한다 Feautre distillation Teacher network에서 나온 soft label 결과를 가지고 training 하는 것이 아니라 중간중간의 layer마다 값을 비교하는 방법 뽑아낸 Knowledge를 ReLU 앞에 놓아가지고 Distillation을 수행하는 방법 Data-free knowledge distillation teacher, student 모두 오리지널 데이터가 필요한 문제-&gt;데이터가 필요 없도록 data에 종속되지 않는 (data가 없거나 매우 적은 양)으로 knowledge distillation 학습시킨 student model을 deploy할 때, Data center에서 뽑아온 metadata와 함께 deploy 하고, stduent model이 필요한 시점에 필요한 데이터를 reconstruction 한다는 것","link":"/2021/03/19/BoostCamp/Day39/"},{"title":"Day41-EDA","text":"Image Classification &amp; EDAEDA란? Exploratory Data Analysis(탐색적 데이터 분석) 데이터를 이해하기 위한 노력 따라치지만 새로운 데이터에 접근하려고 하면 어려움 발생 서술형(불확실성) ​ 처음에는 정말 아무렇게나 해보자 Image Classification unsigned int (0~255) Image+ClassificationModel=Class Baseline 베이스라인 코드는 강의를 거듭할 수록 점점 내용이 더해질 예정 프로젝트 기록 목표 EDA data labelling 목표 달성을 위한 노력 시각화(matplotlib, seaborn, pandas) 모델 개선 방식 우선 resnet18을 시도 (Trained from scratch) 결과, 깨달음 EDA의 중요성 image classification이니까 단순히 분류만 하면 될 줄 알았는데 EDA를 통해 데이터의 imbalance함을 알 수 있었다 object detection을 통해 마스크를 감지하는 것이 필요해보인다 시도 모델 개선 custom dataset 아쉬운 점 라벨링에 의외로 시간이 많이 들었다 augmentation을 시도해봐야겠다.","link":"/2021/03/30/BoostCamp/Project%20Stage/Day41/"},{"title":"Day9","text":"Groupby12h_index = df.groupby([&quot;Team&quot;, &quot;Year&quot;])[&quot;Points&quot;].sum()h_index Team Year Devils 2014 863 2015 673 Kings 2014 741 2016 756 2017 788 Riders 2014 876 2015 789 2016 694 2017 690 Royals 2014 701 2015 804 kings 2015 812 Name: Points, dtype: int64 sort_index() sort_values() agg(aggregation) transform filter 1234import dateutildf_phone[&quot;date&quot;] = df_phone[&quot;date&quot;].apply(dateutil.parser.parse, dayfirst=True)df_phone.dtypes index int64 date datetime64[ns] duration float64 item object month object network object network_type object dtype: object add_prefix pivot_table crosstab merge(a,b,on=’ ‘) merge(left, right, left_on=’ ‘,right_on=’ ‘) merge(how=’ ‘) left,right,outer concat db conneciton 확률론 손실함수(lossfunction)들의 작동원리는데이터 공간을 통계적으로 해석해서 유도 회귀분석에서 손실함수로 사용되는 L2-노름은 예측오차의 분산을 가장 최소화하는 방향으로 학습하도록 유도 교차엔트로피(cross-entropy)는 모델예측의 불확실성을 최소화하는 방향으로 학습하도록 유도 이산확률변수 vs 연속확률변수 데이터공간 xy에 의해 결정되는 것으로 오해를 하지만 확률변수의분포D에 의해 결정된다 회귀문제의 경우 연속활률 변수를 다뤄 밀도함수로 해석 데이터가 robust하면 중앙값을 사용하기도 함 로버스트(robust) 한 통계량은 이상치/에러값으로 부터 영향을 크게 받지 않는 (건장한) 통계량 기대값? 연속 : 확률밀도함수-&gt;적분, 이산 : 확률질량함수-&gt;sum 몬테카를로 샘플링 밀도함수나 질량함수를 알고있으면 기대값을 계산할 때 적분이사 sum을 해주면 되지만 확률분포를 명시적으로 모르는 상황에서 샘플링하는 방법을 알고있으면 적분이나 sum대신에 샘플링을 통해 기대값을 계산할 수 있다. x자리에 샘플링한 데이터를 대입 $f(x^(i))$값들의 산술평균이 기대값에 근사, 독립적으로 샘플링을 해야한다. 독립추출이 보장되면 대수의법치겡 의해 수렴성을 보장 샘플사이즈가 적으면 오차범위가 커질 수 있다. further queston 몬테카를로 방법으로 원주율 계산하기 정사각형넓이 =$4r^2$ ,원의 넓이=$\\pi r^2$ 정사각형 안의 임의의 점이 원안에 있을 확율=$\\pi r^2\\over4r^2$=$\\pi\\over4$ (정사각형 안의 임의의 점이 원안에 있을 확율)*4=$\\pi$ 1from random import random 123456789101112def random_in(r): x=random()*r*2 y=random()*r*2 return (x-r)**2+(y-r)**2&lt;=r**2total=5000success=0for _ in range(total): if random_in(1)==True: success+=1pi=success/total*4print(pi) 3.1904 question 각 벡터마다 max값을 뺴는 이유? softmax함수는 exp()힘수를 사용하므로 오버플로우가 발생할 수 있다. 따라서 max값을 벡터의 모든 요소에서 빼면 벡터의 요소들은 -max~0의 값을 가져 exp()함수의 출력은 0~1의 값을 가지게 된다.","link":"/2021/01/28/BoostCamp/Day9/"},{"title":"Pytorch1","text":"Gradient Descentexercise) $y=x^2w_2+xw_1+b-y$Using pytorch12345import torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimtorch.manual_seed(1) &lt;torch._C.Generator at 0x2cdbae1d070&gt; 12345678x_train = torch.FloatTensor([[1.0],[2.0],[3.0]])y_train = torch.FloatTensor([[2.0],[4.0],[6.0]])w1 = torch.zeros(1, requires_grad=True)w2 = torch.zeros(1, requires_grad=True)b = torch.zeros(1, requires_grad=True)def forward(x): return x*x*w2 + x*w1 + bprint(forward(4)) tensor([0.], grad_fn=&lt;AddBackward0&gt;) 123456789101112131415161718192021# optimizer 설정optimizer = optim.SGD([w2,w1,b], lr=2*1e-2)nb_epochs = 2000for epoch in range(nb_epochs + 1): # H(x) 계산 hypothesis = x_train*x_train*w2+x_train*w1+b # cost 계산 cost = torch.mean((hypothesis - y_train) ** 2) # cost로 H(x) 개선 optimizer.zero_grad() cost.backward() optimizer.step() if epoch % 100 == 0: print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} b: {:.3f} Cost: {:.6f}'.format( epoch, nb_epochs, w1.item(), w2.item(), b.item(), cost.item() )) Epoch 0/2000 w1: 0.373 w2: 0.960 b: 0.160 Cost: 18.666666 Epoch 100/2000 w1: 0.858 w2: 0.302 b: 0.828 Cost: 0.025777 Epoch 200/2000 w1: 0.959 w2: 0.255 b: 0.891 Cost: 0.014748 Epoch 300/2000 w1: 0.998 w2: 0.243 b: 0.875 Cost: 0.013746 Epoch 400/2000 w1: 1.029 w2: 0.235 b: 0.850 Cost: 0.012942 Epoch 500/2000 w1: 1.058 w2: 0.228 b: 0.825 Cost: 0.012187 Epoch 600/2000 w1: 1.086 w2: 0.221 b: 0.801 Cost: 0.011475 Epoch 700/2000 w1: 1.113 w2: 0.215 b: 0.777 Cost: 0.010806 Epoch 800/2000 w1: 1.139 w2: 0.209 b: 0.754 Cost: 0.010175 Epoch 900/2000 w1: 1.165 w2: 0.202 b: 0.732 Cost: 0.009581 Epoch 1000/2000 w1: 1.189 w2: 0.196 b: 0.710 Cost: 0.009022 Epoch 1100/2000 w1: 1.214 w2: 0.191 b: 0.689 Cost: 0.008495 Epoch 1200/2000 w1: 1.237 w2: 0.185 b: 0.669 Cost: 0.008000 Epoch 1300/2000 w1: 1.259 w2: 0.179 b: 0.649 Cost: 0.007533 Epoch 1400/2000 w1: 1.281 w2: 0.174 b: 0.630 Cost: 0.007093 Epoch 1500/2000 w1: 1.303 w2: 0.169 b: 0.611 Cost: 0.006679 Epoch 1600/2000 w1: 1.323 w2: 0.164 b: 0.593 Cost: 0.006289 Epoch 1700/2000 w1: 1.343 w2: 0.159 b: 0.575 Cost: 0.005922 Epoch 1800/2000 w1: 1.363 w2: 0.154 b: 0.558 Cost: 0.005577 Epoch 1900/2000 w1: 1.382 w2: 0.150 b: 0.542 Cost: 0.005251 Epoch 2000/2000 w1: 1.400 w2: 0.145 b: 0.526 Cost: 0.004945 1print(forward(4)) tensor([8.4512], grad_fn=&lt;AddBackward0&gt;) Manual참조 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# Training Datax_data = [1.0, 2.0, 3.0]y_data = [2.0, 4.0, 6.0]# a random guess: random valuew1 = 0w2 = 0b = 0# our model forward passdef forward(x): return pow(x,2)*w2 + x*w1 + b# Loss functiondef loss(x, y): y_pred = forward(x) return (y_pred - y) * (y_pred - y)# compute gradientdef w1_gradient(x, y, y_pred): # d_loss/d_w1 return 2 * x * (y_pred - y)def w2_gradient(x, y, y_pred): # d_loss/d_w2 return 2 * pow(x, 2) * (y_pred - y)def b_gradient(x, y, y_pred): # d_loss/d_b return 2 * (y_pred - y)# Update the weights and the biasdef optimize(x, y, learning_rate = 0.02): global w1, w2, b y_pred = forward(x) w1_grad = w1_gradient(x, y, y_pred) w1 = w1 - learning_rate * w1_grad w2_grad = w2_gradient(x, y, y_pred) w2 = w2 - learning_rate * w2_grad b_grad = b_gradient(x, y, y_pred) b = b - learning_rate * b_grad# print('\\tgrad(w1, w2, b): ', x_val, y_val, round(w1_grad, 2), round(w2_grad, 2), round(b_grad, 2)) return w1, w2, b# Before trainingprint(&quot;Prediction (before training)&quot;, 4, forward(4))# Training loopfor epoch in range(20): for x_val, y_val in zip(x_data, y_data): # Compute derivative w.r.t to the learned weights # Compute the loss and print progress w1, w2, b = optimize(x_val, y_val) l = loss(x_val, y_val) print(&quot;progress : &quot;, epoch, &quot;loss = &quot;, round(l, 2))# After trainingprint(&quot;Predicted score (after training)&quot;, &quot;4 hours of studying: &quot;, forward(4)) Prediction (before training) 4 0 progress : 0 loss = 6.38 progress : 1 loss = 11.8 progress : 2 loss = 6.54 progress : 3 loss = 6.22 progress : 4 loss = 4.57 progress : 5 loss = 3.81 progress : 6 loss = 3.01 progress : 7 loss = 2.45 progress : 8 loss = 1.98 progress : 9 loss = 1.61 progress : 10 loss = 1.32 progress : 11 loss = 1.08 progress : 12 loss = 0.9 progress : 13 loss = 0.75 progress : 14 loss = 0.63 progress : 15 loss = 0.53 progress : 16 loss = 0.45 progress : 17 loss = 0.38 progress : 18 loss = 0.33 progress : 19 loss = 0.29 Predicted score (after training) 4 hours of studying: 7.71975178478036 Optimizer참조 Logistic RegressionBinary Classification using sigmoid12345%matplotlib inlineimport numpy as np # 넘파이 사용import matplotlib.pyplot as plt # 맷플롯립사용def sigmoid(x): # 시그모이드 함수 정의 return 1/(1+np.exp(-x)) 1234567891011x = np.arange(-5.0, 5.0, 0.1)y1 = sigmoid(0.5*x)y2 = sigmoid(x)y3 = sigmoid(2*x)plt.plot(x, y1, 'r', linestyle='--') # W의 값이 0.5일때plt.plot(x, y2, 'g') # W의 값이 1일때plt.plot(x, y3, 'b', linestyle='--') # W의 값이 2일때plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가plt.title('Sigmoid Function')plt.show() ​​ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657from torch import tensorfrom torch import nnfrom torch import sigmoidimport torch.nn.functional as Fimport torch.optim as optim# Training data and ground truthx_data = tensor([[1.0], [2.0], [3.0], [4.0]])y_data = tensor([[0.], [0.], [1.], [1.]])class Model(nn.Module): def __init__(self): &quot;&quot;&quot; In the constructor we instantiate nn.Linear module &quot;&quot;&quot; super(Model, self).__init__() self.linear = nn.Linear(1, 1) # One in and one out def forward(self, x): &quot;&quot;&quot; In the forward function we accept a Variable of input data and we must return a Variable of output data. &quot;&quot;&quot; y_pred = sigmoid(self.linear(x)) return y_pred# our modelmodel = Model()# Construct our loss function and an Optimizer. The call to model.parameters()# in the SGD constructor will contain the learnable parameters of the two# nn.Linear modules which are members of the model.criterion = nn.BCELoss(reduction='mean')optimizer = optim.SGD(model.parameters(), lr=0.01)# Training loopfor epoch in range(1000): # Forward pass: Compute predicted y by passing x to the model y_pred = model(x_data) # Compute and print loss loss = criterion(y_pred, y_data) if epoch%100==0: print(f'Epoch {epoch}/1000 | Loss: {loss.item():.4f}') # Zero gradients, perform a backward pass, and update the weights. optimizer.zero_grad() loss.backward() optimizer.step()# After trainingprint(f'\\nLet\\'s predict the hours need to score above 50%\\n{&quot;=&quot; * 50}')hour_var = model(tensor([[1.0]]))print(f'Prediction after 1 hour of training: {hour_var.item():.4f} | Above 50%: {hour_var.item() &gt; 0.5}')hour_var = model(tensor([[7.0]]))print(f'Prediction after 7 hours of training: {hour_var.item():.4f} | Above 50%: { hour_var.item() &gt; 0.5}') Epoch 0/1000 | Loss: 0.5570 Epoch 100/1000 | Loss: 0.5298 Epoch 200/1000 | Loss: 0.5114 Epoch 300/1000 | Loss: 0.4944 Epoch 400/1000 | Loss: 0.4786 Epoch 500/1000 | Loss: 0.4638 Epoch 600/1000 | Loss: 0.4499 Epoch 700/1000 | Loss: 0.4368 Epoch 800/1000 | Loss: 0.4246 Epoch 900/1000 | Loss: 0.4131 Let's predict the hours need to score above 50% ================================================== Prediction after 1 hour of training: 0.3149 | Above 50%: False Prediction after 7 hours of training: 0.9854 | Above 50%: True Activation Functions 1","link":"/2021/01/25/Pytorch/Pytorch1/"},{"title":"Day44","text":"프로젝트 기록 목표 acc향상 목표 달성을 위한 노력 label smoothing 모델 개선 방식 다양한 loss사용 결과, 깨달음 역시나 acc비슷 시도 cutmix 아쉬운 점 ensemble을 적용하지 못함","link":"/2021/04/02/BoostCamp/Project%20Stage/Day44/"},{"title":"Day42-Augmentation","text":"프로젝트 기록 목표 dataset,loader augmentation 목표 달성을 위한 노력 custom dataset 모델 개선 방식 resnet152를 mask,age,sex각기 적용 결과, 깨달음 메모리 부족을 겪음 무작정 모델을 많이 올릴 수는 없다 시도 모델 개선 object detection 아쉬운 점 object detection에 대해 익숙하지 않아 시간이 오래걸림","link":"/2021/03/31/BoostCamp/Project%20Stage/Day42/"},{"title":"Day43","text":"프로젝트 기록 목표 darknet구현 목표 달성을 위한 노력 custom model from scratch 모델 개선 방식 NFNet 결과, 깨달음 acc향상에 별로였다 시도 pretrained된 모델을 custom 아쉬운 점 아직 모델 구조에 미숙","link":"/2021/04/02/BoostCamp/Project%20Stage/Day43/"},{"title":"Day45","text":"프로젝트 기록 목표 acc향상 목표 달성을 위한 노력 label smoothing cutmix 모델 개선 방식 efficientnet label smoothing loss 결과, 깨달음 역시나 acc비슷 시도 ensemble 아쉬운 점 ensemble을 적용하지 못함","link":"/2021/04/03/BoostCamp/Project%20Stage/Day45/"},{"title":"Day46","text":"프로젝트 기록 목표 acc향상 목표 달성을 위한 노력 ensemble cutmix 모델 개선 방식 efficientnet cutmix and cutmixloss 결과, 깨달음 acc비슷 시도 ensemble 아쉬운 점 valid acc와 test acc 차이가 큰 원인을 찾지 못함","link":"/2021/04/06/BoostCamp/Project%20Stage/Day46/"},{"title":"Day47","text":"프로젝트 기록 목표 acc향상 목표 달성을 위한 노력 test,valid 구분없이 학습 focal loss 모델 개선 방식 resnet50이 일단 성능이 좋음 결과, 깨달음 복잡한 모델이라고 성능이 높진 않은 듯 하다 시도 label 나눠서 학습 아쉬운 점 최적 hypterparameter를 찾는 것이 우선인 것 같다.","link":"/2021/04/06/BoostCamp/Project%20Stage/Day47/"},{"title":"Day48","text":"프로젝트 기록 목표 f1 score 향상 목표 달성을 위한 노력 test,valid 구분없이 학습 sampler를 사용하지 않고 shuffle 모델 개선 방식 resnet+EfficientNet+VIT 결과, 깨달음 앙상블 보단 단일 모델이 성능이 좋음 시도 K-Fold n_split=10 아쉬운 점 코드를 함수 단위로 나누어야 재사용하기 편할 것 같다.","link":"/2021/04/08/BoostCamp/Project%20Stage/Day48/"},{"title":"Day33","text":"Object detectionWhat is object detection semantic segmentation보다 더 구체적 객체가 달라도 구분이 됨 Instance segmentation ⊂ Panoptic sementation object detection=Classification + Box localization two-stage: box localization → classfication one-stage: box + classfication 한번에 What are the applications autonomous driveing ocr Two-stage detectorTraditional Gradient-based detector 과거에는 경계선을 특징으로 모델링 , gradient 방향성을 활용한 선형 모델 사용 selective search 사람이나 특정 물체 뿐만 아니라, 다양한 물체 후보군의 영역 후보군을 지정해주는 방식 bounding box 제안-&gt; Proposal Algorithm Over-segmentation: 영상을 색끼리 잘게 분할 merginig: 비슷한 feature를 가지는 영역들을 합침 반복해서 합쳐주다보면 object를 소수로 특정지음 특정지은 소수의 object 위치를 바운딩 박스로 나타냄 R-CNN Selective Search를 통해 Region Proposal을 진행 → 2K 이하로 설정 각 Region Proposal을 CNN의 input size로 Warping 기존에 pre-trained된 CNN에 input으로 넣어서 Classification을 진행 SVM의 linear classifier만을 이용해서 클래스를 학습(fine-tuning) 단점 모든 region proposal이 CNN에 입력값으로 들어가기 때문에 느림 Hand Designed된 selective search-&gt; 학습을 통한 성능향상에 한계 Fast R-CNN 영상 전체에 대한 Feature을 한번에 추출하고 이를 재활용해서 object detection Conv layer를 통해 feature map 검출 conv layer를 거쳤으므로 tensor형태가 된다 Fully Convolutional Network는 입력사이즈와 상관없이 Feature Map을 뽑아낼 수 있기 때문에 warp 필요 없다 RoI Pooling: Feature를 여러번 재활용, Region Proposal이 제시한 물체의 후보 위치들(Bounding Box)에 대해서 RoI에 해당하는 Feature만 추출한다. RoI feature를 고정된 사이즈로 resampling한다 classification : softmax, bbx regression로 위치 조정 selective search를 사용했으므로 성능 향상 한계 Faster R-CNN IoU 두 영역의 OVERLAP 측정 anchor box 각 위치에서 발생할 것 같은 박스를 미리 정의해둔 후보군 box의 개수와 종류는 hyperparameter Faster R-CNN에서는 9개 (scale 3 * 비율3) selective search 대신 RPN 모듈 제안 Fast R-CNN과 마찬가지로 각각의 영상에서 공유되는 Feature Map을 미리 뽑아두고, 해당 Feature Map을 바탕으로 RPN에서 Region Proposal을 여러 개 제공하고 RoI Pooling을 실시한 다음 Classifier를 통해 정답을 예측 Region Proposal Network Conv Layer를 통해 나온 Feature Map에 Sliding Window 방식으로 돌면서 매 위치마다 미리 정의해둔 K개의 Anchor Box를 고려 각 위치에서 256-d의 feature vector를 하나 추출 각 vector로 부터 Object인지 아닌지에 대한 score인 2K개 classification score (object, non-object) k개의 Bounding Box위치를 regression하는 4k 개의 Coordinates (x,y,w,h 4개) Anchor Box를 촘촘하게 만들면 계산 속도가 느려지므로 대표적인 비율과 Scale만 정해두고 정교한 위치는 Regression 문제로 분할 정복 각각의 Loss → Cross Entropy Loss + Regression Loss를 사용 이 2가지 Loss가 RPN을 위한 요소가 되며, 전체 Target Task를 위한 RoI별 Classification Loss는 따로 하나가 추가가 되서 전체적으로 End-to-End로 학습을 진행한다. RPN에서 object를 완전히 class로 분류한게 아니라, object인지 아닌지만 판단 RPN에서 classifier, regressor 두개의 모델이 필요하고, 마지막으로 classifier가 필요하다. 또 맨 처음 feature map을 뽑아낼 CNN도 필요하다. 총 4개의 모델이 각각이 아니라 한번에 학습된다. non maximum suppression IoU스코어가 낮은 박스들은 제거하는 방식의 NMS 알고리즘을 추가한다. Single-stage-detectorComparison with two-stage detector 성능을 조금 포기하고 계산 속도를 확보해서 real-time detection 이 가능하도록한 모델 ROI pooling을 하지 않기 때문에 구조가 매우 간단한 편 YOLO input image를 SxS grid로 나눈다 각 grid마다 바운딩박스 정보 4개 + object여부 1개 + Class 분류 확률 C개 = 5+C개의 정보를 한꺼번에 예측한다. Faster R-CNN의 RPN과 마찬가지로, ground truth와의 IoU스코어가 높은 Anchor box를 positive로 간주하여 loss 계산 30 channel= 앵커박스를 grid마다 2개만 사용했고, class 개수는 총 20개여서 5*2+20=30 s는 convolution layer에서의 마지막 해상도로 결정됨 마지막 layer에서만 prediction을 수행하기 떄문에 localization 정확도 떨어짐 single shot multibox detector(SSD) SSD는 Multi Scale object를 더 잘 처리하기 위해서 중간 Feature를 각 해상도에 적절한 Bounding Box 들을 출력할 수 있도록하는 Multi Scale구조를 만들었다. 각기 다른 크기의 feature map에서 정해진 크기의 anchor box를 사용하면, feature map 사이즈에 따라 anchor box가 scaling된다. feature map 사이즈마다, anchor box를 적용하여 object를 탐지한다. 때문에 YOLO에 비해 계산량이 늘어난다 SSD는 각 층마다 classifier적용 각 layer마다 (class수+위치정보4)에 anchor box개수를 곱해준다 Two-stage vs One-stageFocal loss 일반적으로object보다 background가 더 넗음-&gt; class imbalance 모든 구역에 대해 object detection하는 경우 negative를 결과로 내는 anchor boxrk 많아진다. focal loss= cross entropy의 확장 파란색 그래프가 기존의 Cross Entropy 나머지가 FL함수에서 $\\gamma$값을 바꿔주었을 때의 그래프다. 학률term을 통해 잘 맞춘 애들은 더 낮은 loss를 주고 맞추지 못한 애들은 더 높은 loss를 준다. FL함수는 정답률이 높을수록 gradient를 0에 가깝게 만들고, 정답률이 낮을수록 gradient가 가팔라지게 Loss 값 자체가 중요한게 아니라 gradient $\\gamma$값을 크게줄수록 적용 폭이 강해진다. Q) gamma가 높을수록 loss가 낮아지지만 잘 찾지 못할 때 loss는 소폭 줄어들게 하고 잘 찾은 경우에서는 loss를 대폭 줄어들게 합니다 RetinaNet FPN U-Net과 비슷한 구조다. residual을 활용하여 더해줌으로써, low-level의 특징과 high-level의 특징을 둘 다 활용하면서 각 scale별로 object를 잘 찾기 위한 multi-scale 구조를 갖게된다. (concat이 아닌 더하기) class 분류와 box 회귀 예측을 진행한다. Detection with Transform DETR CNN으로 Feature추출 후, Positional encoding을 더해준다. encoder 학습 후, decoder에 query를 입력으로 준다. (query는 object 정보이거나, positional encoding 정보) 추가로, 최대 몇개의 box를 찾아줄지에 대한 값도 함께 준다. (N) 해당 query에 맞는 object를 찾아 box를 찾아준다. positional encoding의 경우 해당 위치 근처의 바운딩 박스와 class를 찾아준다 Visualizing CNNWhat is CNN visualization 딥러닝 네트워크= black box CNN의 경우 시각화가 가능하다. visualization as debugging tool low-level feature는 방향성이 있는 선, 동그란 블록 high-level로 갈수록 의미있는 feature Vanilla example: filter visualization AlexNet 첫번째 층의 필터를 시각화 해당 필터를 이미지에 적용했을 때의 결과(하나의 필터만 적용했기 때문에 밝기값만 가지는 1채널 이미지) 높은 층으로 갈수록 필터도 채널 수가 늘어나 고차원의 필터를 시각화하기도 어렵고, 시각화 하더라도 사람이 해석할 수 없다 How to visualize neural network 왼쪽으로 갈수록 모델 자체를 분석 른쪽으로 갈수록 모델의 출력 결과가 왜 그렇게 나타났는지 분석 Analysis of model behaviorsEmbedding feature analysisHigh-level layer에서 얻는 High-level feature들을 분석하는 방법 nearest neighbors in a feature space 잘 군집되어 있음을 확인할 수 있으며 픽셀단위로 학습했음에도 불구하고 포즈도 다르고 방향도 다른 이미지들이 제대로 보여지는 것을 확인할 수 있다. 각각의 이미지에 대해 feature들을 뽑아놓고 임베딩 공간에 저장해둔다. 후 입력이 들어오면, 해당 feature와 비슷하게 임베딩된 feature들을 탐색한다. 유사도 탐색으로 찾아낸 k개의 feature들의 원본 image를 가져와서 반환해준다. 이 feature들은 매우 고차원 공간에 위치하므로 인간이 해석하기가 너무 어렵다. Demensionality reduction 고차원 상상 힘들기 때문에 차원축소를 통해 각 클래스마다 다른 색상으로 구분한다. 각 클래스간의 분포가 비슷한 위치에 존재한다면 해당 클래스들을 유사하게 보고 있다는 것으로 해석 가능 3, 8 , 5 분포가 가까움 -&gt; 경계에서 헷갈릴 수 있음 Activation investigation레이어의 activation을 분석하여 모델의 특성을 파악하는 방법 AlexNet 다섯번째 층의 138번째 채널 값을 thresholding을 통해 시각화-&gt;사람의 얼굴을 detection 각 hidden node들의 역할(activation)을 파악하는 방법 Maximully activating patch 레이어를 하나 골라서 해당 레이어에서 feature map 중 하나의 채널을 고른다. 해당 채널에서 가장 큰 값을 가지는 픽셀을 찾는다. 해당 픽셀의 receptive field가 되는 원본 이미지에서의 영역을 출력해본다. 입력 이미지 여러개에 대해 반복해보면, hidden node들이 어떤 작업을 하는지 파악할 수 있다. Class visualization예제 데이터를 사용하지 않고, 네트워크가 기억하고 있는 이미지를 시각화하여 판단하는 방법 Gradient ascent image synthesis 아무런 이미지나 입력으로 준다 타겟 class의 스코어를 계산한 후 스코어를 최대화하는 방향으로 역전파를 통해 입력 이미지를 업데이트 해준다.(gradient를 더해준다) 점점 타겟 클래스에 맞게 필터들이 어떻게 학습했는지 알 수 있다. Model decision explanation모델이 특정 입력을 어떤 각도로 바라보고 있는지 해석하는 방법 Saliency test영상이 판정되기 위한 각 영역의 중요도를 추출하는 방법 occlusion map 이미지를 일부 가리고 해당 클래스에 대한 스코어가 얼마일지 예측 via backpropagation gradient ascent 방법과 유사하다. 하지만 입력 이미지를 업데이트하는 것이 아니라, 입력 이미지의gradient를 새로운 이미지로 그린다. 입력 이미지를 CNN에 넣어 class score를 얻는다. backpropagation으로 입력 이미지의 gradient를 구한다. gradient에 절댓값 또는 제곱을 하여 절대적인 크기(magnitude)를 구한다. 어느 방향으로 바뀌는지 보다 해당 영역의 얼마나 큰 영향을 끼치는지가 중요 gradient가 높은 지점이 집중한 곳 Rectified unit(backward pass) 위에서 단순하게 gradient만 그려냈다면, 이번에는 gradient를 그린 것보다 더 선명한 패턴을 시각화해 보고자 한다. Forward pass : 음수가 0으로 마스킹 Backward pass:-backpropagation: 현재 값들을 기준으로 음수를 마스킹하지 않고 Forward 시에 0이하였던 unit들을 음수 마스킹 Backward pass-Deconvnet: Backward 시에 Forward시점의 값 기준이 아니라 Backpropagation 시점의 값을 기준으로 음수 마스킹. 마치 역방향으로 ReLU를 재적용 Guided backpropagation : Backward 시에 Forward 패턴도 마스킹하고, 현재 패턴 기준으로도 마스킹 Class Activation mapping CAM Heatmap을 이용하여 분석하는 방법 Grad-CAM SCOUTER","link":"/2021/03/11/BoostCamp/Day33/"}],"tags":[],"categories":[{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"BoostCamp","slug":"AI/BoostCamp","link":"/categories/AI/BoostCamp/"},{"name":"Project Stage","slug":"AI/BoostCamp/Project-Stage","link":"/categories/AI/BoostCamp/Project-Stage/"},{"name":"Pytorch","slug":"AI/Pytorch","link":"/categories/AI/Pytorch/"}]}