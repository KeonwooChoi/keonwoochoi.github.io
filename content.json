{"pages":[],"posts":[{"title":"Pytorch1","text":"Gradient Descentexercise) $y=x^2w_2+xw_1+b-y$Using pytorch12345import torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimtorch.manual_seed(1) &lt;torch._C.Generator at 0x2cdbae1d070&gt; 12345678x_train = torch.FloatTensor([[1.0],[2.0],[3.0]])y_train = torch.FloatTensor([[2.0],[4.0],[6.0]])w1 = torch.zeros(1, requires_grad=True)w2 = torch.zeros(1, requires_grad=True)b = torch.zeros(1, requires_grad=True)def forward(x): return x*x*w2 + x*w1 + bprint(forward(4)) tensor([0.], grad_fn=&lt;AddBackward0&gt;) 123456789101112131415161718192021# optimizer 설정optimizer = optim.SGD([w2,w1,b], lr=2*1e-2)nb_epochs = 2000for epoch in range(nb_epochs + 1): # H(x) 계산 hypothesis = x_train*x_train*w2+x_train*w1+b # cost 계산 cost = torch.mean((hypothesis - y_train) ** 2) # cost로 H(x) 개선 optimizer.zero_grad() cost.backward() optimizer.step() if epoch % 100 == 0: print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} b: {:.3f} Cost: {:.6f}'.format( epoch, nb_epochs, w1.item(), w2.item(), b.item(), cost.item() )) Epoch 0/2000 w1: 0.373 w2: 0.960 b: 0.160 Cost: 18.666666 Epoch 100/2000 w1: 0.858 w2: 0.302 b: 0.828 Cost: 0.025777 Epoch 200/2000 w1: 0.959 w2: 0.255 b: 0.891 Cost: 0.014748 Epoch 300/2000 w1: 0.998 w2: 0.243 b: 0.875 Cost: 0.013746 Epoch 400/2000 w1: 1.029 w2: 0.235 b: 0.850 Cost: 0.012942 Epoch 500/2000 w1: 1.058 w2: 0.228 b: 0.825 Cost: 0.012187 Epoch 600/2000 w1: 1.086 w2: 0.221 b: 0.801 Cost: 0.011475 Epoch 700/2000 w1: 1.113 w2: 0.215 b: 0.777 Cost: 0.010806 Epoch 800/2000 w1: 1.139 w2: 0.209 b: 0.754 Cost: 0.010175 Epoch 900/2000 w1: 1.165 w2: 0.202 b: 0.732 Cost: 0.009581 Epoch 1000/2000 w1: 1.189 w2: 0.196 b: 0.710 Cost: 0.009022 Epoch 1100/2000 w1: 1.214 w2: 0.191 b: 0.689 Cost: 0.008495 Epoch 1200/2000 w1: 1.237 w2: 0.185 b: 0.669 Cost: 0.008000 Epoch 1300/2000 w1: 1.259 w2: 0.179 b: 0.649 Cost: 0.007533 Epoch 1400/2000 w1: 1.281 w2: 0.174 b: 0.630 Cost: 0.007093 Epoch 1500/2000 w1: 1.303 w2: 0.169 b: 0.611 Cost: 0.006679 Epoch 1600/2000 w1: 1.323 w2: 0.164 b: 0.593 Cost: 0.006289 Epoch 1700/2000 w1: 1.343 w2: 0.159 b: 0.575 Cost: 0.005922 Epoch 1800/2000 w1: 1.363 w2: 0.154 b: 0.558 Cost: 0.005577 Epoch 1900/2000 w1: 1.382 w2: 0.150 b: 0.542 Cost: 0.005251 Epoch 2000/2000 w1: 1.400 w2: 0.145 b: 0.526 Cost: 0.004945 1print(forward(4)) tensor([8.4512], grad_fn=&lt;AddBackward0&gt;) Manual참조 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# Training Datax_data = [1.0, 2.0, 3.0]y_data = [2.0, 4.0, 6.0]# a random guess: random valuew1 = 0w2 = 0b = 0# our model forward passdef forward(x): return pow(x,2)*w2 + x*w1 + b# Loss functiondef loss(x, y): y_pred = forward(x) return (y_pred - y) * (y_pred - y)# compute gradientdef w1_gradient(x, y, y_pred): # d_loss/d_w1 return 2 * x * (y_pred - y)def w2_gradient(x, y, y_pred): # d_loss/d_w2 return 2 * pow(x, 2) * (y_pred - y)def b_gradient(x, y, y_pred): # d_loss/d_b return 2 * (y_pred - y)# Update the weights and the biasdef optimize(x, y, learning_rate = 0.02): global w1, w2, b y_pred = forward(x) w1_grad = w1_gradient(x, y, y_pred) w1 = w1 - learning_rate * w1_grad w2_grad = w2_gradient(x, y, y_pred) w2 = w2 - learning_rate * w2_grad b_grad = b_gradient(x, y, y_pred) b = b - learning_rate * b_grad# print('\\tgrad(w1, w2, b): ', x_val, y_val, round(w1_grad, 2), round(w2_grad, 2), round(b_grad, 2)) return w1, w2, b# Before trainingprint(&quot;Prediction (before training)&quot;, 4, forward(4))# Training loopfor epoch in range(20): for x_val, y_val in zip(x_data, y_data): # Compute derivative w.r.t to the learned weights # Compute the loss and print progress w1, w2, b = optimize(x_val, y_val) l = loss(x_val, y_val) print(&quot;progress : &quot;, epoch, &quot;loss = &quot;, round(l, 2))# After trainingprint(&quot;Predicted score (after training)&quot;, &quot;4 hours of studying: &quot;, forward(4)) Prediction (before training) 4 0 progress : 0 loss = 6.38 progress : 1 loss = 11.8 progress : 2 loss = 6.54 progress : 3 loss = 6.22 progress : 4 loss = 4.57 progress : 5 loss = 3.81 progress : 6 loss = 3.01 progress : 7 loss = 2.45 progress : 8 loss = 1.98 progress : 9 loss = 1.61 progress : 10 loss = 1.32 progress : 11 loss = 1.08 progress : 12 loss = 0.9 progress : 13 loss = 0.75 progress : 14 loss = 0.63 progress : 15 loss = 0.53 progress : 16 loss = 0.45 progress : 17 loss = 0.38 progress : 18 loss = 0.33 progress : 19 loss = 0.29 Predicted score (after training) 4 hours of studying: 7.71975178478036 Optimizer참조 Logistic RegressionBinary Classification using sigmoid12345%matplotlib inlineimport numpy as np # 넘파이 사용import matplotlib.pyplot as plt # 맷플롯립사용def sigmoid(x): # 시그모이드 함수 정의 return 1/(1+np.exp(-x)) 1234567891011x = np.arange(-5.0, 5.0, 0.1)y1 = sigmoid(0.5*x)y2 = sigmoid(x)y3 = sigmoid(2*x)plt.plot(x, y1, 'r', linestyle='--') # W의 값이 0.5일때plt.plot(x, y2, 'g') # W의 값이 1일때plt.plot(x, y3, 'b', linestyle='--') # W의 값이 2일때plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가plt.title('Sigmoid Function')plt.show() ​​ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657from torch import tensorfrom torch import nnfrom torch import sigmoidimport torch.nn.functional as Fimport torch.optim as optim# Training data and ground truthx_data = tensor([[1.0], [2.0], [3.0], [4.0]])y_data = tensor([[0.], [0.], [1.], [1.]])class Model(nn.Module): def __init__(self): &quot;&quot;&quot; In the constructor we instantiate nn.Linear module &quot;&quot;&quot; super(Model, self).__init__() self.linear = nn.Linear(1, 1) # One in and one out def forward(self, x): &quot;&quot;&quot; In the forward function we accept a Variable of input data and we must return a Variable of output data. &quot;&quot;&quot; y_pred = sigmoid(self.linear(x)) return y_pred# our modelmodel = Model()# Construct our loss function and an Optimizer. The call to model.parameters()# in the SGD constructor will contain the learnable parameters of the two# nn.Linear modules which are members of the model.criterion = nn.BCELoss(reduction='mean')optimizer = optim.SGD(model.parameters(), lr=0.01)# Training loopfor epoch in range(1000): # Forward pass: Compute predicted y by passing x to the model y_pred = model(x_data) # Compute and print loss loss = criterion(y_pred, y_data) if epoch%100==0: print(f'Epoch {epoch}/1000 | Loss: {loss.item():.4f}') # Zero gradients, perform a backward pass, and update the weights. optimizer.zero_grad() loss.backward() optimizer.step()# After trainingprint(f'\\nLet\\'s predict the hours need to score above 50%\\n{&quot;=&quot; * 50}')hour_var = model(tensor([[1.0]]))print(f'Prediction after 1 hour of training: {hour_var.item():.4f} | Above 50%: {hour_var.item() &gt; 0.5}')hour_var = model(tensor([[7.0]]))print(f'Prediction after 7 hours of training: {hour_var.item():.4f} | Above 50%: { hour_var.item() &gt; 0.5}') Epoch 0/1000 | Loss: 0.5570 Epoch 100/1000 | Loss: 0.5298 Epoch 200/1000 | Loss: 0.5114 Epoch 300/1000 | Loss: 0.4944 Epoch 400/1000 | Loss: 0.4786 Epoch 500/1000 | Loss: 0.4638 Epoch 600/1000 | Loss: 0.4499 Epoch 700/1000 | Loss: 0.4368 Epoch 800/1000 | Loss: 0.4246 Epoch 900/1000 | Loss: 0.4131 Let's predict the hours need to score above 50% ================================================== Prediction after 1 hour of training: 0.3149 | Above 50%: False Prediction after 7 hours of training: 0.9854 | Above 50%: True Activation Functions 1","link":"/2021/01/25/Pytorch/Pytorch1/"},{"title":"Day33","text":"Object detectionWhat is object detection semantic segmentation보다 더 구체적 객체가 달라도 구분이 됨 Instance segmentation ⊂ Panoptic sementation object detection=Classification + Box localization two-stage: box localization → classfication one-stage: box + classfication 한번에 What are the applications autonomous driveing ocr Two-stage detectorTraditional Gradient-based detector 과거에는 경계선을 특징으로 모델링 , gradient 방향성을 활용한 선형 모델 사용 selective search 사람이나 특정 물체 뿐만 아니라, 다양한 물체 후보군의 영역 후보군을 지정해주는 방식 bounding box 제안-&gt; Proposal Algorithm Over-segmentation: 영상을 색끼리 잘게 분할 merginig: 비슷한 feature를 가지는 영역들을 합침 반복해서 합쳐주다보면 object를 소수로 특정지음 특정지은 소수의 object 위치를 바운딩 박스로 나타냄 R-CNN Selective Search를 통해 Region Proposal을 진행 → 2K 이하로 설정 각 Region Proposal을 CNN의 input size로 Warping 기존에 pre-trained된 CNN에 input으로 넣어서 Classification을 진행 SVM의 linear classifier만을 이용해서 클래스를 학습(fine-tuning) 단점 모든 region proposal이 CNN에 입력값으로 들어가기 때문에 느림 Hand Designed된 selective search-&gt; 학습을 통한 성능향상에 한계 Fast R-CNN 영상 전체에 대한 Feature을 한번에 추출하고 이를 재활용해서 object detection Conv layer를 통해 feature map 검출 conv layer를 거쳤으므로 tensor형태가 된다 Fully Convolutional Network는 입력사이즈와 상관없이 Feature Map을 뽑아낼 수 있기 때문에 warp 필요 없다 RoI Pooling: Feature를 여러번 재활용, Region Proposal이 제시한 물체의 후보 위치들(Bounding Box)에 대해서 RoI에 해당하는 Feature만 추출한다. RoI feature를 고정된 사이즈로 resampling한다 classification : softmax, bbx regression로 위치 조정 selective search를 사용했으므로 성능 향상 한계 Faster R-CNN IoU 두 영역의 OVERLAP 측정 anchor box 각 위치에서 발생할 것 같은 박스를 미리 정의해둔 후보군 box의 개수와 종류는 hyperparameter Faster R-CNN에서는 9개 (scale 3 * 비율3) selective search 대신 RPN 모듈 제안 Fast R-CNN과 마찬가지로 각각의 영상에서 공유되는 Feature Map을 미리 뽑아두고, 해당 Feature Map을 바탕으로 RPN에서 Region Proposal을 여러 개 제공하고 RoI Pooling을 실시한 다음 Classifier를 통해 정답을 예측 Region Proposal Network Conv Layer를 통해 나온 Feature Map에 Sliding Window 방식으로 돌면서 매 위치마다 미리 정의해둔 K개의 Anchor Box를 고려 각 위치에서 256-d의 feature vector를 하나 추출 각 vector로 부터 Object인지 아닌지에 대한 score인 2K개 classification score (object, non-object) k개의 Bounding Box위치를 regression하는 4k 개의 Coordinates (x,y,w,h 4개) Anchor Box를 촘촘하게 만들면 계산 속도가 느려지므로 대표적인 비율과 Scale만 정해두고 정교한 위치는 Regression 문제로 분할 정복 각각의 Loss → Cross Entropy Loss + Regression Loss를 사용 이 2가지 Loss가 RPN을 위한 요소가 되며, 전체 Target Task를 위한 RoI별 Classification Loss는 따로 하나가 추가가 되서 전체적으로 End-to-End로 학습을 진행한다. RPN에서 object를 완전히 class로 분류한게 아니라, object인지 아닌지만 판단 RPN에서 classifier, regressor 두개의 모델이 필요하고, 마지막으로 classifier가 필요하다. 또 맨 처음 feature map을 뽑아낼 CNN도 필요하다. 총 4개의 모델이 각각이 아니라 한번에 학습된다. non maximum suppression IoU스코어가 낮은 박스들은 제거하는 방식의 NMS 알고리즘을 추가한다. Single-stage-detectorComparison with two-stage detector 성능을 조금 포기하고 계산 속도를 확보해서 real-time detection 이 가능하도록한 모델 ROI pooling을 하지 않기 때문에 구조가 매우 간단한 편 YOLO input image를 SxS grid로 나눈다 각 grid마다 바운딩박스 정보 4개 + object여부 1개 + Class 분류 확률 C개 = 5+C개의 정보를 한꺼번에 예측한다. Faster R-CNN의 RPN과 마찬가지로, ground truth와의 IoU스코어가 높은 Anchor box를 positive로 간주하여 loss 계산 30 channel= 앵커박스를 grid마다 2개만 사용했고, class 개수는 총 20개여서 5*2+20=30 s는 convolution layer에서의 마지막 해상도로 결정됨 마지막 layer에서만 prediction을 수행하기 떄문에 localization 정확도 떨어짐 single shot multibox detector(SSD) SSD는 Multi Scale object를 더 잘 처리하기 위해서 중간 Feature를 각 해상도에 적절한 Bounding Box 들을 출력할 수 있도록하는 Multi Scale구조를 만들었다. 각기 다른 크기의 feature map에서 정해진 크기의 anchor box를 사용하면, feature map 사이즈에 따라 anchor box가 scaling된다. feature map 사이즈마다, anchor box를 적용하여 object를 탐지한다. 때문에 YOLO에 비해 계산량이 늘어난다 SSD는 각 층마다 classifier적용 각 layer마다 (class수+위치정보4)에 anchor box개수를 곱해준다 Two-stage vs One-stageFocal loss 일반적으로object보다 background가 더 넗음-&gt; class imbalance 모든 구역에 대해 object detection하는 경우 negative를 결과로 내는 anchor boxrk 많아진다. focal loss= cross entropy의 확장 파란색 그래프가 기존의 Cross Entropy 나머지가 FL함수에서 $\\gamma$값을 바꿔주었을 때의 그래프다. 학률term을 통해 잘 맞춘 애들은 더 낮은 loss를 주고 맞추지 못한 애들은 더 높은 loss를 준다. FL함수는 정답률이 높을수록 gradient를 0에 가깝게 만들고, 정답률이 낮을수록 gradient가 가팔라지게 Loss 값 자체가 중요한게 아니라 gradient $\\gamma$값을 크게줄수록 적용 폭이 강해진다. Q) gamma가 높을수록 loss가 낮아지지만 잘 찾지 못할 때 loss는 소폭 줄어들게 하고 잘 찾은 경우에서는 loss를 대폭 줄어들게 합니다 RetinaNet FPN U-Net과 비슷한 구조다. residual을 활용하여 더해줌으로써, low-level의 특징과 high-level의 특징을 둘 다 활용하면서 각 scale별로 object를 잘 찾기 위한 multi-scale 구조를 갖게된다. (concat이 아닌 더하기) class 분류와 box 회귀 예측을 진행한다. Detection with Transform DETR CNN으로 Feature추출 후, Positional encoding을 더해준다. encoder 학습 후, decoder에 query를 입력으로 준다. (query는 object 정보이거나, positional encoding 정보) 추가로, 최대 몇개의 box를 찾아줄지에 대한 값도 함께 준다. (N) 해당 query에 맞는 object를 찾아 box를 찾아준다. positional encoding의 경우 해당 위치 근처의 바운딩 박스와 class를 찾아준다 Visualizing CNNWhat is CNN visualization 딥러닝 네트워크= black box CNN의 경우 시각화가 가능하다. visualization as debugging tool low-level feature는 방향성이 있는 선, 동그란 블록 high-level로 갈수록 의미있는 feature Vanilla example: filter visualization AlexNet 첫번째 층의 필터를 시각화 해당 필터를 이미지에 적용했을 때의 결과(하나의 필터만 적용했기 때문에 밝기값만 가지는 1채널 이미지) 높은 층으로 갈수록 필터도 채널 수가 늘어나 고차원의 필터를 시각화하기도 어렵고, 시각화 하더라도 사람이 해석할 수 없다 How to visualize neural network 왼쪽으로 갈수록 모델 자체를 분석 른쪽으로 갈수록 모델의 출력 결과가 왜 그렇게 나타났는지 분석 Analysis of model behaviorsEmbedding feature analysisHigh-level layer에서 얻는 High-level feature들을 분석하는 방법 nearest neighbors in a feature space 잘 군집되어 있음을 확인할 수 있으며 픽셀단위로 학습했음에도 불구하고 포즈도 다르고 방향도 다른 이미지들이 제대로 보여지는 것을 확인할 수 있다. 각각의 이미지에 대해 feature들을 뽑아놓고 임베딩 공간에 저장해둔다. 후 입력이 들어오면, 해당 feature와 비슷하게 임베딩된 feature들을 탐색한다. 유사도 탐색으로 찾아낸 k개의 feature들의 원본 image를 가져와서 반환해준다. 이 feature들은 매우 고차원 공간에 위치하므로 인간이 해석하기가 너무 어렵다. Demensionality reduction 고차원 상상 힘들기 때문에 차원축소를 통해 각 클래스마다 다른 색상으로 구분한다. 각 클래스간의 분포가 비슷한 위치에 존재한다면 해당 클래스들을 유사하게 보고 있다는 것으로 해석 가능 3, 8 , 5 분포가 가까움 -&gt; 경계에서 헷갈릴 수 있음 Activation investigation레이어의 activation을 분석하여 모델의 특성을 파악하는 방법 AlexNet 다섯번째 층의 138번째 채널 값을 thresholding을 통해 시각화-&gt;사람의 얼굴을 detection 각 hidden node들의 역할(activation)을 파악하는 방법 Maximully activating patch 레이어를 하나 골라서 해당 레이어에서 feature map 중 하나의 채널을 고른다. 해당 채널에서 가장 큰 값을 가지는 픽셀을 찾는다. 해당 픽셀의 receptive field가 되는 원본 이미지에서의 영역을 출력해본다. 입력 이미지 여러개에 대해 반복해보면, hidden node들이 어떤 작업을 하는지 파악할 수 있다. Class visualization예제 데이터를 사용하지 않고, 네트워크가 기억하고 있는 이미지를 시각화하여 판단하는 방법 Gradient ascent image synthesis 아무런 이미지나 입력으로 준다 타겟 class의 스코어를 계산한 후 스코어를 최대화하는 방향으로 역전파를 통해 입력 이미지를 업데이트 해준다.(gradient를 더해준다) 점점 타겟 클래스에 맞게 필터들이 어떻게 학습했는지 알 수 있다. Model decision explanation모델이 특정 입력을 어떤 각도로 바라보고 있는지 해석하는 방법 Saliency test영상이 판정되기 위한 각 영역의 중요도를 추출하는 방법 occlusion map 이미지를 일부 가리고 해당 클래스에 대한 스코어가 얼마일지 예측 via backpropagation gradient ascent 방법과 유사하다. 하지만 입력 이미지를 업데이트하는 것이 아니라, 입력 이미지의gradient를 새로운 이미지로 그린다. 입력 이미지를 CNN에 넣어 class score를 얻는다. backpropagation으로 입력 이미지의 gradient를 구한다. gradient에 절댓값 또는 제곱을 하여 절대적인 크기(magnitude)를 구한다. 어느 방향으로 바뀌는지 보다 해당 영역의 얼마나 큰 영향을 끼치는지가 중요 gradient가 높은 지점이 집중한 곳 Rectified unit(backward pass) 위에서 단순하게 gradient만 그려냈다면, 이번에는 gradient를 그린 것보다 더 선명한 패턴을 시각화해 보고자 한다. Forward pass : 음수가 0으로 마스킹 Backward pass:-backpropagation: 현재 값들을 기준으로 음수를 마스킹하지 않고 Forward 시에 0이하였던 unit들을 음수 마스킹 Backward pass-Deconvnet: Backward 시에 Forward시점의 값 기준이 아니라 Backpropagation 시점의 값을 기준으로 음수 마스킹. 마치 역방향으로 ReLU를 재적용 Guided backpropagation : Backward 시에 Forward 패턴도 마스킹하고, 현재 패턴 기준으로도 마스킹 Class Activation mapping CAM Heatmap을 이용하여 분석하는 방법 Grad-CAM SCOUTER","link":"/2021/03/11/BoostCamp/Day33/"},{"title":"Day36","text":"연역적 (deductive) 결정 가설 증명을 통해 현상을 추론 “전제가 참이면, 결론도 참”이라는 논리로 결정 전제에 따라 결과가 바뀜 귀납적 (inductive) 결정 가설을 경험적 자료와 비교해 추론 높은 확률로 참, 낮은 확률로 거짓 머신러닝(결정기)도 이에 해당 결정기 결정기는 어떤 데이터를 가지고 최종 판단을 내리는 것을 말한다. 추천시스템과 같은 가벼운 의사결정부터 암 진단과 같은 무거운 결정까지 다양 딥러닝이 발전하기 전에는 모델의 성능이 좋지 않았기 때문에 가벼운 결정만 가능하였지만 발전 이후 정확도가 거의 100%에 가까워지면서 무거운 의사결정가지 가능 가벼운 결정기머신러닝(결정기)은 인간의 결정을 대신 해줌 서비스하기 위해 큰 데이터로 학습한 모델을 경량화해서 edge device에 탑재. 경량화: 필요한 것만 갖고 불필요한 것을 제거하여 규모를 줄이거나 가볍게 만드는 것 소형화: 필요/불필요한 것을 구분하지 않고 규모를 줄이거나 가볍게 만드는 것 무엇을 경량화? 모델이 가진 무의미한 정보량을 줄여서 경량화를 달성하는 것이 목표 무의미한 정보가 줄어들면, 정보의 밀도가 올라간다 모델 압축(Compression)과도 같다 어떻게 경량화? Pruning Quantization Knowledge Distillation Filter Decomposition 모델 경량화 과정 Edge device cloud service나 on-premise(자체 서버)를 했을 때에 엄청난 비용이 발생 사생활 문제와 항상 네트워크에 연결되어 있어야 한다는 문제 Low cost No privacy concerns Stand-alone Cloud intelligence, edge intelligence Edge intellignece는 Centralized intelligence와 비교 좌측은 중앙 서버의 과중이 심한 반면 우측의 Edge intelligence의 경우 비교적 중앙 서버가 과중이 심하지 않음 Edge intelligence에는 Edge Training, Edge Offloading, Edge Caching, Edge Inference 등이 있다. 우리가 많이 다루게 될 내용은 Edge Inference Edge Inference를 적용하기 위해서는 Pytorch로 모델을 만든 뒤 Edge device에서 사용할 수 있다 Edge Inferenced의 depth High level에서 사용하는 PyTorch나 Tensorflow 등으로 Model을 대부분 만들고 이것들이 Edge devices로 내려가기 위해서는 Low level IR로 Graph lowering OptimizerComputer Optimization 컴퓨터가 문제를 푸는 과정 모든 combination을 고려하기 전까지 최적해를 알 수 없음. 반대로, 유한한 모든 combination을 고려하면 무조건 최적해 보장 ML Optimazation 머신러닝이 문제를 푸는 과정 모든 상태를 고려하지 않고 현재 상태보다 낫게 업데이트해 최적화 Decision problem vs optimization problemDecision problem 조건을 만족한다면 문제를 푼 것. 하나의 결정. 무한한 자원으로 최고 성능을 내는 것. Decision Spanning Tree (DST) upper bound가 정해져 있고, 그 upper bound만 만족하면 풀리는 문제 Optimazation problem 더이상 못찾을 때까지 decision을 연쇄적으로 반복. 제약 조건을 만족하면서 최고의 성능을 내는 것 Minimum Spanning Tree(MST) Dicision problem을 연쇄적으로 반복했을 때 해결 Constraints무엇을 원하느냐에 따라 굉장히 달라짐(시간,돈…) Decision problem에서 무한한 자원 (infinite amount of resoources)을 사용한다고 가정 Optimization problem에서는 각각의 Decision problem에서 지불했던 Cost를 더해서 Constraints를 계산합니다. 이때, 모든 Cost를 더했을 때 Constraint를 넘으면 안된다","link":"/2021/03/16/BoostCamp/Day36/"},{"title":"Day37","text":"","link":"/2021/03/18/BoostCamp/Day37/"},{"title":"Day38","text":"Acceleration 대기시간(Latency)은 요청한 데이터가 도달할 때까지 걸리는 시간이다. 대역폭(Bandwidth)은 단위시간 동안 전달할 수 있는 데이터의 최대치이다. 처리량(Throughput)은 단위시간 동안 실제로 전달되는 데이터의 양으로, 병렬 처리(Parallel processing)은 처리량을 늘리기 위한 것이다. GPU를 사용하는 이유, 병렬 처리가 가능한 라이브러리를 사용하는 이유, 모두 가속화와 밀접한 관련이 있다. Hardware acceleration SoC(System on Chip)는 CPU, GPU 등 다양한 시스템의 구성요소를 칩 하나에 집약한 것으로, 이를 사용하는 대표적인 제품에는 Apple의 M1이 있다. FPGA(Field-programmable gate array)는 사용자가 원하는 용도에 따라 내부 회로를 코딩해서 바꿔 사용할 수 있는 칩이다. 공간 복잡도와 관련있는 압축은 소프트웨어에서 해결하고, 시간 복잡도와 관련있는 가속은 하드웨어에서 해결Deep learning compiler 딥러닝 모델을 특정 디바이스에서 효율적으로 동작시키기 위해서는 해당 디바이스에 최적화된 코드가 필요하다. 이러한 작업을 자동으로 지원해주는 도구가 바로 DL compiler LLVM 원래는 ‘언어의 종류 x 아키텍처의 종류’만큼 복수의 컴파일러가 필요하다 LLVM IR을 사용하면 Frontend에서 어떤 언어가 들어오던 원하는 architecture로 변환해 MLIR MLIR은 LLVM의 Machine Learning 버전 MLIR에서는 중간에 있는 compiler들을 조립 후 통합해서 “통합 Framework”를 사용할 수 있게 만들었다. DL complier에 적용하는 Hardware-specific optimizations Hardware Intrinsic Mapping Memory Allocation &amp; Fetching Memory Latency Hiding Loop Oriented Optimization Techniques Parallelization Pruning Pruning이란 중요하지 않고 반복되는 부분을 잘라내는 것을 뜻한다. 이를 통해 정보의 손실은 일어나겠지만, 모델의 복잡도를 줄여 일반화 성능을 높이고 속도를 높이는 효과를 낸다. 딥러닝에서는 Pruning을 통해 중요하지 않은 것(weight이 0에 가까운 것)을 줄인다. Pruning과 Dropout은 비슷해보이지만, Pruning은 Dropout과 달리 버린 부분을 되살릴 수 없다. 또한 Dropout은 학습 시 사용하는 뉴런의 조합의 바꿔서 앙상블 효과를 낼 뿐 테스트를 할 때는 모든 뉴런을 전부 사용한다. L1, L2 regularization 모델 과적합을 방지하기 위한 방법 중 하나도 weight regularization이 있다. loss function 에 weight L1 norm, L2 norm 항을 추가한 것을 각각 L1, L2 regulation 이라 칭한다. pruning 비율에 따른 accuracy 감소 비율 pruning 후 retrain 할 때 weight regularization 항을 추가하여 과적합(파란점)을 방지(빨간점)한다. pruning 하면 parameter 수가 감소하고, accuracy도 낮아진다. 동일 accuracy를 보일 경우 속도는 느려진다. (tradeoff) Pruning category Unstructured Pruning : weight를 아무 규격 없이 잘라내는 pruning Structured Pruning : weight를 channel / layer 단위로 규격을 잡아 제거하는 pruning, 규격을 잡아 제거했기 때문에 hardward optimization이 잘 된다. Iterative pruning Pruning을 한 번에 많이 수행하게 되면, 많은 weight가 사라지게되어 pruning loss가 줄어든 후 Accuracy가 다시 올라가지 않아서 Iterative (반복적)으로 수행 pruning loss -&gt; retraining -&gt; pruning loss -&gt; retraining … Lottery ticket hypothesis pruning하기 전 얻었던 Accuracy (91%)를 pruning하고 나서도 얻을 수 있는 subnetwork가 원래 network 안에 존재할 것이다라는 가설 original network의 initialization된 parameter를 그대로 사용해야 Accuracy가 잘 나오는 subnetwork. 한계점은 subnetwork를 찾기 위해서는 어짜피 original network를 train해서 찾아야 한다는 것 한계점을 극복하기 위해 차후에 나온 방법(적은 cost) Iterative Magnitude pruning weight의 크기 기준으로 정렬해서 크기가 낮은 기준으로 잘라낸다는 의미 prune-&gt;mask를 씌우고 구조만 가지고 와서 다시 init Iterative Magnitude Pruning with Rewinding k번까지만 train 시킨 후, 이때의 네트워크를 저장 이후 수렴할 때 까지 훈련하고 pruning한 후 마스크를 적용해준다. Retrain 시, 마스크가 적용된 네트워크를 k번 학습하고 저장해놓은 네트워크를 이용하여 초기화해준다.","link":"/2021/03/18/BoostCamp/Day38/"}],"tags":[],"categories":[{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"BoostCamp","slug":"AI/BoostCamp","link":"/categories/AI/BoostCamp/"},{"name":"Pytorch","slug":"AI/Pytorch","link":"/categories/AI/Pytorch/"}]}